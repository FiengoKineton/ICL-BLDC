10
True
0
Loaded 1000 DataFrames from ../../../in-context-bldc-data/simulated/50_percent_add_with_alfa_beta_speed_corrected.
Loaded 100 DataFrames from ../data/CL_experiments_double_sensor/train/inertia13_ki-0.0061-kp-11.8427.
saving model in:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
sequence length:  10
max iterations:  20000
batch size:  64
learning rate:  1e-05
layers:  8
heads:  4
embd:  16
using experimental batch extractor
number of parameters: 0.03M
num decayed parameter tensors: 35, with 24,832 parameters
num non-decayed parameter tensors: 19, with 289 parameters
using fused AdamW: True
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1], Train Loss: 0.5576, Val Loss: 0.4727, LR: 0.000000, best val loss was: 0.4727
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2], Train Loss: 0.5195, Val Loss: 0.4737, LR: 0.000000, best val loss was: 0.4727
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3], Train Loss: 0.5434, Val Loss: 0.4979, LR: 0.000000, best val loss was: 0.4727
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4], Train Loss: 0.5679, Val Loss: 0.4617, LR: 0.000000, best val loss was: 0.4617
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5], Train Loss: 0.5544, Val Loss: 0.4685, LR: 0.000000, best val loss was: 0.4617
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [6], Train Loss: 0.5112, Val Loss: 0.4569, LR: 0.000000, best val loss was: 0.4569
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [7], Train Loss: 0.5069, Val Loss: 0.4640, LR: 0.000000, best val loss was: 0.4569
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [8], Train Loss: 0.5129, Val Loss: 0.4480, LR: 0.000000, best val loss was: 0.4480
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [9], Train Loss: 0.5186, Val Loss: 0.4639, LR: 0.000000, best val loss was: 0.4480
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [10], Train Loss: 0.5646, Val Loss: 0.4583, LR: 0.000000, best val loss was: 0.4480
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [11], Train Loss: 0.5621, Val Loss: 0.4706, LR: 0.000000, best val loss was: 0.4480
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [12], Train Loss: 0.5214, Val Loss: 0.4539, LR: 0.000000, best val loss was: 0.4480
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [13], Train Loss: 0.5282, Val Loss: 0.4590, LR: 0.000000, best val loss was: 0.4480
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [14], Train Loss: 0.5402, Val Loss: 0.4401, LR: 0.000000, best val loss was: 0.4401
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [15], Train Loss: 0.5621, Val Loss: 0.4423, LR: 0.000000, best val loss was: 0.4401
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [16], Train Loss: 0.5635, Val Loss: 0.4649, LR: 0.000000, best val loss was: 0.4401
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [17], Train Loss: 0.5954, Val Loss: 0.4572, LR: 0.000000, best val loss was: 0.4401
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [18], Train Loss: 0.5601, Val Loss: 0.4308, LR: 0.000000, best val loss was: 0.4308
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [19], Train Loss: 0.5437, Val Loss: 0.4480, LR: 0.000000, best val loss was: 0.4308
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [20], Train Loss: 0.4964, Val Loss: 0.4356, LR: 0.000000, best val loss was: 0.4308
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [21], Train Loss: 0.5332, Val Loss: 0.4501, LR: 0.000000, best val loss was: 0.4308
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [22], Train Loss: 0.5526, Val Loss: 0.4378, LR: 0.000000, best val loss was: 0.4308
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [23], Train Loss: 0.5452, Val Loss: 0.4660, LR: 0.000000, best val loss was: 0.4308
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [24], Train Loss: 0.5640, Val Loss: 0.4281, LR: 0.000000, best val loss was: 0.4281
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [25], Train Loss: 0.5484, Val Loss: 0.4460, LR: 0.000000, best val loss was: 0.4281
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [26], Train Loss: 0.5979, Val Loss: 0.4018, LR: 0.000000, best val loss was: 0.4018
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [27], Train Loss: 0.5631, Val Loss: 0.4763, LR: 0.000000, best val loss was: 0.4018
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [28], Train Loss: 0.5085, Val Loss: 0.4574, LR: 0.000000, best val loss was: 0.4018
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [29], Train Loss: 0.5211, Val Loss: 0.4506, LR: 0.000000, best val loss was: 0.4018
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [30], Train Loss: 0.5729, Val Loss: 0.4556, LR: 0.000000, best val loss was: 0.4018
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [31], Train Loss: 0.5989, Val Loss: 0.4507, LR: 0.000000, best val loss was: 0.4018
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [32], Train Loss: 0.4860, Val Loss: 0.4479, LR: 0.000000, best val loss was: 0.4018
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [33], Train Loss: 0.4965, Val Loss: 0.4400, LR: 0.000000, best val loss was: 0.4018
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [34], Train Loss: 0.5357, Val Loss: 0.4395, LR: 0.000000, best val loss was: 0.4018
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [35], Train Loss: 0.5150, Val Loss: 0.4392, LR: 0.000000, best val loss was: 0.4018
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [36], Train Loss: 0.5530, Val Loss: 0.4301, LR: 0.000000, best val loss was: 0.4018
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [37], Train Loss: 0.5547, Val Loss: 0.4346, LR: 0.000000, best val loss was: 0.4018
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [38], Train Loss: 0.5386, Val Loss: 0.4241, LR: 0.000000, best val loss was: 0.4018
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [39], Train Loss: 0.4894, Val Loss: 0.4540, LR: 0.000000, best val loss was: 0.4018
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [40], Train Loss: 0.5389, Val Loss: 0.4116, LR: 0.000000, best val loss was: 0.4018
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [41], Train Loss: 0.5058, Val Loss: 0.4235, LR: 0.000000, best val loss was: 0.4018
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [42], Train Loss: 0.5462, Val Loss: 0.4413, LR: 0.000000, best val loss was: 0.4018
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [43], Train Loss: 0.5019, Val Loss: 0.4337, LR: 0.000000, best val loss was: 0.4018
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [44], Train Loss: 0.5095, Val Loss: 0.4192, LR: 0.000000, best val loss was: 0.4018
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [45], Train Loss: 0.5497, Val Loss: 0.3991, LR: 0.000000, best val loss was: 0.3991
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [46], Train Loss: 0.5379, Val Loss: 0.4068, LR: 0.000000, best val loss was: 0.3991
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [47], Train Loss: 0.5417, Val Loss: 0.3950, LR: 0.000000, best val loss was: 0.3950
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [48], Train Loss: 0.5071, Val Loss: 0.4390, LR: 0.000000, best val loss was: 0.3950
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [49], Train Loss: 0.5062, Val Loss: 0.4427, LR: 0.000000, best val loss was: 0.3950
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [50], Train Loss: 0.4626, Val Loss: 0.3947, LR: 0.000000, best val loss was: 0.3947
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [51], Train Loss: 0.5189, Val Loss: 0.4299, LR: 0.000000, best val loss was: 0.3947
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [52], Train Loss: 0.4915, Val Loss: 0.4049, LR: 0.000000, best val loss was: 0.3947
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [53], Train Loss: 0.5093, Val Loss: 0.4359, LR: 0.000000, best val loss was: 0.3947
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [54], Train Loss: 0.4651, Val Loss: 0.4261, LR: 0.000000, best val loss was: 0.3947
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [55], Train Loss: 0.4847, Val Loss: 0.4157, LR: 0.000000, best val loss was: 0.3947
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [56], Train Loss: 0.4827, Val Loss: 0.4081, LR: 0.000000, best val loss was: 0.3947
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [57], Train Loss: 0.5727, Val Loss: 0.3923, LR: 0.000000, best val loss was: 0.3923
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [58], Train Loss: 0.5666, Val Loss: 0.4142, LR: 0.000000, best val loss was: 0.3923
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [59], Train Loss: 0.5408, Val Loss: 0.3998, LR: 0.000000, best val loss was: 0.3923
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [60], Train Loss: 0.5203, Val Loss: 0.3641, LR: 0.000000, best val loss was: 0.3641
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [61], Train Loss: 0.5443, Val Loss: 0.4181, LR: 0.000000, best val loss was: 0.3641
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [62], Train Loss: 0.4884, Val Loss: 0.3758, LR: 0.000000, best val loss was: 0.3641
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [63], Train Loss: 0.4695, Val Loss: 0.3932, LR: 0.000000, best val loss was: 0.3641
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [64], Train Loss: 0.5344, Val Loss: 0.3844, LR: 0.000000, best val loss was: 0.3641
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [65], Train Loss: 0.5052, Val Loss: 0.3936, LR: 0.000000, best val loss was: 0.3641
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [66], Train Loss: 0.4999, Val Loss: 0.3933, LR: 0.000000, best val loss was: 0.3641
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [67], Train Loss: 0.5157, Val Loss: 0.3865, LR: 0.000000, best val loss was: 0.3641
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [68], Train Loss: 0.5154, Val Loss: 0.3982, LR: 0.000000, best val loss was: 0.3641
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [69], Train Loss: 0.4443, Val Loss: 0.3721, LR: 0.000000, best val loss was: 0.3641
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [70], Train Loss: 0.5024, Val Loss: 0.4020, LR: 0.000000, best val loss was: 0.3641
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [71], Train Loss: 0.5330, Val Loss: 0.3890, LR: 0.000000, best val loss was: 0.3641
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [72], Train Loss: 0.4864, Val Loss: 0.3760, LR: 0.000000, best val loss was: 0.3641
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [73], Train Loss: 0.5352, Val Loss: 0.3951, LR: 0.000000, best val loss was: 0.3641
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [74], Train Loss: 0.4925, Val Loss: 0.4042, LR: 0.000000, best val loss was: 0.3641
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [75], Train Loss: 0.4939, Val Loss: 0.3908, LR: 0.000000, best val loss was: 0.3641
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [76], Train Loss: 0.5151, Val Loss: 0.4097, LR: 0.000000, best val loss was: 0.3641
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [77], Train Loss: 0.5178, Val Loss: 0.3649, LR: 0.000000, best val loss was: 0.3641
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [78], Train Loss: 0.4618, Val Loss: 0.3924, LR: 0.000000, best val loss was: 0.3641
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [79], Train Loss: 0.4840, Val Loss: 0.4009, LR: 0.000000, best val loss was: 0.3641
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [80], Train Loss: 0.4850, Val Loss: 0.3710, LR: 0.000000, best val loss was: 0.3641
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [81], Train Loss: 0.5195, Val Loss: 0.3681, LR: 0.000000, best val loss was: 0.3641
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [82], Train Loss: 0.4866, Val Loss: 0.3758, LR: 0.000000, best val loss was: 0.3641
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [83], Train Loss: 0.4988, Val Loss: 0.4000, LR: 0.000000, best val loss was: 0.3641
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [84], Train Loss: 0.4672, Val Loss: 0.3786, LR: 0.000000, best val loss was: 0.3641
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [85], Train Loss: 0.5807, Val Loss: 0.3661, LR: 0.000000, best val loss was: 0.3641
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [86], Train Loss: 0.4746, Val Loss: 0.3736, LR: 0.000000, best val loss was: 0.3641
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [87], Train Loss: 0.5054, Val Loss: 0.3680, LR: 0.000000, best val loss was: 0.3641
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [88], Train Loss: 0.5313, Val Loss: 0.4005, LR: 0.000000, best val loss was: 0.3641
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [89], Train Loss: 0.5070, Val Loss: 0.3707, LR: 0.000000, best val loss was: 0.3641
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [90], Train Loss: 0.4953, Val Loss: 0.3967, LR: 0.000000, best val loss was: 0.3641
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [91], Train Loss: 0.4918, Val Loss: 0.3652, LR: 0.000000, best val loss was: 0.3641
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [92], Train Loss: 0.4746, Val Loss: 0.3555, LR: 0.000000, best val loss was: 0.3555
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [93], Train Loss: 0.4254, Val Loss: 0.3502, LR: 0.000000, best val loss was: 0.3502
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [94], Train Loss: 0.5011, Val Loss: 0.3900, LR: 0.000000, best val loss was: 0.3502
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [95], Train Loss: 0.4513, Val Loss: 0.3616, LR: 0.000000, best val loss was: 0.3502
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [96], Train Loss: 0.4699, Val Loss: 0.3663, LR: 0.000000, best val loss was: 0.3502
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [97], Train Loss: 0.5019, Val Loss: 0.3708, LR: 0.000000, best val loss was: 0.3502
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [98], Train Loss: 0.4868, Val Loss: 0.3750, LR: 0.000000, best val loss was: 0.3502
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [99], Train Loss: 0.4483, Val Loss: 0.3477, LR: 0.000000, best val loss was: 0.3477
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [100], Train Loss: 0.4636, Val Loss: 0.3589, LR: 0.000000, best val loss was: 0.3477
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [101], Train Loss: 0.5213, Val Loss: 0.3663, LR: 0.000000, best val loss was: 0.3477
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [102], Train Loss: 0.4557, Val Loss: 0.3614, LR: 0.000000, best val loss was: 0.3477
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [103], Train Loss: 0.4809, Val Loss: 0.3603, LR: 0.000000, best val loss was: 0.3477
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [104], Train Loss: 0.4642, Val Loss: 0.3595, LR: 0.000000, best val loss was: 0.3477
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [105], Train Loss: 0.4670, Val Loss: 0.3624, LR: 0.000000, best val loss was: 0.3477
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [106], Train Loss: 0.4887, Val Loss: 0.3660, LR: 0.000000, best val loss was: 0.3477
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [107], Train Loss: 0.5290, Val Loss: 0.3749, LR: 0.000000, best val loss was: 0.3477
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [108], Train Loss: 0.5038, Val Loss: 0.3543, LR: 0.000000, best val loss was: 0.3477
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [109], Train Loss: 0.4786, Val Loss: 0.3457, LR: 0.000000, best val loss was: 0.3457
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [110], Train Loss: 0.4505, Val Loss: 0.3274, LR: 0.000000, best val loss was: 0.3274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [111], Train Loss: 0.4598, Val Loss: 0.3815, LR: 0.000000, best val loss was: 0.3274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [112], Train Loss: 0.5315, Val Loss: 0.3476, LR: 0.000000, best val loss was: 0.3274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [113], Train Loss: 0.4762, Val Loss: 0.3767, LR: 0.000000, best val loss was: 0.3274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [114], Train Loss: 0.4818, Val Loss: 0.3649, LR: 0.000000, best val loss was: 0.3274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [115], Train Loss: 0.5282, Val Loss: 0.3633, LR: 0.000000, best val loss was: 0.3274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [116], Train Loss: 0.4984, Val Loss: 0.3412, LR: 0.000000, best val loss was: 0.3274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [117], Train Loss: 0.4374, Val Loss: 0.3464, LR: 0.000000, best val loss was: 0.3274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [118], Train Loss: 0.4270, Val Loss: 0.3285, LR: 0.000000, best val loss was: 0.3274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [119], Train Loss: 0.4723, Val Loss: 0.3603, LR: 0.000000, best val loss was: 0.3274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [120], Train Loss: 0.4584, Val Loss: 0.3364, LR: 0.000000, best val loss was: 0.3274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [121], Train Loss: 0.4362, Val Loss: 0.3329, LR: 0.000000, best val loss was: 0.3274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [122], Train Loss: 0.4607, Val Loss: 0.3585, LR: 0.000000, best val loss was: 0.3274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [123], Train Loss: 0.4597, Val Loss: 0.3363, LR: 0.000000, best val loss was: 0.3274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [124], Train Loss: 0.4668, Val Loss: 0.3628, LR: 0.000000, best val loss was: 0.3274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [125], Train Loss: 0.4619, Val Loss: 0.3396, LR: 0.000000, best val loss was: 0.3274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [126], Train Loss: 0.4804, Val Loss: 0.3399, LR: 0.000000, best val loss was: 0.3274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [127], Train Loss: 0.4845, Val Loss: 0.3585, LR: 0.000000, best val loss was: 0.3274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [128], Train Loss: 0.4600, Val Loss: 0.3423, LR: 0.000000, best val loss was: 0.3274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [129], Train Loss: 0.4174, Val Loss: 0.3279, LR: 0.000000, best val loss was: 0.3274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [130], Train Loss: 0.4355, Val Loss: 0.3545, LR: 0.000000, best val loss was: 0.3274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [131], Train Loss: 0.4630, Val Loss: 0.3380, LR: 0.000000, best val loss was: 0.3274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [132], Train Loss: 0.4769, Val Loss: 0.3534, LR: 0.000000, best val loss was: 0.3274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [133], Train Loss: 0.4290, Val Loss: 0.3483, LR: 0.000000, best val loss was: 0.3274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [134], Train Loss: 0.4511, Val Loss: 0.3240, LR: 0.000000, best val loss was: 0.3240
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [135], Train Loss: 0.4449, Val Loss: 0.3499, LR: 0.000000, best val loss was: 0.3240
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [136], Train Loss: 0.4158, Val Loss: 0.3349, LR: 0.000000, best val loss was: 0.3240
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [137], Train Loss: 0.5221, Val Loss: 0.3306, LR: 0.000000, best val loss was: 0.3240
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [138], Train Loss: 0.4539, Val Loss: 0.3278, LR: 0.000000, best val loss was: 0.3240
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [139], Train Loss: 0.4715, Val Loss: 0.3260, LR: 0.000000, best val loss was: 0.3240
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [140], Train Loss: 0.4622, Val Loss: 0.3247, LR: 0.000000, best val loss was: 0.3240
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [141], Train Loss: 0.4493, Val Loss: 0.3351, LR: 0.000000, best val loss was: 0.3240
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [142], Train Loss: 0.4694, Val Loss: 0.3291, LR: 0.000000, best val loss was: 0.3240
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [143], Train Loss: 0.4990, Val Loss: 0.3316, LR: 0.000000, best val loss was: 0.3240
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [144], Train Loss: 0.4437, Val Loss: 0.3213, LR: 0.000000, best val loss was: 0.3213
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [145], Train Loss: 0.4612, Val Loss: 0.3357, LR: 0.000000, best val loss was: 0.3213
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [146], Train Loss: 0.4507, Val Loss: 0.3053, LR: 0.000000, best val loss was: 0.3053
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [147], Train Loss: 0.4831, Val Loss: 0.3279, LR: 0.000000, best val loss was: 0.3053
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [148], Train Loss: 0.4550, Val Loss: 0.3079, LR: 0.000000, best val loss was: 0.3053
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [149], Train Loss: 0.4362, Val Loss: 0.3156, LR: 0.000000, best val loss was: 0.3053
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [150], Train Loss: 0.4361, Val Loss: 0.3133, LR: 0.000000, best val loss was: 0.3053
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [151], Train Loss: 0.4626, Val Loss: 0.3100, LR: 0.000000, best val loss was: 0.3053
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [152], Train Loss: 0.4824, Val Loss: 0.3140, LR: 0.000000, best val loss was: 0.3053
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [153], Train Loss: 0.4624, Val Loss: 0.3279, LR: 0.000000, best val loss was: 0.3053
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [154], Train Loss: 0.4270, Val Loss: 0.3166, LR: 0.000000, best val loss was: 0.3053
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [155], Train Loss: 0.4294, Val Loss: 0.3233, LR: 0.000000, best val loss was: 0.3053
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [156], Train Loss: 0.4173, Val Loss: 0.3254, LR: 0.000000, best val loss was: 0.3053
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [157], Train Loss: 0.5134, Val Loss: 0.3059, LR: 0.000000, best val loss was: 0.3053
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [158], Train Loss: 0.4225, Val Loss: 0.2978, LR: 0.000000, best val loss was: 0.2978
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [159], Train Loss: 0.4237, Val Loss: 0.2948, LR: 0.000000, best val loss was: 0.2948
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [160], Train Loss: 0.4101, Val Loss: 0.3084, LR: 0.000000, best val loss was: 0.2948
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [161], Train Loss: 0.4650, Val Loss: 0.3029, LR: 0.000000, best val loss was: 0.2948
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [162], Train Loss: 0.4396, Val Loss: 0.3066, LR: 0.000000, best val loss was: 0.2948
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [163], Train Loss: 0.4376, Val Loss: 0.3133, LR: 0.000000, best val loss was: 0.2948
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [164], Train Loss: 0.4285, Val Loss: 0.3101, LR: 0.000000, best val loss was: 0.2948
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [165], Train Loss: 0.4509, Val Loss: 0.3030, LR: 0.000000, best val loss was: 0.2948
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [166], Train Loss: 0.4077, Val Loss: 0.2987, LR: 0.000000, best val loss was: 0.2948
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [167], Train Loss: 0.4881, Val Loss: 0.3094, LR: 0.000000, best val loss was: 0.2948
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [168], Train Loss: 0.4073, Val Loss: 0.3131, LR: 0.000000, best val loss was: 0.2948
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [169], Train Loss: 0.4758, Val Loss: 0.3043, LR: 0.000000, best val loss was: 0.2948
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [170], Train Loss: 0.4770, Val Loss: 0.2948, LR: 0.000000, best val loss was: 0.2948
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [171], Train Loss: 0.4700, Val Loss: 0.3237, LR: 0.000000, best val loss was: 0.2948
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [172], Train Loss: 0.3961, Val Loss: 0.3051, LR: 0.000000, best val loss was: 0.2948
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [173], Train Loss: 0.4884, Val Loss: 0.2958, LR: 0.000000, best val loss was: 0.2948
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [174], Train Loss: 0.3963, Val Loss: 0.2824, LR: 0.000000, best val loss was: 0.2824
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [175], Train Loss: 0.4515, Val Loss: 0.2912, LR: 0.000000, best val loss was: 0.2824
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [176], Train Loss: 0.4015, Val Loss: 0.2963, LR: 0.000000, best val loss was: 0.2824
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [177], Train Loss: 0.4133, Val Loss: 0.2797, LR: 0.000000, best val loss was: 0.2797
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [178], Train Loss: 0.4507, Val Loss: 0.2769, LR: 0.000000, best val loss was: 0.2769
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [179], Train Loss: 0.4187, Val Loss: 0.3113, LR: 0.000000, best val loss was: 0.2769
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [180], Train Loss: 0.4052, Val Loss: 0.2972, LR: 0.000000, best val loss was: 0.2769
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [181], Train Loss: 0.4646, Val Loss: 0.2960, LR: 0.000000, best val loss was: 0.2769
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [182], Train Loss: 0.4120, Val Loss: 0.2779, LR: 0.000000, best val loss was: 0.2769
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [183], Train Loss: 0.3986, Val Loss: 0.3032, LR: 0.000000, best val loss was: 0.2769
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [184], Train Loss: 0.4092, Val Loss: 0.2973, LR: 0.000000, best val loss was: 0.2769
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [185], Train Loss: 0.4405, Val Loss: 0.2730, LR: 0.000000, best val loss was: 0.2730
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [186], Train Loss: 0.4213, Val Loss: 0.2878, LR: 0.000000, best val loss was: 0.2730
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [187], Train Loss: 0.4107, Val Loss: 0.2871, LR: 0.000000, best val loss was: 0.2730
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [188], Train Loss: 0.4226, Val Loss: 0.2981, LR: 0.000000, best val loss was: 0.2730
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [189], Train Loss: 0.4211, Val Loss: 0.2901, LR: 0.000000, best val loss was: 0.2730
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [190], Train Loss: 0.4261, Val Loss: 0.2870, LR: 0.000000, best val loss was: 0.2730
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [191], Train Loss: 0.4394, Val Loss: 0.3010, LR: 0.000000, best val loss was: 0.2730
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [192], Train Loss: 0.4105, Val Loss: 0.2941, LR: 0.000000, best val loss was: 0.2730
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [193], Train Loss: 0.4262, Val Loss: 0.2830, LR: 0.000000, best val loss was: 0.2730
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [194], Train Loss: 0.3922, Val Loss: 0.2800, LR: 0.000000, best val loss was: 0.2730
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [195], Train Loss: 0.4168, Val Loss: 0.2826, LR: 0.000000, best val loss was: 0.2730
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [196], Train Loss: 0.4488, Val Loss: 0.2817, LR: 0.000000, best val loss was: 0.2730
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [197], Train Loss: 0.4273, Val Loss: 0.2872, LR: 0.000000, best val loss was: 0.2730
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [198], Train Loss: 0.4580, Val Loss: 0.2741, LR: 0.000000, best val loss was: 0.2730
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [199], Train Loss: 0.4066, Val Loss: 0.2808, LR: 0.000000, best val loss was: 0.2730
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [200], Train Loss: 0.3596, Val Loss: 0.2591, LR: 0.000000, best val loss was: 0.2591
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [201], Train Loss: 0.4371, Val Loss: 0.2812, LR: 0.000000, best val loss was: 0.2591
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [202], Train Loss: 0.4083, Val Loss: 0.2763, LR: 0.000000, best val loss was: 0.2591
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [203], Train Loss: 0.4277, Val Loss: 0.2793, LR: 0.000000, best val loss was: 0.2591
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [204], Train Loss: 0.4089, Val Loss: 0.2594, LR: 0.000000, best val loss was: 0.2591
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [205], Train Loss: 0.4799, Val Loss: 0.2825, LR: 0.000000, best val loss was: 0.2591
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [206], Train Loss: 0.4245, Val Loss: 0.2766, LR: 0.000000, best val loss was: 0.2591
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [207], Train Loss: 0.4602, Val Loss: 0.2644, LR: 0.000000, best val loss was: 0.2591
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [208], Train Loss: 0.4228, Val Loss: 0.2652, LR: 0.000000, best val loss was: 0.2591
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [209], Train Loss: 0.4449, Val Loss: 0.2708, LR: 0.000000, best val loss was: 0.2591
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [210], Train Loss: 0.3887, Val Loss: 0.2694, LR: 0.000000, best val loss was: 0.2591
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [211], Train Loss: 0.4088, Val Loss: 0.2768, LR: 0.000000, best val loss was: 0.2591
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [212], Train Loss: 0.3965, Val Loss: 0.2671, LR: 0.000000, best val loss was: 0.2591
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [213], Train Loss: 0.4288, Val Loss: 0.2763, LR: 0.000000, best val loss was: 0.2591
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [214], Train Loss: 0.4164, Val Loss: 0.2642, LR: 0.000000, best val loss was: 0.2591
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [215], Train Loss: 0.4197, Val Loss: 0.2690, LR: 0.000000, best val loss was: 0.2591
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [216], Train Loss: 0.4094, Val Loss: 0.2680, LR: 0.000000, best val loss was: 0.2591
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [217], Train Loss: 0.4156, Val Loss: 0.2938, LR: 0.000000, best val loss was: 0.2591
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [218], Train Loss: 0.4053, Val Loss: 0.2590, LR: 0.000000, best val loss was: 0.2590
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [219], Train Loss: 0.4300, Val Loss: 0.2586, LR: 0.000000, best val loss was: 0.2586
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [220], Train Loss: 0.4157, Val Loss: 0.2530, LR: 0.000000, best val loss was: 0.2530
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [221], Train Loss: 0.3798, Val Loss: 0.2608, LR: 0.000000, best val loss was: 0.2530
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [222], Train Loss: 0.3834, Val Loss: 0.2583, LR: 0.000000, best val loss was: 0.2530
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [223], Train Loss: 0.4205, Val Loss: 0.2710, LR: 0.000000, best val loss was: 0.2530
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [224], Train Loss: 0.4135, Val Loss: 0.2528, LR: 0.000000, best val loss was: 0.2528
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [225], Train Loss: 0.4021, Val Loss: 0.2547, LR: 0.000000, best val loss was: 0.2528
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [226], Train Loss: 0.3980, Val Loss: 0.2552, LR: 0.000000, best val loss was: 0.2528
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [227], Train Loss: 0.3969, Val Loss: 0.2596, LR: 0.000000, best val loss was: 0.2528
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [228], Train Loss: 0.4220, Val Loss: 0.2525, LR: 0.000000, best val loss was: 0.2525
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [229], Train Loss: 0.4379, Val Loss: 0.2667, LR: 0.000000, best val loss was: 0.2525
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [230], Train Loss: 0.4091, Val Loss: 0.2490, LR: 0.000000, best val loss was: 0.2490
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [231], Train Loss: 0.4248, Val Loss: 0.2601, LR: 0.000000, best val loss was: 0.2490
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [232], Train Loss: 0.3887, Val Loss: 0.2536, LR: 0.000000, best val loss was: 0.2490
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [233], Train Loss: 0.3900, Val Loss: 0.2522, LR: 0.000000, best val loss was: 0.2490
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [234], Train Loss: 0.4325, Val Loss: 0.2572, LR: 0.000000, best val loss was: 0.2490
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [235], Train Loss: 0.4475, Val Loss: 0.2605, LR: 0.000000, best val loss was: 0.2490
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [236], Train Loss: 0.4338, Val Loss: 0.2484, LR: 0.000000, best val loss was: 0.2484
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [237], Train Loss: 0.3909, Val Loss: 0.2457, LR: 0.000000, best val loss was: 0.2457
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [238], Train Loss: 0.3939, Val Loss: 0.2350, LR: 0.000000, best val loss was: 0.2350
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [239], Train Loss: 0.4139, Val Loss: 0.2463, LR: 0.000000, best val loss was: 0.2350
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [240], Train Loss: 0.3958, Val Loss: 0.2456, LR: 0.000000, best val loss was: 0.2350
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [241], Train Loss: 0.4089, Val Loss: 0.2358, LR: 0.000000, best val loss was: 0.2350
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [242], Train Loss: 0.3922, Val Loss: 0.2530, LR: 0.000000, best val loss was: 0.2350
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [243], Train Loss: 0.3900, Val Loss: 0.2542, LR: 0.000000, best val loss was: 0.2350
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [244], Train Loss: 0.4157, Val Loss: 0.2472, LR: 0.000000, best val loss was: 0.2350
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [245], Train Loss: 0.3951, Val Loss: 0.2437, LR: 0.000000, best val loss was: 0.2350
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [246], Train Loss: 0.3979, Val Loss: 0.2457, LR: 0.000000, best val loss was: 0.2350
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [247], Train Loss: 0.4233, Val Loss: 0.2440, LR: 0.000000, best val loss was: 0.2350
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [248], Train Loss: 0.3817, Val Loss: 0.2394, LR: 0.000000, best val loss was: 0.2350
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [249], Train Loss: 0.4167, Val Loss: 0.2482, LR: 0.000000, best val loss was: 0.2350
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [250], Train Loss: 0.3933, Val Loss: 0.2378, LR: 0.000000, best val loss was: 0.2350
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [251], Train Loss: 0.3877, Val Loss: 0.2455, LR: 0.000001, best val loss was: 0.2350
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [252], Train Loss: 0.4035, Val Loss: 0.2377, LR: 0.000001, best val loss was: 0.2350
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [253], Train Loss: 0.3834, Val Loss: 0.2241, LR: 0.000001, best val loss was: 0.2241
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [254], Train Loss: 0.4043, Val Loss: 0.2490, LR: 0.000001, best val loss was: 0.2241
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [255], Train Loss: 0.3669, Val Loss: 0.2474, LR: 0.000001, best val loss was: 0.2241
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [256], Train Loss: 0.4038, Val Loss: 0.2429, LR: 0.000001, best val loss was: 0.2241
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [257], Train Loss: 0.3822, Val Loss: 0.2478, LR: 0.000001, best val loss was: 0.2241
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [258], Train Loss: 0.4029, Val Loss: 0.2310, LR: 0.000001, best val loss was: 0.2241
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [259], Train Loss: 0.3936, Val Loss: 0.2421, LR: 0.000001, best val loss was: 0.2241
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [260], Train Loss: 0.4289, Val Loss: 0.2307, LR: 0.000001, best val loss was: 0.2241
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [261], Train Loss: 0.3851, Val Loss: 0.2476, LR: 0.000001, best val loss was: 0.2241
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [262], Train Loss: 0.4091, Val Loss: 0.2336, LR: 0.000001, best val loss was: 0.2241
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [263], Train Loss: 0.4252, Val Loss: 0.2387, LR: 0.000001, best val loss was: 0.2241
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [264], Train Loss: 0.4098, Val Loss: 0.2515, LR: 0.000001, best val loss was: 0.2241
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [265], Train Loss: 0.3782, Val Loss: 0.2349, LR: 0.000001, best val loss was: 0.2241
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [266], Train Loss: 0.3850, Val Loss: 0.2265, LR: 0.000001, best val loss was: 0.2241
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [267], Train Loss: 0.3918, Val Loss: 0.2305, LR: 0.000001, best val loss was: 0.2241
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [268], Train Loss: 0.3982, Val Loss: 0.2338, LR: 0.000001, best val loss was: 0.2241
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [269], Train Loss: 0.3911, Val Loss: 0.2287, LR: 0.000001, best val loss was: 0.2241
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [270], Train Loss: 0.3909, Val Loss: 0.2282, LR: 0.000001, best val loss was: 0.2241
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [271], Train Loss: 0.4090, Val Loss: 0.2202, LR: 0.000001, best val loss was: 0.2202
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [272], Train Loss: 0.3761, Val Loss: 0.2029, LR: 0.000001, best val loss was: 0.2029
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [273], Train Loss: 0.3615, Val Loss: 0.2261, LR: 0.000001, best val loss was: 0.2029
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [274], Train Loss: 0.4144, Val Loss: 0.2329, LR: 0.000001, best val loss was: 0.2029
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [275], Train Loss: 0.3553, Val Loss: 0.2262, LR: 0.000001, best val loss was: 0.2029
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [276], Train Loss: 0.3829, Val Loss: 0.2330, LR: 0.000001, best val loss was: 0.2029
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [277], Train Loss: 0.4178, Val Loss: 0.2285, LR: 0.000001, best val loss was: 0.2029
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [278], Train Loss: 0.3859, Val Loss: 0.2395, LR: 0.000001, best val loss was: 0.2029
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [279], Train Loss: 0.3739, Val Loss: 0.2284, LR: 0.000001, best val loss was: 0.2029
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [280], Train Loss: 0.3631, Val Loss: 0.2285, LR: 0.000001, best val loss was: 0.2029
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [281], Train Loss: 0.3923, Val Loss: 0.2285, LR: 0.000001, best val loss was: 0.2029
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [282], Train Loss: 0.3678, Val Loss: 0.2281, LR: 0.000001, best val loss was: 0.2029
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [283], Train Loss: 0.4031, Val Loss: 0.2251, LR: 0.000001, best val loss was: 0.2029
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [284], Train Loss: 0.3854, Val Loss: 0.2338, LR: 0.000001, best val loss was: 0.2029
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [285], Train Loss: 0.3777, Val Loss: 0.2372, LR: 0.000001, best val loss was: 0.2029
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [286], Train Loss: 0.3837, Val Loss: 0.2270, LR: 0.000001, best val loss was: 0.2029
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [287], Train Loss: 0.3842, Val Loss: 0.2159, LR: 0.000001, best val loss was: 0.2029
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [288], Train Loss: 0.4040, Val Loss: 0.2184, LR: 0.000001, best val loss was: 0.2029
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [289], Train Loss: 0.3904, Val Loss: 0.2301, LR: 0.000001, best val loss was: 0.2029
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [290], Train Loss: 0.3638, Val Loss: 0.2313, LR: 0.000001, best val loss was: 0.2029
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [291], Train Loss: 0.4064, Val Loss: 0.2383, LR: 0.000001, best val loss was: 0.2029
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [292], Train Loss: 0.3716, Val Loss: 0.2224, LR: 0.000001, best val loss was: 0.2029
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [293], Train Loss: 0.3857, Val Loss: 0.2148, LR: 0.000001, best val loss was: 0.2029
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [294], Train Loss: 0.3993, Val Loss: 0.2252, LR: 0.000001, best val loss was: 0.2029
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [295], Train Loss: 0.3940, Val Loss: 0.2094, LR: 0.000001, best val loss was: 0.2029
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [296], Train Loss: 0.3691, Val Loss: 0.2199, LR: 0.000001, best val loss was: 0.2029
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [297], Train Loss: 0.3646, Val Loss: 0.2223, LR: 0.000001, best val loss was: 0.2029
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [298], Train Loss: 0.3635, Val Loss: 0.2186, LR: 0.000001, best val loss was: 0.2029
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [299], Train Loss: 0.3990, Val Loss: 0.2116, LR: 0.000001, best val loss was: 0.2029
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [300], Train Loss: 0.3850, Val Loss: 0.2116, LR: 0.000001, best val loss was: 0.2029
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [301], Train Loss: 0.3591, Val Loss: 0.2165, LR: 0.000001, best val loss was: 0.2029
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [302], Train Loss: 0.3838, Val Loss: 0.2241, LR: 0.000001, best val loss was: 0.2029
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [303], Train Loss: 0.3844, Val Loss: 0.2149, LR: 0.000001, best val loss was: 0.2029
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [304], Train Loss: 0.3680, Val Loss: 0.2107, LR: 0.000001, best val loss was: 0.2029
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [305], Train Loss: 0.3969, Val Loss: 0.2260, LR: 0.000001, best val loss was: 0.2029
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [306], Train Loss: 0.3940, Val Loss: 0.2138, LR: 0.000001, best val loss was: 0.2029
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [307], Train Loss: 0.3510, Val Loss: 0.2148, LR: 0.000001, best val loss was: 0.2029
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [308], Train Loss: 0.3509, Val Loss: 0.2223, LR: 0.000001, best val loss was: 0.2029
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [309], Train Loss: 0.3594, Val Loss: 0.2200, LR: 0.000001, best val loss was: 0.2029
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [310], Train Loss: 0.3717, Val Loss: 0.2019, LR: 0.000001, best val loss was: 0.2019
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [311], Train Loss: 0.3803, Val Loss: 0.2059, LR: 0.000001, best val loss was: 0.2019
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [312], Train Loss: 0.3579, Val Loss: 0.2152, LR: 0.000001, best val loss was: 0.2019
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [313], Train Loss: 0.3592, Val Loss: 0.2041, LR: 0.000001, best val loss was: 0.2019
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [314], Train Loss: 0.3783, Val Loss: 0.2105, LR: 0.000001, best val loss was: 0.2019
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [315], Train Loss: 0.3831, Val Loss: 0.2097, LR: 0.000001, best val loss was: 0.2019
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [316], Train Loss: 0.3359, Val Loss: 0.2226, LR: 0.000001, best val loss was: 0.2019
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [317], Train Loss: 0.4372, Val Loss: 0.2047, LR: 0.000001, best val loss was: 0.2019
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [318], Train Loss: 0.3839, Val Loss: 0.2200, LR: 0.000001, best val loss was: 0.2019
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [319], Train Loss: 0.3541, Val Loss: 0.2012, LR: 0.000001, best val loss was: 0.2012
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [320], Train Loss: 0.3695, Val Loss: 0.2038, LR: 0.000001, best val loss was: 0.2012
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [321], Train Loss: 0.3623, Val Loss: 0.2080, LR: 0.000001, best val loss was: 0.2012
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [322], Train Loss: 0.4034, Val Loss: 0.2085, LR: 0.000001, best val loss was: 0.2012
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [323], Train Loss: 0.3820, Val Loss: 0.2132, LR: 0.000001, best val loss was: 0.2012
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [324], Train Loss: 0.3463, Val Loss: 0.2087, LR: 0.000001, best val loss was: 0.2012
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [325], Train Loss: 0.3851, Val Loss: 0.2120, LR: 0.000001, best val loss was: 0.2012
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [326], Train Loss: 0.3641, Val Loss: 0.2137, LR: 0.000001, best val loss was: 0.2012
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [327], Train Loss: 0.3619, Val Loss: 0.2033, LR: 0.000001, best val loss was: 0.2012
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [328], Train Loss: 0.3598, Val Loss: 0.2237, LR: 0.000001, best val loss was: 0.2012
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [329], Train Loss: 0.3633, Val Loss: 0.2009, LR: 0.000001, best val loss was: 0.2009
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [330], Train Loss: 0.3546, Val Loss: 0.2172, LR: 0.000001, best val loss was: 0.2009
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [331], Train Loss: 0.3689, Val Loss: 0.2138, LR: 0.000001, best val loss was: 0.2009
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [332], Train Loss: 0.3530, Val Loss: 0.2078, LR: 0.000001, best val loss was: 0.2009
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [333], Train Loss: 0.3813, Val Loss: 0.1991, LR: 0.000001, best val loss was: 0.1991
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [334], Train Loss: 0.3699, Val Loss: 0.2085, LR: 0.000001, best val loss was: 0.1991
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [335], Train Loss: 0.3994, Val Loss: 0.2090, LR: 0.000001, best val loss was: 0.1991
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [336], Train Loss: 0.3496, Val Loss: 0.2004, LR: 0.000001, best val loss was: 0.1991
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [337], Train Loss: 0.3953, Val Loss: 0.1956, LR: 0.000001, best val loss was: 0.1956
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [338], Train Loss: 0.3717, Val Loss: 0.2061, LR: 0.000001, best val loss was: 0.1956
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [339], Train Loss: 0.3492, Val Loss: 0.2002, LR: 0.000001, best val loss was: 0.1956
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [340], Train Loss: 0.3435, Val Loss: 0.1987, LR: 0.000001, best val loss was: 0.1956
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [341], Train Loss: 0.3728, Val Loss: 0.2032, LR: 0.000001, best val loss was: 0.1956
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [342], Train Loss: 0.3770, Val Loss: 0.2034, LR: 0.000001, best val loss was: 0.1956
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [343], Train Loss: 0.4069, Val Loss: 0.1960, LR: 0.000001, best val loss was: 0.1956
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [344], Train Loss: 0.3705, Val Loss: 0.2010, LR: 0.000001, best val loss was: 0.1956
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [345], Train Loss: 0.3313, Val Loss: 0.2049, LR: 0.000001, best val loss was: 0.1956
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [346], Train Loss: 0.3383, Val Loss: 0.2103, LR: 0.000001, best val loss was: 0.1956
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [347], Train Loss: 0.3456, Val Loss: 0.2053, LR: 0.000001, best val loss was: 0.1956
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [348], Train Loss: 0.3435, Val Loss: 0.2012, LR: 0.000001, best val loss was: 0.1956
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [349], Train Loss: 0.3351, Val Loss: 0.1949, LR: 0.000001, best val loss was: 0.1949
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [350], Train Loss: 0.3683, Val Loss: 0.2094, LR: 0.000001, best val loss was: 0.1949
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [351], Train Loss: 0.3210, Val Loss: 0.1993, LR: 0.000001, best val loss was: 0.1949
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [352], Train Loss: 0.3807, Val Loss: 0.1972, LR: 0.000001, best val loss was: 0.1949
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [353], Train Loss: 0.3503, Val Loss: 0.1969, LR: 0.000001, best val loss was: 0.1949
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [354], Train Loss: 0.3422, Val Loss: 0.1940, LR: 0.000001, best val loss was: 0.1940
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [355], Train Loss: 0.3600, Val Loss: 0.1977, LR: 0.000001, best val loss was: 0.1940
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [356], Train Loss: 0.3399, Val Loss: 0.1930, LR: 0.000001, best val loss was: 0.1930
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [357], Train Loss: 0.3849, Val Loss: 0.1998, LR: 0.000001, best val loss was: 0.1930
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [358], Train Loss: 0.3470, Val Loss: 0.1908, LR: 0.000001, best val loss was: 0.1908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [359], Train Loss: 0.3980, Val Loss: 0.2072, LR: 0.000001, best val loss was: 0.1908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [360], Train Loss: 0.3674, Val Loss: 0.2028, LR: 0.000001, best val loss was: 0.1908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [361], Train Loss: 0.3339, Val Loss: 0.1986, LR: 0.000001, best val loss was: 0.1908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [362], Train Loss: 0.3460, Val Loss: 0.1931, LR: 0.000001, best val loss was: 0.1908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [363], Train Loss: 0.3483, Val Loss: 0.1889, LR: 0.000001, best val loss was: 0.1889
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [364], Train Loss: 0.3917, Val Loss: 0.1857, LR: 0.000001, best val loss was: 0.1857
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [365], Train Loss: 0.3520, Val Loss: 0.1957, LR: 0.000001, best val loss was: 0.1857
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [366], Train Loss: 0.3592, Val Loss: 0.1899, LR: 0.000001, best val loss was: 0.1857
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [367], Train Loss: 0.3369, Val Loss: 0.1918, LR: 0.000001, best val loss was: 0.1857
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [368], Train Loss: 0.3768, Val Loss: 0.1992, LR: 0.000001, best val loss was: 0.1857
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [369], Train Loss: 0.3065, Val Loss: 0.2051, LR: 0.000001, best val loss was: 0.1857
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [370], Train Loss: 0.3711, Val Loss: 0.1864, LR: 0.000001, best val loss was: 0.1857
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [371], Train Loss: 0.3814, Val Loss: 0.1890, LR: 0.000001, best val loss was: 0.1857
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [372], Train Loss: 0.3295, Val Loss: 0.1872, LR: 0.000001, best val loss was: 0.1857
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [373], Train Loss: 0.3479, Val Loss: 0.2063, LR: 0.000001, best val loss was: 0.1857
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [374], Train Loss: 0.3621, Val Loss: 0.1847, LR: 0.000001, best val loss was: 0.1847
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [375], Train Loss: 0.3320, Val Loss: 0.1771, LR: 0.000001, best val loss was: 0.1771
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [376], Train Loss: 0.3266, Val Loss: 0.1878, LR: 0.000001, best val loss was: 0.1771
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [377], Train Loss: 0.3660, Val Loss: 0.2047, LR: 0.000001, best val loss was: 0.1771
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [378], Train Loss: 0.3452, Val Loss: 0.1836, LR: 0.000001, best val loss was: 0.1771
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [379], Train Loss: 0.3545, Val Loss: 0.1834, LR: 0.000001, best val loss was: 0.1771
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [380], Train Loss: 0.3543, Val Loss: 0.1866, LR: 0.000001, best val loss was: 0.1771
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [381], Train Loss: 0.3434, Val Loss: 0.1907, LR: 0.000001, best val loss was: 0.1771
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [382], Train Loss: 0.3571, Val Loss: 0.1958, LR: 0.000001, best val loss was: 0.1771
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [383], Train Loss: 0.3572, Val Loss: 0.1963, LR: 0.000001, best val loss was: 0.1771
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [384], Train Loss: 0.3732, Val Loss: 0.1853, LR: 0.000001, best val loss was: 0.1771
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [385], Train Loss: 0.3389, Val Loss: 0.1999, LR: 0.000001, best val loss was: 0.1771
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [386], Train Loss: 0.3483, Val Loss: 0.1916, LR: 0.000001, best val loss was: 0.1771
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [387], Train Loss: 0.3387, Val Loss: 0.1986, LR: 0.000001, best val loss was: 0.1771
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [388], Train Loss: 0.3572, Val Loss: 0.2066, LR: 0.000001, best val loss was: 0.1771
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [389], Train Loss: 0.3300, Val Loss: 0.1861, LR: 0.000001, best val loss was: 0.1771
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [390], Train Loss: 0.3294, Val Loss: 0.1942, LR: 0.000001, best val loss was: 0.1771
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [391], Train Loss: 0.4020, Val Loss: 0.1871, LR: 0.000001, best val loss was: 0.1771
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [392], Train Loss: 0.3383, Val Loss: 0.1865, LR: 0.000001, best val loss was: 0.1771
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [393], Train Loss: 0.3578, Val Loss: 0.1842, LR: 0.000001, best val loss was: 0.1771
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [394], Train Loss: 0.3649, Val Loss: 0.1838, LR: 0.000001, best val loss was: 0.1771
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [395], Train Loss: 0.3516, Val Loss: 0.1783, LR: 0.000001, best val loss was: 0.1771
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [396], Train Loss: 0.3906, Val Loss: 0.1769, LR: 0.000001, best val loss was: 0.1769
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [397], Train Loss: 0.3534, Val Loss: 0.1909, LR: 0.000001, best val loss was: 0.1769
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [398], Train Loss: 0.3733, Val Loss: 0.1846, LR: 0.000001, best val loss was: 0.1769
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [399], Train Loss: 0.3537, Val Loss: 0.1889, LR: 0.000001, best val loss was: 0.1769
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [400], Train Loss: 0.3327, Val Loss: 0.1938, LR: 0.000001, best val loss was: 0.1769
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [401], Train Loss: 0.3870, Val Loss: 0.1793, LR: 0.000001, best val loss was: 0.1769
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [402], Train Loss: 0.3397, Val Loss: 0.1756, LR: 0.000001, best val loss was: 0.1756
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [403], Train Loss: 0.3392, Val Loss: 0.1903, LR: 0.000001, best val loss was: 0.1756
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [404], Train Loss: 0.3690, Val Loss: 0.1875, LR: 0.000001, best val loss was: 0.1756
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [405], Train Loss: 0.3861, Val Loss: 0.1862, LR: 0.000001, best val loss was: 0.1756
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [406], Train Loss: 0.3633, Val Loss: 0.1878, LR: 0.000001, best val loss was: 0.1756
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [407], Train Loss: 0.3541, Val Loss: 0.1926, LR: 0.000001, best val loss was: 0.1756
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [408], Train Loss: 0.3402, Val Loss: 0.1833, LR: 0.000001, best val loss was: 0.1756
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [409], Train Loss: 0.3255, Val Loss: 0.1957, LR: 0.000001, best val loss was: 0.1756
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [410], Train Loss: 0.3555, Val Loss: 0.1800, LR: 0.000001, best val loss was: 0.1756
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [411], Train Loss: 0.3646, Val Loss: 0.1916, LR: 0.000001, best val loss was: 0.1756
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [412], Train Loss: 0.3292, Val Loss: 0.1825, LR: 0.000001, best val loss was: 0.1756
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [413], Train Loss: 0.3720, Val Loss: 0.1812, LR: 0.000001, best val loss was: 0.1756
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [414], Train Loss: 0.3355, Val Loss: 0.1695, LR: 0.000001, best val loss was: 0.1695
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [415], Train Loss: 0.3492, Val Loss: 0.1872, LR: 0.000001, best val loss was: 0.1695
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [416], Train Loss: 0.3410, Val Loss: 0.1898, LR: 0.000001, best val loss was: 0.1695
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [417], Train Loss: 0.3459, Val Loss: 0.1893, LR: 0.000001, best val loss was: 0.1695
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [418], Train Loss: 0.3576, Val Loss: 0.1935, LR: 0.000001, best val loss was: 0.1695
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [419], Train Loss: 0.3234, Val Loss: 0.1861, LR: 0.000001, best val loss was: 0.1695
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [420], Train Loss: 0.3169, Val Loss: 0.1882, LR: 0.000001, best val loss was: 0.1695
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [421], Train Loss: 0.3749, Val Loss: 0.1758, LR: 0.000001, best val loss was: 0.1695
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [422], Train Loss: 0.3423, Val Loss: 0.1782, LR: 0.000001, best val loss was: 0.1695
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [423], Train Loss: 0.2990, Val Loss: 0.1825, LR: 0.000001, best val loss was: 0.1695
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [424], Train Loss: 0.3418, Val Loss: 0.1853, LR: 0.000001, best val loss was: 0.1695
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [425], Train Loss: 0.3321, Val Loss: 0.1824, LR: 0.000001, best val loss was: 0.1695
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [426], Train Loss: 0.3768, Val Loss: 0.1792, LR: 0.000001, best val loss was: 0.1695
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [427], Train Loss: 0.3501, Val Loss: 0.1798, LR: 0.000001, best val loss was: 0.1695
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [428], Train Loss: 0.3182, Val Loss: 0.1852, LR: 0.000001, best val loss was: 0.1695
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [429], Train Loss: 0.3775, Val Loss: 0.1779, LR: 0.000001, best val loss was: 0.1695
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [430], Train Loss: 0.3296, Val Loss: 0.1769, LR: 0.000001, best val loss was: 0.1695
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [431], Train Loss: 0.3222, Val Loss: 0.1809, LR: 0.000001, best val loss was: 0.1695
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [432], Train Loss: 0.3139, Val Loss: 0.1860, LR: 0.000001, best val loss was: 0.1695
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [433], Train Loss: 0.3292, Val Loss: 0.1812, LR: 0.000001, best val loss was: 0.1695
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [434], Train Loss: 0.3381, Val Loss: 0.1828, LR: 0.000001, best val loss was: 0.1695
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [435], Train Loss: 0.3799, Val Loss: 0.1838, LR: 0.000001, best val loss was: 0.1695
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [436], Train Loss: 0.3024, Val Loss: 0.1824, LR: 0.000001, best val loss was: 0.1695
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [437], Train Loss: 0.3627, Val Loss: 0.1728, LR: 0.000001, best val loss was: 0.1695
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [438], Train Loss: 0.3374, Val Loss: 0.1753, LR: 0.000001, best val loss was: 0.1695
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [439], Train Loss: 0.3807, Val Loss: 0.1797, LR: 0.000001, best val loss was: 0.1695
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [440], Train Loss: 0.3427, Val Loss: 0.1889, LR: 0.000001, best val loss was: 0.1695
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [441], Train Loss: 0.3139, Val Loss: 0.1779, LR: 0.000001, best val loss was: 0.1695
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [442], Train Loss: 0.3454, Val Loss: 0.1869, LR: 0.000001, best val loss was: 0.1695
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [443], Train Loss: 0.3174, Val Loss: 0.1772, LR: 0.000001, best val loss was: 0.1695
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [444], Train Loss: 0.3293, Val Loss: 0.1680, LR: 0.000001, best val loss was: 0.1680
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [445], Train Loss: 0.3267, Val Loss: 0.1759, LR: 0.000001, best val loss was: 0.1680
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [446], Train Loss: 0.3731, Val Loss: 0.1889, LR: 0.000001, best val loss was: 0.1680
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [447], Train Loss: 0.3493, Val Loss: 0.1770, LR: 0.000001, best val loss was: 0.1680
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [448], Train Loss: 0.3217, Val Loss: 0.1777, LR: 0.000001, best val loss was: 0.1680
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [449], Train Loss: 0.3550, Val Loss: 0.1732, LR: 0.000001, best val loss was: 0.1680
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [450], Train Loss: 0.3213, Val Loss: 0.1878, LR: 0.000001, best val loss was: 0.1680
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [451], Train Loss: 0.3436, Val Loss: 0.1796, LR: 0.000001, best val loss was: 0.1680
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [452], Train Loss: 0.3404, Val Loss: 0.1741, LR: 0.000001, best val loss was: 0.1680
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [453], Train Loss: 0.3748, Val Loss: 0.1792, LR: 0.000001, best val loss was: 0.1680
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [454], Train Loss: 0.3120, Val Loss: 0.1766, LR: 0.000001, best val loss was: 0.1680
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [455], Train Loss: 0.3401, Val Loss: 0.1709, LR: 0.000001, best val loss was: 0.1680
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [456], Train Loss: 0.3213, Val Loss: 0.1765, LR: 0.000001, best val loss was: 0.1680
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [457], Train Loss: 0.3059, Val Loss: 0.1758, LR: 0.000001, best val loss was: 0.1680
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [458], Train Loss: 0.3516, Val Loss: 0.1772, LR: 0.000001, best val loss was: 0.1680
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [459], Train Loss: 0.3146, Val Loss: 0.1699, LR: 0.000001, best val loss was: 0.1680
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [460], Train Loss: 0.3443, Val Loss: 0.1737, LR: 0.000001, best val loss was: 0.1680
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [461], Train Loss: 0.3460, Val Loss: 0.1777, LR: 0.000001, best val loss was: 0.1680
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [462], Train Loss: 0.3237, Val Loss: 0.1773, LR: 0.000001, best val loss was: 0.1680
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [463], Train Loss: 0.3153, Val Loss: 0.1742, LR: 0.000001, best val loss was: 0.1680
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [464], Train Loss: 0.3456, Val Loss: 0.1726, LR: 0.000001, best val loss was: 0.1680
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [465], Train Loss: 0.3233, Val Loss: 0.1744, LR: 0.000001, best val loss was: 0.1680
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [466], Train Loss: 0.3397, Val Loss: 0.1762, LR: 0.000001, best val loss was: 0.1680
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [467], Train Loss: 0.3302, Val Loss: 0.1843, LR: 0.000001, best val loss was: 0.1680
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [468], Train Loss: 0.3290, Val Loss: 0.1808, LR: 0.000001, best val loss was: 0.1680
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [469], Train Loss: 0.3187, Val Loss: 0.1740, LR: 0.000001, best val loss was: 0.1680
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [470], Train Loss: 0.3384, Val Loss: 0.1799, LR: 0.000001, best val loss was: 0.1680
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [471], Train Loss: 0.3279, Val Loss: 0.1723, LR: 0.000001, best val loss was: 0.1680
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [472], Train Loss: 0.3194, Val Loss: 0.1787, LR: 0.000001, best val loss was: 0.1680
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [473], Train Loss: 0.3339, Val Loss: 0.1710, LR: 0.000001, best val loss was: 0.1680
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [474], Train Loss: 0.3358, Val Loss: 0.1840, LR: 0.000001, best val loss was: 0.1680
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [475], Train Loss: 0.3068, Val Loss: 0.1690, LR: 0.000001, best val loss was: 0.1680
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [476], Train Loss: 0.3502, Val Loss: 0.1793, LR: 0.000001, best val loss was: 0.1680
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [477], Train Loss: 0.3202, Val Loss: 0.1719, LR: 0.000001, best val loss was: 0.1680
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [478], Train Loss: 0.3318, Val Loss: 0.1742, LR: 0.000001, best val loss was: 0.1680
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [479], Train Loss: 0.3335, Val Loss: 0.1776, LR: 0.000001, best val loss was: 0.1680
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [480], Train Loss: 0.3422, Val Loss: 0.1700, LR: 0.000001, best val loss was: 0.1680
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [481], Train Loss: 0.3413, Val Loss: 0.1726, LR: 0.000001, best val loss was: 0.1680
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [482], Train Loss: 0.3360, Val Loss: 0.1696, LR: 0.000001, best val loss was: 0.1680
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [483], Train Loss: 0.3342, Val Loss: 0.1676, LR: 0.000001, best val loss was: 0.1676
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [484], Train Loss: 0.3675, Val Loss: 0.1688, LR: 0.000001, best val loss was: 0.1676
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [485], Train Loss: 0.3245, Val Loss: 0.1721, LR: 0.000001, best val loss was: 0.1676
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [486], Train Loss: 0.3208, Val Loss: 0.1629, LR: 0.000001, best val loss was: 0.1629
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [487], Train Loss: 0.3206, Val Loss: 0.1726, LR: 0.000001, best val loss was: 0.1629
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [488], Train Loss: 0.3306, Val Loss: 0.1643, LR: 0.000001, best val loss was: 0.1629
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [489], Train Loss: 0.3254, Val Loss: 0.1676, LR: 0.000001, best val loss was: 0.1629
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [490], Train Loss: 0.3464, Val Loss: 0.1738, LR: 0.000001, best val loss was: 0.1629
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [491], Train Loss: 0.3601, Val Loss: 0.1778, LR: 0.000001, best val loss was: 0.1629
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [492], Train Loss: 0.3384, Val Loss: 0.1660, LR: 0.000001, best val loss was: 0.1629
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [493], Train Loss: 0.3278, Val Loss: 0.1736, LR: 0.000001, best val loss was: 0.1629
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [494], Train Loss: 0.3086, Val Loss: 0.1764, LR: 0.000001, best val loss was: 0.1629
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [495], Train Loss: 0.3434, Val Loss: 0.1706, LR: 0.000001, best val loss was: 0.1629
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [496], Train Loss: 0.3184, Val Loss: 0.1708, LR: 0.000001, best val loss was: 0.1629
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [497], Train Loss: 0.3460, Val Loss: 0.1700, LR: 0.000001, best val loss was: 0.1629
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [498], Train Loss: 0.3613, Val Loss: 0.1732, LR: 0.000001, best val loss was: 0.1629
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [499], Train Loss: 0.3631, Val Loss: 0.1615, LR: 0.000001, best val loss was: 0.1615
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [500], Train Loss: 0.3344, Val Loss: 0.1666, LR: 0.000001, best val loss was: 0.1615
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [501], Train Loss: 0.3468, Val Loss: 0.1743, LR: 0.000001, best val loss was: 0.1615
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [502], Train Loss: 0.3330, Val Loss: 0.1659, LR: 0.000001, best val loss was: 0.1615
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [503], Train Loss: 0.3133, Val Loss: 0.1652, LR: 0.000001, best val loss was: 0.1615
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [504], Train Loss: 0.3466, Val Loss: 0.1621, LR: 0.000001, best val loss was: 0.1615
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [505], Train Loss: 0.3615, Val Loss: 0.1630, LR: 0.000001, best val loss was: 0.1615
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [506], Train Loss: 0.3504, Val Loss: 0.1636, LR: 0.000001, best val loss was: 0.1615
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [507], Train Loss: 0.3469, Val Loss: 0.1668, LR: 0.000001, best val loss was: 0.1615
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [508], Train Loss: 0.3391, Val Loss: 0.1706, LR: 0.000001, best val loss was: 0.1615
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [509], Train Loss: 0.3569, Val Loss: 0.1742, LR: 0.000001, best val loss was: 0.1615
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [510], Train Loss: 0.3432, Val Loss: 0.1677, LR: 0.000001, best val loss was: 0.1615
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [511], Train Loss: 0.3472, Val Loss: 0.1646, LR: 0.000001, best val loss was: 0.1615
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [512], Train Loss: 0.3425, Val Loss: 0.1593, LR: 0.000001, best val loss was: 0.1593
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [513], Train Loss: 0.3159, Val Loss: 0.1625, LR: 0.000001, best val loss was: 0.1593
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [514], Train Loss: 0.3439, Val Loss: 0.1649, LR: 0.000001, best val loss was: 0.1593
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [515], Train Loss: 0.3253, Val Loss: 0.1669, LR: 0.000001, best val loss was: 0.1593
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [516], Train Loss: 0.3363, Val Loss: 0.1689, LR: 0.000001, best val loss was: 0.1593
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [517], Train Loss: 0.3216, Val Loss: 0.1589, LR: 0.000001, best val loss was: 0.1589
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [518], Train Loss: 0.3093, Val Loss: 0.1619, LR: 0.000001, best val loss was: 0.1589
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [519], Train Loss: 0.3334, Val Loss: 0.1653, LR: 0.000001, best val loss was: 0.1589
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [520], Train Loss: 0.3031, Val Loss: 0.1681, LR: 0.000001, best val loss was: 0.1589
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [521], Train Loss: 0.3161, Val Loss: 0.1658, LR: 0.000001, best val loss was: 0.1589
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [522], Train Loss: 0.3072, Val Loss: 0.1608, LR: 0.000001, best val loss was: 0.1589
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [523], Train Loss: 0.3330, Val Loss: 0.1622, LR: 0.000001, best val loss was: 0.1589
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [524], Train Loss: 0.2961, Val Loss: 0.1737, LR: 0.000001, best val loss was: 0.1589
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [525], Train Loss: 0.3147, Val Loss: 0.1656, LR: 0.000001, best val loss was: 0.1589
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [526], Train Loss: 0.3143, Val Loss: 0.1550, LR: 0.000001, best val loss was: 0.1550
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [527], Train Loss: 0.3516, Val Loss: 0.1624, LR: 0.000001, best val loss was: 0.1550
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [528], Train Loss: 0.2944, Val Loss: 0.1754, LR: 0.000001, best val loss was: 0.1550
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [529], Train Loss: 0.3362, Val Loss: 0.1685, LR: 0.000001, best val loss was: 0.1550
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [530], Train Loss: 0.3155, Val Loss: 0.1736, LR: 0.000001, best val loss was: 0.1550
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [531], Train Loss: 0.3147, Val Loss: 0.1684, LR: 0.000001, best val loss was: 0.1550
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [532], Train Loss: 0.3351, Val Loss: 0.1551, LR: 0.000001, best val loss was: 0.1550
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [533], Train Loss: 0.3124, Val Loss: 0.1688, LR: 0.000001, best val loss was: 0.1550
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [534], Train Loss: 0.2881, Val Loss: 0.1728, LR: 0.000001, best val loss was: 0.1550
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [535], Train Loss: 0.3248, Val Loss: 0.1634, LR: 0.000001, best val loss was: 0.1550
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [536], Train Loss: 0.3105, Val Loss: 0.1623, LR: 0.000001, best val loss was: 0.1550
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [537], Train Loss: 0.3357, Val Loss: 0.1525, LR: 0.000001, best val loss was: 0.1525
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [538], Train Loss: 0.3282, Val Loss: 0.1677, LR: 0.000001, best val loss was: 0.1525
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [539], Train Loss: 0.3035, Val Loss: 0.1679, LR: 0.000001, best val loss was: 0.1525
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [540], Train Loss: 0.3523, Val Loss: 0.1622, LR: 0.000001, best val loss was: 0.1525
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [541], Train Loss: 0.3064, Val Loss: 0.1616, LR: 0.000001, best val loss was: 0.1525
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [542], Train Loss: 0.3139, Val Loss: 0.1714, LR: 0.000001, best val loss was: 0.1525
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [543], Train Loss: 0.3179, Val Loss: 0.1579, LR: 0.000001, best val loss was: 0.1525
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [544], Train Loss: 0.3345, Val Loss: 0.1647, LR: 0.000001, best val loss was: 0.1525
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [545], Train Loss: 0.3328, Val Loss: 0.1650, LR: 0.000001, best val loss was: 0.1525
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [546], Train Loss: 0.3187, Val Loss: 0.1662, LR: 0.000001, best val loss was: 0.1525
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [547], Train Loss: 0.3031, Val Loss: 0.1652, LR: 0.000001, best val loss was: 0.1525
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [548], Train Loss: 0.3421, Val Loss: 0.1730, LR: 0.000001, best val loss was: 0.1525
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [549], Train Loss: 0.3135, Val Loss: 0.1628, LR: 0.000001, best val loss was: 0.1525
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [550], Train Loss: 0.3118, Val Loss: 0.1644, LR: 0.000001, best val loss was: 0.1525
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [551], Train Loss: 0.3329, Val Loss: 0.1524, LR: 0.000001, best val loss was: 0.1524
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [552], Train Loss: 0.3446, Val Loss: 0.1476, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [553], Train Loss: 0.3053, Val Loss: 0.1541, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [554], Train Loss: 0.3068, Val Loss: 0.1543, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [555], Train Loss: 0.2908, Val Loss: 0.1606, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [556], Train Loss: 0.3298, Val Loss: 0.1647, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [557], Train Loss: 0.3251, Val Loss: 0.1668, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [558], Train Loss: 0.2969, Val Loss: 0.1612, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [559], Train Loss: 0.3594, Val Loss: 0.1657, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [560], Train Loss: 0.2931, Val Loss: 0.1577, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [561], Train Loss: 0.3098, Val Loss: 0.1560, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [562], Train Loss: 0.3277, Val Loss: 0.1623, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [563], Train Loss: 0.3161, Val Loss: 0.1590, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [564], Train Loss: 0.3393, Val Loss: 0.1560, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [565], Train Loss: 0.2965, Val Loss: 0.1642, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [566], Train Loss: 0.3108, Val Loss: 0.1537, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [567], Train Loss: 0.3006, Val Loss: 0.1596, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [568], Train Loss: 0.3134, Val Loss: 0.1626, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [569], Train Loss: 0.3654, Val Loss: 0.1638, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [570], Train Loss: 0.2953, Val Loss: 0.1617, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [571], Train Loss: 0.3112, Val Loss: 0.1578, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [572], Train Loss: 0.3161, Val Loss: 0.1552, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [573], Train Loss: 0.3087, Val Loss: 0.1558, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [574], Train Loss: 0.3195, Val Loss: 0.1586, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [575], Train Loss: 0.2871, Val Loss: 0.1566, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [576], Train Loss: 0.3122, Val Loss: 0.1558, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [577], Train Loss: 0.3341, Val Loss: 0.1655, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [578], Train Loss: 0.3338, Val Loss: 0.1575, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [579], Train Loss: 0.3316, Val Loss: 0.1549, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [580], Train Loss: 0.3699, Val Loss: 0.1632, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [581], Train Loss: 0.3437, Val Loss: 0.1544, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [582], Train Loss: 0.2947, Val Loss: 0.1579, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [583], Train Loss: 0.3265, Val Loss: 0.1523, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [584], Train Loss: 0.3063, Val Loss: 0.1516, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [585], Train Loss: 0.2997, Val Loss: 0.1596, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [586], Train Loss: 0.3306, Val Loss: 0.1552, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [587], Train Loss: 0.2914, Val Loss: 0.1564, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [588], Train Loss: 0.3198, Val Loss: 0.1588, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [589], Train Loss: 0.3385, Val Loss: 0.1609, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [590], Train Loss: 0.3050, Val Loss: 0.1505, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [591], Train Loss: 0.3155, Val Loss: 0.1536, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [592], Train Loss: 0.3040, Val Loss: 0.1566, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [593], Train Loss: 0.3213, Val Loss: 0.1528, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [594], Train Loss: 0.3241, Val Loss: 0.1599, LR: 0.000001, best val loss was: 0.1476
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [595], Train Loss: 0.2871, Val Loss: 0.1474, LR: 0.000001, best val loss was: 0.1474
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [596], Train Loss: 0.3183, Val Loss: 0.1608, LR: 0.000001, best val loss was: 0.1474
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [597], Train Loss: 0.2958, Val Loss: 0.1573, LR: 0.000001, best val loss was: 0.1474
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [598], Train Loss: 0.3188, Val Loss: 0.1562, LR: 0.000001, best val loss was: 0.1474
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [599], Train Loss: 0.3011, Val Loss: 0.1560, LR: 0.000001, best val loss was: 0.1474
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [600], Train Loss: 0.2878, Val Loss: 0.1565, LR: 0.000001, best val loss was: 0.1474
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [601], Train Loss: 0.3495, Val Loss: 0.1544, LR: 0.000001, best val loss was: 0.1474
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [602], Train Loss: 0.2949, Val Loss: 0.1641, LR: 0.000001, best val loss was: 0.1474
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [603], Train Loss: 0.3072, Val Loss: 0.1613, LR: 0.000001, best val loss was: 0.1474
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [604], Train Loss: 0.3166, Val Loss: 0.1535, LR: 0.000001, best val loss was: 0.1474
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [605], Train Loss: 0.3237, Val Loss: 0.1494, LR: 0.000001, best val loss was: 0.1474
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [606], Train Loss: 0.3014, Val Loss: 0.1448, LR: 0.000001, best val loss was: 0.1448
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [607], Train Loss: 0.3040, Val Loss: 0.1524, LR: 0.000001, best val loss was: 0.1448
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [608], Train Loss: 0.3096, Val Loss: 0.1586, LR: 0.000001, best val loss was: 0.1448
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [609], Train Loss: 0.3268, Val Loss: 0.1534, LR: 0.000001, best val loss was: 0.1448
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [610], Train Loss: 0.3312, Val Loss: 0.1566, LR: 0.000001, best val loss was: 0.1448
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [611], Train Loss: 0.3050, Val Loss: 0.1505, LR: 0.000001, best val loss was: 0.1448
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [612], Train Loss: 0.3176, Val Loss: 0.1581, LR: 0.000001, best val loss was: 0.1448
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [613], Train Loss: 0.2796, Val Loss: 0.1476, LR: 0.000001, best val loss was: 0.1448
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [614], Train Loss: 0.3219, Val Loss: 0.1503, LR: 0.000001, best val loss was: 0.1448
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [615], Train Loss: 0.2972, Val Loss: 0.1492, LR: 0.000001, best val loss was: 0.1448
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [616], Train Loss: 0.3016, Val Loss: 0.1608, LR: 0.000001, best val loss was: 0.1448
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [617], Train Loss: 0.3243, Val Loss: 0.1497, LR: 0.000001, best val loss was: 0.1448
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [618], Train Loss: 0.2925, Val Loss: 0.1569, LR: 0.000001, best val loss was: 0.1448
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [619], Train Loss: 0.3072, Val Loss: 0.1533, LR: 0.000001, best val loss was: 0.1448
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [620], Train Loss: 0.3314, Val Loss: 0.1508, LR: 0.000001, best val loss was: 0.1448
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [621], Train Loss: 0.3119, Val Loss: 0.1466, LR: 0.000001, best val loss was: 0.1448
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [622], Train Loss: 0.3041, Val Loss: 0.1554, LR: 0.000001, best val loss was: 0.1448
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [623], Train Loss: 0.3155, Val Loss: 0.1506, LR: 0.000001, best val loss was: 0.1448
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [624], Train Loss: 0.3435, Val Loss: 0.1499, LR: 0.000001, best val loss was: 0.1448
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [625], Train Loss: 0.3313, Val Loss: 0.1574, LR: 0.000001, best val loss was: 0.1448
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [626], Train Loss: 0.2768, Val Loss: 0.1437, LR: 0.000001, best val loss was: 0.1437
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [627], Train Loss: 0.3152, Val Loss: 0.1508, LR: 0.000001, best val loss was: 0.1437
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [628], Train Loss: 0.3161, Val Loss: 0.1462, LR: 0.000001, best val loss was: 0.1437
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [629], Train Loss: 0.3254, Val Loss: 0.1444, LR: 0.000001, best val loss was: 0.1437
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [630], Train Loss: 0.3263, Val Loss: 0.1557, LR: 0.000001, best val loss was: 0.1437
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [631], Train Loss: 0.2973, Val Loss: 0.1447, LR: 0.000001, best val loss was: 0.1437
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [632], Train Loss: 0.3323, Val Loss: 0.1488, LR: 0.000001, best val loss was: 0.1437
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [633], Train Loss: 0.3238, Val Loss: 0.1547, LR: 0.000001, best val loss was: 0.1437
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [634], Train Loss: 0.3260, Val Loss: 0.1571, LR: 0.000001, best val loss was: 0.1437
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [635], Train Loss: 0.2812, Val Loss: 0.1491, LR: 0.000001, best val loss was: 0.1437
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [636], Train Loss: 0.3109, Val Loss: 0.1477, LR: 0.000001, best val loss was: 0.1437
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [637], Train Loss: 0.2783, Val Loss: 0.1491, LR: 0.000001, best val loss was: 0.1437
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [638], Train Loss: 0.3123, Val Loss: 0.1575, LR: 0.000001, best val loss was: 0.1437
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [639], Train Loss: 0.2979, Val Loss: 0.1540, LR: 0.000001, best val loss was: 0.1437
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [640], Train Loss: 0.3283, Val Loss: 0.1506, LR: 0.000001, best val loss was: 0.1437
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [641], Train Loss: 0.3264, Val Loss: 0.1497, LR: 0.000001, best val loss was: 0.1437
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [642], Train Loss: 0.3077, Val Loss: 0.1379, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [643], Train Loss: 0.2869, Val Loss: 0.1485, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [644], Train Loss: 0.3062, Val Loss: 0.1565, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [645], Train Loss: 0.2836, Val Loss: 0.1416, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [646], Train Loss: 0.2899, Val Loss: 0.1548, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [647], Train Loss: 0.3031, Val Loss: 0.1501, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [648], Train Loss: 0.2725, Val Loss: 0.1477, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [649], Train Loss: 0.3080, Val Loss: 0.1440, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [650], Train Loss: 0.3237, Val Loss: 0.1563, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [651], Train Loss: 0.3213, Val Loss: 0.1524, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [652], Train Loss: 0.2963, Val Loss: 0.1567, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [653], Train Loss: 0.3057, Val Loss: 0.1538, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [654], Train Loss: 0.3118, Val Loss: 0.1444, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [655], Train Loss: 0.3186, Val Loss: 0.1547, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [656], Train Loss: 0.3178, Val Loss: 0.1489, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [657], Train Loss: 0.3009, Val Loss: 0.1444, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [658], Train Loss: 0.2865, Val Loss: 0.1511, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [659], Train Loss: 0.3024, Val Loss: 0.1496, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [660], Train Loss: 0.2984, Val Loss: 0.1454, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [661], Train Loss: 0.3091, Val Loss: 0.1447, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [662], Train Loss: 0.3237, Val Loss: 0.1483, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [663], Train Loss: 0.2922, Val Loss: 0.1491, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [664], Train Loss: 0.3136, Val Loss: 0.1472, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [665], Train Loss: 0.2971, Val Loss: 0.1445, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [666], Train Loss: 0.3002, Val Loss: 0.1497, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [667], Train Loss: 0.3341, Val Loss: 0.1455, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [668], Train Loss: 0.3412, Val Loss: 0.1554, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [669], Train Loss: 0.3040, Val Loss: 0.1486, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [670], Train Loss: 0.2853, Val Loss: 0.1548, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [671], Train Loss: 0.3275, Val Loss: 0.1437, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [672], Train Loss: 0.2896, Val Loss: 0.1465, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [673], Train Loss: 0.3069, Val Loss: 0.1419, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [674], Train Loss: 0.3001, Val Loss: 0.1463, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [675], Train Loss: 0.3161, Val Loss: 0.1409, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [676], Train Loss: 0.3262, Val Loss: 0.1463, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [677], Train Loss: 0.3083, Val Loss: 0.1459, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [678], Train Loss: 0.3184, Val Loss: 0.1428, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [679], Train Loss: 0.3163, Val Loss: 0.1414, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [680], Train Loss: 0.3025, Val Loss: 0.1500, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [681], Train Loss: 0.3289, Val Loss: 0.1406, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [682], Train Loss: 0.2804, Val Loss: 0.1413, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [683], Train Loss: 0.3137, Val Loss: 0.1422, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [684], Train Loss: 0.3098, Val Loss: 0.1456, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [685], Train Loss: 0.2975, Val Loss: 0.1460, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [686], Train Loss: 0.2957, Val Loss: 0.1497, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [687], Train Loss: 0.2817, Val Loss: 0.1578, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [688], Train Loss: 0.2999, Val Loss: 0.1409, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [689], Train Loss: 0.2894, Val Loss: 0.1498, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [690], Train Loss: 0.3128, Val Loss: 0.1411, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [691], Train Loss: 0.3225, Val Loss: 0.1492, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [692], Train Loss: 0.2853, Val Loss: 0.1523, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [693], Train Loss: 0.3076, Val Loss: 0.1502, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [694], Train Loss: 0.2860, Val Loss: 0.1417, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [695], Train Loss: 0.3163, Val Loss: 0.1464, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [696], Train Loss: 0.2891, Val Loss: 0.1467, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [697], Train Loss: 0.2960, Val Loss: 0.1496, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [698], Train Loss: 0.2762, Val Loss: 0.1425, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [699], Train Loss: 0.3082, Val Loss: 0.1432, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [700], Train Loss: 0.3177, Val Loss: 0.1461, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [701], Train Loss: 0.3005, Val Loss: 0.1486, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [702], Train Loss: 0.3322, Val Loss: 0.1419, LR: 0.000001, best val loss was: 0.1379
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [703], Train Loss: 0.3192, Val Loss: 0.1366, LR: 0.000001, best val loss was: 0.1366
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [704], Train Loss: 0.2767, Val Loss: 0.1431, LR: 0.000001, best val loss was: 0.1366
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [705], Train Loss: 0.3090, Val Loss: 0.1383, LR: 0.000001, best val loss was: 0.1366
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [706], Train Loss: 0.3033, Val Loss: 0.1388, LR: 0.000001, best val loss was: 0.1366
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [707], Train Loss: 0.2769, Val Loss: 0.1425, LR: 0.000001, best val loss was: 0.1366
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [708], Train Loss: 0.3128, Val Loss: 0.1452, LR: 0.000001, best val loss was: 0.1366
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [709], Train Loss: 0.2791, Val Loss: 0.1424, LR: 0.000001, best val loss was: 0.1366
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [710], Train Loss: 0.2690, Val Loss: 0.1451, LR: 0.000001, best val loss was: 0.1366
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [711], Train Loss: 0.3225, Val Loss: 0.1417, LR: 0.000001, best val loss was: 0.1366
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [712], Train Loss: 0.3079, Val Loss: 0.1430, LR: 0.000001, best val loss was: 0.1366
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [713], Train Loss: 0.2754, Val Loss: 0.1459, LR: 0.000001, best val loss was: 0.1366
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [714], Train Loss: 0.3029, Val Loss: 0.1412, LR: 0.000001, best val loss was: 0.1366
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [715], Train Loss: 0.3098, Val Loss: 0.1465, LR: 0.000001, best val loss was: 0.1366
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [716], Train Loss: 0.2802, Val Loss: 0.1443, LR: 0.000001, best val loss was: 0.1366
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [717], Train Loss: 0.2860, Val Loss: 0.1425, LR: 0.000001, best val loss was: 0.1366
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [718], Train Loss: 0.2873, Val Loss: 0.1368, LR: 0.000001, best val loss was: 0.1366
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [719], Train Loss: 0.2896, Val Loss: 0.1423, LR: 0.000001, best val loss was: 0.1366
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [720], Train Loss: 0.3119, Val Loss: 0.1308, LR: 0.000001, best val loss was: 0.1308
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [721], Train Loss: 0.2963, Val Loss: 0.1491, LR: 0.000001, best val loss was: 0.1308
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [722], Train Loss: 0.2800, Val Loss: 0.1414, LR: 0.000001, best val loss was: 0.1308
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [723], Train Loss: 0.2929, Val Loss: 0.1359, LR: 0.000001, best val loss was: 0.1308
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [724], Train Loss: 0.2940, Val Loss: 0.1380, LR: 0.000001, best val loss was: 0.1308
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [725], Train Loss: 0.2792, Val Loss: 0.1496, LR: 0.000001, best val loss was: 0.1308
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [726], Train Loss: 0.2779, Val Loss: 0.1434, LR: 0.000001, best val loss was: 0.1308
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [727], Train Loss: 0.3343, Val Loss: 0.1399, LR: 0.000001, best val loss was: 0.1308
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [728], Train Loss: 0.2908, Val Loss: 0.1365, LR: 0.000001, best val loss was: 0.1308
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [729], Train Loss: 0.3217, Val Loss: 0.1357, LR: 0.000001, best val loss was: 0.1308
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [730], Train Loss: 0.2979, Val Loss: 0.1415, LR: 0.000001, best val loss was: 0.1308
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [731], Train Loss: 0.3230, Val Loss: 0.1398, LR: 0.000001, best val loss was: 0.1308
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [732], Train Loss: 0.2969, Val Loss: 0.1372, LR: 0.000001, best val loss was: 0.1308
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [733], Train Loss: 0.2920, Val Loss: 0.1348, LR: 0.000001, best val loss was: 0.1308
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [734], Train Loss: 0.2865, Val Loss: 0.1305, LR: 0.000001, best val loss was: 0.1305
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [735], Train Loss: 0.3040, Val Loss: 0.1402, LR: 0.000001, best val loss was: 0.1305
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [736], Train Loss: 0.3189, Val Loss: 0.1328, LR: 0.000001, best val loss was: 0.1305
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [737], Train Loss: 0.3023, Val Loss: 0.1325, LR: 0.000001, best val loss was: 0.1305
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [738], Train Loss: 0.3036, Val Loss: 0.1352, LR: 0.000001, best val loss was: 0.1305
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [739], Train Loss: 0.3217, Val Loss: 0.1438, LR: 0.000001, best val loss was: 0.1305
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [740], Train Loss: 0.3194, Val Loss: 0.1452, LR: 0.000001, best val loss was: 0.1305
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [741], Train Loss: 0.3080, Val Loss: 0.1428, LR: 0.000001, best val loss was: 0.1305
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [742], Train Loss: 0.3176, Val Loss: 0.1389, LR: 0.000001, best val loss was: 0.1305
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [743], Train Loss: 0.3107, Val Loss: 0.1312, LR: 0.000001, best val loss was: 0.1305
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [744], Train Loss: 0.3189, Val Loss: 0.1367, LR: 0.000001, best val loss was: 0.1305
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [745], Train Loss: 0.3068, Val Loss: 0.1378, LR: 0.000001, best val loss was: 0.1305
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [746], Train Loss: 0.2896, Val Loss: 0.1381, LR: 0.000001, best val loss was: 0.1305
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [747], Train Loss: 0.2794, Val Loss: 0.1338, LR: 0.000001, best val loss was: 0.1305
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [748], Train Loss: 0.3141, Val Loss: 0.1348, LR: 0.000001, best val loss was: 0.1305
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [749], Train Loss: 0.2935, Val Loss: 0.1389, LR: 0.000001, best val loss was: 0.1305
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [750], Train Loss: 0.3053, Val Loss: 0.1301, LR: 0.000002, best val loss was: 0.1301
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [751], Train Loss: 0.3069, Val Loss: 0.1396, LR: 0.000002, best val loss was: 0.1301
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [752], Train Loss: 0.2939, Val Loss: 0.1390, LR: 0.000002, best val loss was: 0.1301
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [753], Train Loss: 0.2955, Val Loss: 0.1483, LR: 0.000002, best val loss was: 0.1301
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [754], Train Loss: 0.3087, Val Loss: 0.1399, LR: 0.000002, best val loss was: 0.1301
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [755], Train Loss: 0.3239, Val Loss: 0.1358, LR: 0.000002, best val loss was: 0.1301
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [756], Train Loss: 0.2978, Val Loss: 0.1452, LR: 0.000002, best val loss was: 0.1301
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [757], Train Loss: 0.2970, Val Loss: 0.1403, LR: 0.000002, best val loss was: 0.1301
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [758], Train Loss: 0.3055, Val Loss: 0.1346, LR: 0.000002, best val loss was: 0.1301
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [759], Train Loss: 0.2894, Val Loss: 0.1402, LR: 0.000002, best val loss was: 0.1301
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [760], Train Loss: 0.3195, Val Loss: 0.1435, LR: 0.000002, best val loss was: 0.1301
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [761], Train Loss: 0.3159, Val Loss: 0.1370, LR: 0.000002, best val loss was: 0.1301
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [762], Train Loss: 0.3014, Val Loss: 0.1281, LR: 0.000002, best val loss was: 0.1281
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [763], Train Loss: 0.2941, Val Loss: 0.1339, LR: 0.000002, best val loss was: 0.1281
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [764], Train Loss: 0.3245, Val Loss: 0.1363, LR: 0.000002, best val loss was: 0.1281
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [765], Train Loss: 0.2918, Val Loss: 0.1321, LR: 0.000002, best val loss was: 0.1281
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [766], Train Loss: 0.2629, Val Loss: 0.1321, LR: 0.000002, best val loss was: 0.1281
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [767], Train Loss: 0.3156, Val Loss: 0.1463, LR: 0.000002, best val loss was: 0.1281
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [768], Train Loss: 0.2953, Val Loss: 0.1304, LR: 0.000002, best val loss was: 0.1281
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [769], Train Loss: 0.3028, Val Loss: 0.1309, LR: 0.000002, best val loss was: 0.1281
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [770], Train Loss: 0.3346, Val Loss: 0.1431, LR: 0.000002, best val loss was: 0.1281
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [771], Train Loss: 0.3139, Val Loss: 0.1424, LR: 0.000002, best val loss was: 0.1281
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [772], Train Loss: 0.3275, Val Loss: 0.1316, LR: 0.000002, best val loss was: 0.1281
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [773], Train Loss: 0.2864, Val Loss: 0.1342, LR: 0.000002, best val loss was: 0.1281
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [774], Train Loss: 0.2665, Val Loss: 0.1277, LR: 0.000002, best val loss was: 0.1277
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [775], Train Loss: 0.3162, Val Loss: 0.1274, LR: 0.000002, best val loss was: 0.1274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [776], Train Loss: 0.2841, Val Loss: 0.1465, LR: 0.000002, best val loss was: 0.1274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [777], Train Loss: 0.2859, Val Loss: 0.1398, LR: 0.000002, best val loss was: 0.1274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [778], Train Loss: 0.2806, Val Loss: 0.1379, LR: 0.000002, best val loss was: 0.1274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [779], Train Loss: 0.2875, Val Loss: 0.1289, LR: 0.000002, best val loss was: 0.1274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [780], Train Loss: 0.2876, Val Loss: 0.1447, LR: 0.000002, best val loss was: 0.1274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [781], Train Loss: 0.3076, Val Loss: 0.1409, LR: 0.000002, best val loss was: 0.1274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [782], Train Loss: 0.2917, Val Loss: 0.1330, LR: 0.000002, best val loss was: 0.1274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [783], Train Loss: 0.3060, Val Loss: 0.1373, LR: 0.000002, best val loss was: 0.1274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [784], Train Loss: 0.3128, Val Loss: 0.1357, LR: 0.000002, best val loss was: 0.1274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [785], Train Loss: 0.3101, Val Loss: 0.1381, LR: 0.000002, best val loss was: 0.1274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [786], Train Loss: 0.2731, Val Loss: 0.1358, LR: 0.000002, best val loss was: 0.1274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [787], Train Loss: 0.2848, Val Loss: 0.1366, LR: 0.000002, best val loss was: 0.1274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [788], Train Loss: 0.3063, Val Loss: 0.1274, LR: 0.000002, best val loss was: 0.1274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [789], Train Loss: 0.2654, Val Loss: 0.1314, LR: 0.000002, best val loss was: 0.1274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [790], Train Loss: 0.2869, Val Loss: 0.1330, LR: 0.000002, best val loss was: 0.1274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [791], Train Loss: 0.3029, Val Loss: 0.1395, LR: 0.000002, best val loss was: 0.1274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [792], Train Loss: 0.2736, Val Loss: 0.1323, LR: 0.000002, best val loss was: 0.1274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [793], Train Loss: 0.3107, Val Loss: 0.1328, LR: 0.000002, best val loss was: 0.1274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [794], Train Loss: 0.2612, Val Loss: 0.1364, LR: 0.000002, best val loss was: 0.1274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [795], Train Loss: 0.2967, Val Loss: 0.1332, LR: 0.000002, best val loss was: 0.1274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [796], Train Loss: 0.2816, Val Loss: 0.1313, LR: 0.000002, best val loss was: 0.1274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [797], Train Loss: 0.2693, Val Loss: 0.1339, LR: 0.000002, best val loss was: 0.1274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [798], Train Loss: 0.2614, Val Loss: 0.1340, LR: 0.000002, best val loss was: 0.1274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [799], Train Loss: 0.2845, Val Loss: 0.1322, LR: 0.000002, best val loss was: 0.1274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [800], Train Loss: 0.2723, Val Loss: 0.1292, LR: 0.000002, best val loss was: 0.1274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [801], Train Loss: 0.2817, Val Loss: 0.1257, LR: 0.000002, best val loss was: 0.1257
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [802], Train Loss: 0.2859, Val Loss: 0.1272, LR: 0.000002, best val loss was: 0.1257
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [803], Train Loss: 0.3133, Val Loss: 0.1356, LR: 0.000002, best val loss was: 0.1257
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [804], Train Loss: 0.2977, Val Loss: 0.1324, LR: 0.000002, best val loss was: 0.1257
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [805], Train Loss: 0.2738, Val Loss: 0.1322, LR: 0.000002, best val loss was: 0.1257
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [806], Train Loss: 0.2952, Val Loss: 0.1293, LR: 0.000002, best val loss was: 0.1257
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [807], Train Loss: 0.2929, Val Loss: 0.1341, LR: 0.000002, best val loss was: 0.1257
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [808], Train Loss: 0.3261, Val Loss: 0.1303, LR: 0.000002, best val loss was: 0.1257
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [809], Train Loss: 0.2560, Val Loss: 0.1297, LR: 0.000002, best val loss was: 0.1257
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [810], Train Loss: 0.3101, Val Loss: 0.1385, LR: 0.000002, best val loss was: 0.1257
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [811], Train Loss: 0.2874, Val Loss: 0.1265, LR: 0.000002, best val loss was: 0.1257
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [812], Train Loss: 0.2849, Val Loss: 0.1334, LR: 0.000002, best val loss was: 0.1257
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [813], Train Loss: 0.2943, Val Loss: 0.1340, LR: 0.000002, best val loss was: 0.1257
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [814], Train Loss: 0.2922, Val Loss: 0.1454, LR: 0.000002, best val loss was: 0.1257
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [815], Train Loss: 0.2783, Val Loss: 0.1273, LR: 0.000002, best val loss was: 0.1257
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [816], Train Loss: 0.2885, Val Loss: 0.1305, LR: 0.000002, best val loss was: 0.1257
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [817], Train Loss: 0.2813, Val Loss: 0.1310, LR: 0.000002, best val loss was: 0.1257
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [818], Train Loss: 0.3308, Val Loss: 0.1343, LR: 0.000002, best val loss was: 0.1257
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [819], Train Loss: 0.2941, Val Loss: 0.1317, LR: 0.000002, best val loss was: 0.1257
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [820], Train Loss: 0.2973, Val Loss: 0.1321, LR: 0.000002, best val loss was: 0.1257
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [821], Train Loss: 0.2633, Val Loss: 0.1290, LR: 0.000002, best val loss was: 0.1257
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [822], Train Loss: 0.2789, Val Loss: 0.1270, LR: 0.000002, best val loss was: 0.1257
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [823], Train Loss: 0.2773, Val Loss: 0.1297, LR: 0.000002, best val loss was: 0.1257
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [824], Train Loss: 0.2685, Val Loss: 0.1275, LR: 0.000002, best val loss was: 0.1257
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [825], Train Loss: 0.3105, Val Loss: 0.1302, LR: 0.000002, best val loss was: 0.1257
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [826], Train Loss: 0.2930, Val Loss: 0.1283, LR: 0.000002, best val loss was: 0.1257
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [827], Train Loss: 0.2876, Val Loss: 0.1346, LR: 0.000002, best val loss was: 0.1257
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [828], Train Loss: 0.2897, Val Loss: 0.1321, LR: 0.000002, best val loss was: 0.1257
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [829], Train Loss: 0.2548, Val Loss: 0.1316, LR: 0.000002, best val loss was: 0.1257
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [830], Train Loss: 0.2843, Val Loss: 0.1279, LR: 0.000002, best val loss was: 0.1257
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [831], Train Loss: 0.2967, Val Loss: 0.1282, LR: 0.000002, best val loss was: 0.1257
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [832], Train Loss: 0.3123, Val Loss: 0.1293, LR: 0.000002, best val loss was: 0.1257
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [833], Train Loss: 0.3003, Val Loss: 0.1228, LR: 0.000002, best val loss was: 0.1228
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [834], Train Loss: 0.3064, Val Loss: 0.1255, LR: 0.000002, best val loss was: 0.1228
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [835], Train Loss: 0.3136, Val Loss: 0.1332, LR: 0.000002, best val loss was: 0.1228
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [836], Train Loss: 0.2651, Val Loss: 0.1236, LR: 0.000002, best val loss was: 0.1228
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [837], Train Loss: 0.2964, Val Loss: 0.1275, LR: 0.000002, best val loss was: 0.1228
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [838], Train Loss: 0.2790, Val Loss: 0.1272, LR: 0.000002, best val loss was: 0.1228
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [839], Train Loss: 0.2637, Val Loss: 0.1223, LR: 0.000002, best val loss was: 0.1223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [840], Train Loss: 0.2901, Val Loss: 0.1272, LR: 0.000002, best val loss was: 0.1223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [841], Train Loss: 0.2524, Val Loss: 0.1296, LR: 0.000002, best val loss was: 0.1223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [842], Train Loss: 0.2815, Val Loss: 0.1259, LR: 0.000002, best val loss was: 0.1223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [843], Train Loss: 0.2781, Val Loss: 0.1342, LR: 0.000002, best val loss was: 0.1223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [844], Train Loss: 0.2854, Val Loss: 0.1239, LR: 0.000002, best val loss was: 0.1223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [845], Train Loss: 0.2986, Val Loss: 0.1274, LR: 0.000002, best val loss was: 0.1223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [846], Train Loss: 0.2940, Val Loss: 0.1255, LR: 0.000002, best val loss was: 0.1223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [847], Train Loss: 0.2656, Val Loss: 0.1361, LR: 0.000002, best val loss was: 0.1223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [848], Train Loss: 0.2794, Val Loss: 0.1257, LR: 0.000002, best val loss was: 0.1223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [849], Train Loss: 0.2836, Val Loss: 0.1288, LR: 0.000002, best val loss was: 0.1223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [850], Train Loss: 0.2642, Val Loss: 0.1257, LR: 0.000002, best val loss was: 0.1223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [851], Train Loss: 0.2457, Val Loss: 0.1286, LR: 0.000002, best val loss was: 0.1223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [852], Train Loss: 0.2999, Val Loss: 0.1215, LR: 0.000002, best val loss was: 0.1215
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [853], Train Loss: 0.2882, Val Loss: 0.1241, LR: 0.000002, best val loss was: 0.1215
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [854], Train Loss: 0.3166, Val Loss: 0.1216, LR: 0.000002, best val loss was: 0.1215
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [855], Train Loss: 0.2864, Val Loss: 0.1264, LR: 0.000002, best val loss was: 0.1215
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [856], Train Loss: 0.3000, Val Loss: 0.1311, LR: 0.000002, best val loss was: 0.1215
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [857], Train Loss: 0.3006, Val Loss: 0.1301, LR: 0.000002, best val loss was: 0.1215
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [858], Train Loss: 0.3127, Val Loss: 0.1362, LR: 0.000002, best val loss was: 0.1215
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [859], Train Loss: 0.2659, Val Loss: 0.1191, LR: 0.000002, best val loss was: 0.1191
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [860], Train Loss: 0.2782, Val Loss: 0.1293, LR: 0.000002, best val loss was: 0.1191
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [861], Train Loss: 0.2828, Val Loss: 0.1297, LR: 0.000002, best val loss was: 0.1191
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [862], Train Loss: 0.3175, Val Loss: 0.1247, LR: 0.000002, best val loss was: 0.1191
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [863], Train Loss: 0.2973, Val Loss: 0.1277, LR: 0.000002, best val loss was: 0.1191
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [864], Train Loss: 0.2725, Val Loss: 0.1292, LR: 0.000002, best val loss was: 0.1191
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [865], Train Loss: 0.2693, Val Loss: 0.1191, LR: 0.000002, best val loss was: 0.1191
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [866], Train Loss: 0.2999, Val Loss: 0.1259, LR: 0.000002, best val loss was: 0.1191
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [867], Train Loss: 0.2903, Val Loss: 0.1265, LR: 0.000002, best val loss was: 0.1191
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [868], Train Loss: 0.2833, Val Loss: 0.1267, LR: 0.000002, best val loss was: 0.1191
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [869], Train Loss: 0.2890, Val Loss: 0.1283, LR: 0.000002, best val loss was: 0.1191
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [870], Train Loss: 0.2508, Val Loss: 0.1221, LR: 0.000002, best val loss was: 0.1191
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [871], Train Loss: 0.2930, Val Loss: 0.1240, LR: 0.000002, best val loss was: 0.1191
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [872], Train Loss: 0.2884, Val Loss: 0.1335, LR: 0.000002, best val loss was: 0.1191
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [873], Train Loss: 0.2946, Val Loss: 0.1209, LR: 0.000002, best val loss was: 0.1191
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [874], Train Loss: 0.2770, Val Loss: 0.1358, LR: 0.000002, best val loss was: 0.1191
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [875], Train Loss: 0.2954, Val Loss: 0.1235, LR: 0.000002, best val loss was: 0.1191
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [876], Train Loss: 0.3017, Val Loss: 0.1280, LR: 0.000002, best val loss was: 0.1191
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [877], Train Loss: 0.2701, Val Loss: 0.1265, LR: 0.000002, best val loss was: 0.1191
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [878], Train Loss: 0.2769, Val Loss: 0.1260, LR: 0.000002, best val loss was: 0.1191
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [879], Train Loss: 0.2685, Val Loss: 0.1274, LR: 0.000002, best val loss was: 0.1191
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [880], Train Loss: 0.3004, Val Loss: 0.1212, LR: 0.000002, best val loss was: 0.1191
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [881], Train Loss: 0.2813, Val Loss: 0.1256, LR: 0.000002, best val loss was: 0.1191
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [882], Train Loss: 0.2909, Val Loss: 0.1296, LR: 0.000002, best val loss was: 0.1191
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [883], Train Loss: 0.2879, Val Loss: 0.1193, LR: 0.000002, best val loss was: 0.1191
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [884], Train Loss: 0.3094, Val Loss: 0.1240, LR: 0.000002, best val loss was: 0.1191
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [885], Train Loss: 0.2657, Val Loss: 0.1229, LR: 0.000002, best val loss was: 0.1191
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [886], Train Loss: 0.2847, Val Loss: 0.1313, LR: 0.000002, best val loss was: 0.1191
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [887], Train Loss: 0.2697, Val Loss: 0.1253, LR: 0.000002, best val loss was: 0.1191
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [888], Train Loss: 0.2797, Val Loss: 0.1298, LR: 0.000002, best val loss was: 0.1191
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [889], Train Loss: 0.2797, Val Loss: 0.1304, LR: 0.000002, best val loss was: 0.1191
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [890], Train Loss: 0.2910, Val Loss: 0.1239, LR: 0.000002, best val loss was: 0.1191
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [891], Train Loss: 0.2653, Val Loss: 0.1217, LR: 0.000002, best val loss was: 0.1191
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [892], Train Loss: 0.2733, Val Loss: 0.1217, LR: 0.000002, best val loss was: 0.1191
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [893], Train Loss: 0.2415, Val Loss: 0.1311, LR: 0.000002, best val loss was: 0.1191
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [894], Train Loss: 0.3092, Val Loss: 0.1217, LR: 0.000002, best val loss was: 0.1191
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [895], Train Loss: 0.2976, Val Loss: 0.1248, LR: 0.000002, best val loss was: 0.1191
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [896], Train Loss: 0.2453, Val Loss: 0.1172, LR: 0.000002, best val loss was: 0.1172
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [897], Train Loss: 0.2712, Val Loss: 0.1172, LR: 0.000002, best val loss was: 0.1172
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [898], Train Loss: 0.3017, Val Loss: 0.1227, LR: 0.000002, best val loss was: 0.1172
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [899], Train Loss: 0.2916, Val Loss: 0.1248, LR: 0.000002, best val loss was: 0.1172
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [900], Train Loss: 0.3015, Val Loss: 0.1289, LR: 0.000002, best val loss was: 0.1172
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [901], Train Loss: 0.2723, Val Loss: 0.1257, LR: 0.000002, best val loss was: 0.1172
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [902], Train Loss: 0.2607, Val Loss: 0.1170, LR: 0.000002, best val loss was: 0.1170
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [903], Train Loss: 0.2855, Val Loss: 0.1225, LR: 0.000002, best val loss was: 0.1170
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [904], Train Loss: 0.2909, Val Loss: 0.1185, LR: 0.000002, best val loss was: 0.1170
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [905], Train Loss: 0.3176, Val Loss: 0.1276, LR: 0.000002, best val loss was: 0.1170
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [906], Train Loss: 0.2715, Val Loss: 0.1215, LR: 0.000002, best val loss was: 0.1170
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [907], Train Loss: 0.2877, Val Loss: 0.1180, LR: 0.000002, best val loss was: 0.1170
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [908], Train Loss: 0.2663, Val Loss: 0.1139, LR: 0.000002, best val loss was: 0.1139
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [909], Train Loss: 0.2775, Val Loss: 0.1237, LR: 0.000002, best val loss was: 0.1139
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [910], Train Loss: 0.2789, Val Loss: 0.1210, LR: 0.000002, best val loss was: 0.1139
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [911], Train Loss: 0.2729, Val Loss: 0.1190, LR: 0.000002, best val loss was: 0.1139
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [912], Train Loss: 0.2665, Val Loss: 0.1244, LR: 0.000002, best val loss was: 0.1139
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [913], Train Loss: 0.2805, Val Loss: 0.1258, LR: 0.000002, best val loss was: 0.1139
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [914], Train Loss: 0.2863, Val Loss: 0.1241, LR: 0.000002, best val loss was: 0.1139
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [915], Train Loss: 0.2574, Val Loss: 0.1213, LR: 0.000002, best val loss was: 0.1139
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [916], Train Loss: 0.2751, Val Loss: 0.1210, LR: 0.000002, best val loss was: 0.1139
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [917], Train Loss: 0.2689, Val Loss: 0.1185, LR: 0.000002, best val loss was: 0.1139
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [918], Train Loss: 0.2983, Val Loss: 0.1138, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [919], Train Loss: 0.2588, Val Loss: 0.1266, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [920], Train Loss: 0.2721, Val Loss: 0.1191, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [921], Train Loss: 0.2695, Val Loss: 0.1249, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [922], Train Loss: 0.2831, Val Loss: 0.1222, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [923], Train Loss: 0.3077, Val Loss: 0.1203, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [924], Train Loss: 0.2612, Val Loss: 0.1199, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [925], Train Loss: 0.2659, Val Loss: 0.1198, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [926], Train Loss: 0.2866, Val Loss: 0.1190, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [927], Train Loss: 0.2698, Val Loss: 0.1264, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [928], Train Loss: 0.2664, Val Loss: 0.1170, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [929], Train Loss: 0.2614, Val Loss: 0.1239, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [930], Train Loss: 0.2484, Val Loss: 0.1218, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [931], Train Loss: 0.2755, Val Loss: 0.1218, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [932], Train Loss: 0.2423, Val Loss: 0.1216, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [933], Train Loss: 0.2901, Val Loss: 0.1267, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [934], Train Loss: 0.2730, Val Loss: 0.1165, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [935], Train Loss: 0.2870, Val Loss: 0.1223, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [936], Train Loss: 0.2514, Val Loss: 0.1195, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [937], Train Loss: 0.2902, Val Loss: 0.1258, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [938], Train Loss: 0.2782, Val Loss: 0.1191, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [939], Train Loss: 0.2888, Val Loss: 0.1230, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [940], Train Loss: 0.2802, Val Loss: 0.1209, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [941], Train Loss: 0.2665, Val Loss: 0.1198, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [942], Train Loss: 0.2729, Val Loss: 0.1305, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [943], Train Loss: 0.2692, Val Loss: 0.1251, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [944], Train Loss: 0.2755, Val Loss: 0.1184, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [945], Train Loss: 0.2916, Val Loss: 0.1211, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [946], Train Loss: 0.2920, Val Loss: 0.1153, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [947], Train Loss: 0.3054, Val Loss: 0.1185, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [948], Train Loss: 0.2718, Val Loss: 0.1197, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [949], Train Loss: 0.3063, Val Loss: 0.1149, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [950], Train Loss: 0.2458, Val Loss: 0.1202, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [951], Train Loss: 0.2886, Val Loss: 0.1149, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [952], Train Loss: 0.2651, Val Loss: 0.1206, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [953], Train Loss: 0.2657, Val Loss: 0.1170, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [954], Train Loss: 0.2744, Val Loss: 0.1205, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [955], Train Loss: 0.2783, Val Loss: 0.1198, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [956], Train Loss: 0.2783, Val Loss: 0.1187, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [957], Train Loss: 0.2648, Val Loss: 0.1194, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [958], Train Loss: 0.2942, Val Loss: 0.1205, LR: 0.000002, best val loss was: 0.1138
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [959], Train Loss: 0.2437, Val Loss: 0.1132, LR: 0.000002, best val loss was: 0.1132
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [960], Train Loss: 0.2752, Val Loss: 0.1206, LR: 0.000002, best val loss was: 0.1132
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [961], Train Loss: 0.2554, Val Loss: 0.1225, LR: 0.000002, best val loss was: 0.1132
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [962], Train Loss: 0.2777, Val Loss: 0.1143, LR: 0.000002, best val loss was: 0.1132
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [963], Train Loss: 0.2729, Val Loss: 0.1179, LR: 0.000002, best val loss was: 0.1132
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [964], Train Loss: 0.2805, Val Loss: 0.1149, LR: 0.000002, best val loss was: 0.1132
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [965], Train Loss: 0.2444, Val Loss: 0.1221, LR: 0.000002, best val loss was: 0.1132
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [966], Train Loss: 0.2730, Val Loss: 0.1186, LR: 0.000002, best val loss was: 0.1132
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [967], Train Loss: 0.2608, Val Loss: 0.1197, LR: 0.000002, best val loss was: 0.1132
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [968], Train Loss: 0.2687, Val Loss: 0.1155, LR: 0.000002, best val loss was: 0.1132
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [969], Train Loss: 0.3027, Val Loss: 0.1180, LR: 0.000002, best val loss was: 0.1132
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [970], Train Loss: 0.2889, Val Loss: 0.1221, LR: 0.000002, best val loss was: 0.1132
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [971], Train Loss: 0.2786, Val Loss: 0.1181, LR: 0.000002, best val loss was: 0.1132
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [972], Train Loss: 0.2525, Val Loss: 0.1215, LR: 0.000002, best val loss was: 0.1132
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [973], Train Loss: 0.2752, Val Loss: 0.1126, LR: 0.000002, best val loss was: 0.1126
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [974], Train Loss: 0.2554, Val Loss: 0.1169, LR: 0.000002, best val loss was: 0.1126
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [975], Train Loss: 0.2671, Val Loss: 0.1131, LR: 0.000002, best val loss was: 0.1126
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [976], Train Loss: 0.2578, Val Loss: 0.1218, LR: 0.000002, best val loss was: 0.1126
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [977], Train Loss: 0.2811, Val Loss: 0.1107, LR: 0.000002, best val loss was: 0.1107
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [978], Train Loss: 0.2918, Val Loss: 0.1125, LR: 0.000002, best val loss was: 0.1107
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [979], Train Loss: 0.2863, Val Loss: 0.1180, LR: 0.000002, best val loss was: 0.1107
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [980], Train Loss: 0.2615, Val Loss: 0.1181, LR: 0.000002, best val loss was: 0.1107
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [981], Train Loss: 0.2702, Val Loss: 0.1181, LR: 0.000002, best val loss was: 0.1107
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [982], Train Loss: 0.2443, Val Loss: 0.1103, LR: 0.000002, best val loss was: 0.1103
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [983], Train Loss: 0.2418, Val Loss: 0.1132, LR: 0.000002, best val loss was: 0.1103
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [984], Train Loss: 0.2589, Val Loss: 0.1160, LR: 0.000002, best val loss was: 0.1103
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [985], Train Loss: 0.2818, Val Loss: 0.1201, LR: 0.000002, best val loss was: 0.1103
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [986], Train Loss: 0.2626, Val Loss: 0.1199, LR: 0.000002, best val loss was: 0.1103
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [987], Train Loss: 0.2441, Val Loss: 0.1156, LR: 0.000002, best val loss was: 0.1103
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [988], Train Loss: 0.2748, Val Loss: 0.1114, LR: 0.000002, best val loss was: 0.1103
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [989], Train Loss: 0.2527, Val Loss: 0.1154, LR: 0.000002, best val loss was: 0.1103
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [990], Train Loss: 0.2593, Val Loss: 0.1151, LR: 0.000002, best val loss was: 0.1103
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [991], Train Loss: 0.2714, Val Loss: 0.1134, LR: 0.000002, best val loss was: 0.1103
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [992], Train Loss: 0.2809, Val Loss: 0.1097, LR: 0.000002, best val loss was: 0.1097
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [993], Train Loss: 0.2340, Val Loss: 0.1163, LR: 0.000002, best val loss was: 0.1097
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [994], Train Loss: 0.2796, Val Loss: 0.1141, LR: 0.000002, best val loss was: 0.1097
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [995], Train Loss: 0.2612, Val Loss: 0.1163, LR: 0.000002, best val loss was: 0.1097
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [996], Train Loss: 0.2476, Val Loss: 0.1216, LR: 0.000002, best val loss was: 0.1097
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [997], Train Loss: 0.2443, Val Loss: 0.1133, LR: 0.000002, best val loss was: 0.1097
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [998], Train Loss: 0.2597, Val Loss: 0.1119, LR: 0.000002, best val loss was: 0.1097
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [999], Train Loss: 0.2779, Val Loss: 0.1170, LR: 0.000002, best val loss was: 0.1097
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1000], Train Loss: 0.2611, Val Loss: 0.1125, LR: 0.000002, best val loss was: 0.1097
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1001], Train Loss: 0.2862, Val Loss: 0.1162, LR: 0.000002, best val loss was: 0.1097
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1002], Train Loss: 0.2613, Val Loss: 0.1168, LR: 0.000002, best val loss was: 0.1097
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1003], Train Loss: 0.2962, Val Loss: 0.1170, LR: 0.000002, best val loss was: 0.1097
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1004], Train Loss: 0.2666, Val Loss: 0.1115, LR: 0.000002, best val loss was: 0.1097
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1005], Train Loss: 0.2562, Val Loss: 0.1068, LR: 0.000002, best val loss was: 0.1068
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1006], Train Loss: 0.2554, Val Loss: 0.1110, LR: 0.000002, best val loss was: 0.1068
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1007], Train Loss: 0.2718, Val Loss: 0.1207, LR: 0.000002, best val loss was: 0.1068
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1008], Train Loss: 0.2887, Val Loss: 0.1174, LR: 0.000002, best val loss was: 0.1068
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1009], Train Loss: 0.2408, Val Loss: 0.1125, LR: 0.000002, best val loss was: 0.1068
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1010], Train Loss: 0.2972, Val Loss: 0.1103, LR: 0.000002, best val loss was: 0.1068
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1011], Train Loss: 0.2496, Val Loss: 0.1129, LR: 0.000002, best val loss was: 0.1068
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1012], Train Loss: 0.2752, Val Loss: 0.1171, LR: 0.000002, best val loss was: 0.1068
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1013], Train Loss: 0.2722, Val Loss: 0.1121, LR: 0.000002, best val loss was: 0.1068
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1014], Train Loss: 0.2598, Val Loss: 0.1073, LR: 0.000002, best val loss was: 0.1068
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1015], Train Loss: 0.2362, Val Loss: 0.1147, LR: 0.000002, best val loss was: 0.1068
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1016], Train Loss: 0.2419, Val Loss: 0.1156, LR: 0.000002, best val loss was: 0.1068
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1017], Train Loss: 0.2576, Val Loss: 0.1122, LR: 0.000002, best val loss was: 0.1068
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1018], Train Loss: 0.2588, Val Loss: 0.1163, LR: 0.000002, best val loss was: 0.1068
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1019], Train Loss: 0.2620, Val Loss: 0.1175, LR: 0.000002, best val loss was: 0.1068
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1020], Train Loss: 0.3083, Val Loss: 0.1090, LR: 0.000002, best val loss was: 0.1068
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1021], Train Loss: 0.2747, Val Loss: 0.1099, LR: 0.000002, best val loss was: 0.1068
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1022], Train Loss: 0.2652, Val Loss: 0.1049, LR: 0.000002, best val loss was: 0.1049
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1023], Train Loss: 0.2454, Val Loss: 0.1086, LR: 0.000002, best val loss was: 0.1049
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1024], Train Loss: 0.2825, Val Loss: 0.1180, LR: 0.000002, best val loss was: 0.1049
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1025], Train Loss: 0.2583, Val Loss: 0.1170, LR: 0.000002, best val loss was: 0.1049
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1026], Train Loss: 0.2758, Val Loss: 0.1079, LR: 0.000002, best val loss was: 0.1049
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1027], Train Loss: 0.2782, Val Loss: 0.1100, LR: 0.000002, best val loss was: 0.1049
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1028], Train Loss: 0.2297, Val Loss: 0.1122, LR: 0.000002, best val loss was: 0.1049
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1029], Train Loss: 0.2611, Val Loss: 0.1102, LR: 0.000002, best val loss was: 0.1049
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1030], Train Loss: 0.2471, Val Loss: 0.1104, LR: 0.000002, best val loss was: 0.1049
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1031], Train Loss: 0.2891, Val Loss: 0.1146, LR: 0.000002, best val loss was: 0.1049
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1032], Train Loss: 0.2724, Val Loss: 0.1081, LR: 0.000002, best val loss was: 0.1049
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1033], Train Loss: 0.2522, Val Loss: 0.1049, LR: 0.000002, best val loss was: 0.1049
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1034], Train Loss: 0.2985, Val Loss: 0.1114, LR: 0.000002, best val loss was: 0.1049
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1035], Train Loss: 0.2676, Val Loss: 0.1192, LR: 0.000002, best val loss was: 0.1049
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1036], Train Loss: 0.2824, Val Loss: 0.1136, LR: 0.000002, best val loss was: 0.1049
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1037], Train Loss: 0.2621, Val Loss: 0.1046, LR: 0.000002, best val loss was: 0.1046
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1038], Train Loss: 0.2656, Val Loss: 0.1115, LR: 0.000002, best val loss was: 0.1046
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1039], Train Loss: 0.2848, Val Loss: 0.1128, LR: 0.000002, best val loss was: 0.1046
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1040], Train Loss: 0.2626, Val Loss: 0.1108, LR: 0.000002, best val loss was: 0.1046
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1041], Train Loss: 0.2529, Val Loss: 0.1102, LR: 0.000002, best val loss was: 0.1046
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1042], Train Loss: 0.2723, Val Loss: 0.1170, LR: 0.000002, best val loss was: 0.1046
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1043], Train Loss: 0.2651, Val Loss: 0.1061, LR: 0.000002, best val loss was: 0.1046
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1044], Train Loss: 0.2769, Val Loss: 0.1119, LR: 0.000002, best val loss was: 0.1046
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1045], Train Loss: 0.2859, Val Loss: 0.1107, LR: 0.000002, best val loss was: 0.1046
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1046], Train Loss: 0.2664, Val Loss: 0.1077, LR: 0.000002, best val loss was: 0.1046
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1047], Train Loss: 0.2458, Val Loss: 0.1081, LR: 0.000002, best val loss was: 0.1046
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1048], Train Loss: 0.2814, Val Loss: 0.1115, LR: 0.000002, best val loss was: 0.1046
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1049], Train Loss: 0.2891, Val Loss: 0.1107, LR: 0.000002, best val loss was: 0.1046
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1050], Train Loss: 0.2648, Val Loss: 0.1116, LR: 0.000002, best val loss was: 0.1046
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1051], Train Loss: 0.2803, Val Loss: 0.1109, LR: 0.000002, best val loss was: 0.1046
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1052], Train Loss: 0.2981, Val Loss: 0.1122, LR: 0.000002, best val loss was: 0.1046
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1053], Train Loss: 0.2706, Val Loss: 0.1063, LR: 0.000002, best val loss was: 0.1046
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1054], Train Loss: 0.2613, Val Loss: 0.1108, LR: 0.000002, best val loss was: 0.1046
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1055], Train Loss: 0.2660, Val Loss: 0.1126, LR: 0.000002, best val loss was: 0.1046
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1056], Train Loss: 0.2525, Val Loss: 0.1063, LR: 0.000002, best val loss was: 0.1046
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1057], Train Loss: 0.2750, Val Loss: 0.1097, LR: 0.000002, best val loss was: 0.1046
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1058], Train Loss: 0.2516, Val Loss: 0.1063, LR: 0.000002, best val loss was: 0.1046
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1059], Train Loss: 0.2606, Val Loss: 0.1164, LR: 0.000002, best val loss was: 0.1046
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1060], Train Loss: 0.2448, Val Loss: 0.1053, LR: 0.000002, best val loss was: 0.1046
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1061], Train Loss: 0.2764, Val Loss: 0.1107, LR: 0.000002, best val loss was: 0.1046
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1062], Train Loss: 0.2654, Val Loss: 0.1086, LR: 0.000002, best val loss was: 0.1046
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1063], Train Loss: 0.2601, Val Loss: 0.1159, LR: 0.000002, best val loss was: 0.1046
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1064], Train Loss: 0.2556, Val Loss: 0.1168, LR: 0.000002, best val loss was: 0.1046
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1065], Train Loss: 0.2558, Val Loss: 0.1044, LR: 0.000002, best val loss was: 0.1044
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1066], Train Loss: 0.2733, Val Loss: 0.1131, LR: 0.000002, best val loss was: 0.1044
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1067], Train Loss: 0.2664, Val Loss: 0.1039, LR: 0.000002, best val loss was: 0.1039
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1068], Train Loss: 0.2515, Val Loss: 0.1054, LR: 0.000002, best val loss was: 0.1039
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1069], Train Loss: 0.2554, Val Loss: 0.1064, LR: 0.000002, best val loss was: 0.1039
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1070], Train Loss: 0.2872, Val Loss: 0.1103, LR: 0.000002, best val loss was: 0.1039
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1071], Train Loss: 0.2540, Val Loss: 0.1149, LR: 0.000002, best val loss was: 0.1039
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1072], Train Loss: 0.2595, Val Loss: 0.1090, LR: 0.000002, best val loss was: 0.1039
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1073], Train Loss: 0.2487, Val Loss: 0.1079, LR: 0.000002, best val loss was: 0.1039
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1074], Train Loss: 0.2472, Val Loss: 0.1126, LR: 0.000002, best val loss was: 0.1039
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1075], Train Loss: 0.2404, Val Loss: 0.1081, LR: 0.000002, best val loss was: 0.1039
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1076], Train Loss: 0.2815, Val Loss: 0.1113, LR: 0.000002, best val loss was: 0.1039
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1077], Train Loss: 0.2787, Val Loss: 0.1108, LR: 0.000002, best val loss was: 0.1039
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1078], Train Loss: 0.2656, Val Loss: 0.1066, LR: 0.000002, best val loss was: 0.1039
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1079], Train Loss: 0.2763, Val Loss: 0.1032, LR: 0.000002, best val loss was: 0.1032
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1080], Train Loss: 0.2423, Val Loss: 0.1091, LR: 0.000002, best val loss was: 0.1032
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1081], Train Loss: 0.2649, Val Loss: 0.1065, LR: 0.000002, best val loss was: 0.1032
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1082], Train Loss: 0.2624, Val Loss: 0.1089, LR: 0.000002, best val loss was: 0.1032
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1083], Train Loss: 0.2747, Val Loss: 0.1106, LR: 0.000002, best val loss was: 0.1032
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1084], Train Loss: 0.2563, Val Loss: 0.1110, LR: 0.000002, best val loss was: 0.1032
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1085], Train Loss: 0.2503, Val Loss: 0.1114, LR: 0.000002, best val loss was: 0.1032
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1086], Train Loss: 0.2596, Val Loss: 0.1073, LR: 0.000002, best val loss was: 0.1032
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1087], Train Loss: 0.2555, Val Loss: 0.1069, LR: 0.000002, best val loss was: 0.1032
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1088], Train Loss: 0.2427, Val Loss: 0.1060, LR: 0.000002, best val loss was: 0.1032
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1089], Train Loss: 0.2479, Val Loss: 0.1077, LR: 0.000002, best val loss was: 0.1032
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1090], Train Loss: 0.2190, Val Loss: 0.1035, LR: 0.000002, best val loss was: 0.1032
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1091], Train Loss: 0.2680, Val Loss: 0.1112, LR: 0.000002, best val loss was: 0.1032
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1092], Train Loss: 0.2777, Val Loss: 0.1166, LR: 0.000002, best val loss was: 0.1032
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1093], Train Loss: 0.2578, Val Loss: 0.1079, LR: 0.000002, best val loss was: 0.1032
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1094], Train Loss: 0.2496, Val Loss: 0.1048, LR: 0.000002, best val loss was: 0.1032
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1095], Train Loss: 0.2558, Val Loss: 0.1030, LR: 0.000002, best val loss was: 0.1030
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1096], Train Loss: 0.2452, Val Loss: 0.1085, LR: 0.000002, best val loss was: 0.1030
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1097], Train Loss: 0.2792, Val Loss: 0.1123, LR: 0.000002, best val loss was: 0.1030
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1098], Train Loss: 0.2602, Val Loss: 0.1175, LR: 0.000002, best val loss was: 0.1030
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1099], Train Loss: 0.2419, Val Loss: 0.1066, LR: 0.000002, best val loss was: 0.1030
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1100], Train Loss: 0.2927, Val Loss: 0.1095, LR: 0.000002, best val loss was: 0.1030
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1101], Train Loss: 0.2384, Val Loss: 0.1117, LR: 0.000002, best val loss was: 0.1030
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1102], Train Loss: 0.2351, Val Loss: 0.1105, LR: 0.000002, best val loss was: 0.1030
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1103], Train Loss: 0.2558, Val Loss: 0.1061, LR: 0.000002, best val loss was: 0.1030
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1104], Train Loss: 0.2856, Val Loss: 0.1089, LR: 0.000002, best val loss was: 0.1030
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1105], Train Loss: 0.2617, Val Loss: 0.1053, LR: 0.000002, best val loss was: 0.1030
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1106], Train Loss: 0.2863, Val Loss: 0.1038, LR: 0.000002, best val loss was: 0.1030
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1107], Train Loss: 0.2580, Val Loss: 0.1054, LR: 0.000002, best val loss was: 0.1030
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1108], Train Loss: 0.2649, Val Loss: 0.1030, LR: 0.000002, best val loss was: 0.1030
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1109], Train Loss: 0.2453, Val Loss: 0.1083, LR: 0.000002, best val loss was: 0.1030
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1110], Train Loss: 0.2830, Val Loss: 0.1063, LR: 0.000002, best val loss was: 0.1030
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1111], Train Loss: 0.2986, Val Loss: 0.1018, LR: 0.000002, best val loss was: 0.1018
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1112], Train Loss: 0.2724, Val Loss: 0.1012, LR: 0.000002, best val loss was: 0.1012
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1113], Train Loss: 0.2722, Val Loss: 0.1100, LR: 0.000002, best val loss was: 0.1012
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1114], Train Loss: 0.2360, Val Loss: 0.1086, LR: 0.000002, best val loss was: 0.1012
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1115], Train Loss: 0.2412, Val Loss: 0.1162, LR: 0.000002, best val loss was: 0.1012
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1116], Train Loss: 0.2522, Val Loss: 0.1087, LR: 0.000002, best val loss was: 0.1012
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1117], Train Loss: 0.2398, Val Loss: 0.1077, LR: 0.000002, best val loss was: 0.1012
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1118], Train Loss: 0.2358, Val Loss: 0.1051, LR: 0.000002, best val loss was: 0.1012
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1119], Train Loss: 0.2364, Val Loss: 0.1085, LR: 0.000002, best val loss was: 0.1012
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1120], Train Loss: 0.2542, Val Loss: 0.1025, LR: 0.000002, best val loss was: 0.1012
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1121], Train Loss: 0.2429, Val Loss: 0.1106, LR: 0.000002, best val loss was: 0.1012
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1122], Train Loss: 0.2877, Val Loss: 0.1078, LR: 0.000002, best val loss was: 0.1012
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1123], Train Loss: 0.2285, Val Loss: 0.1095, LR: 0.000002, best val loss was: 0.1012
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1124], Train Loss: 0.2639, Val Loss: 0.1045, LR: 0.000002, best val loss was: 0.1012
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1125], Train Loss: 0.2593, Val Loss: 0.1063, LR: 0.000002, best val loss was: 0.1012
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1126], Train Loss: 0.2762, Val Loss: 0.1100, LR: 0.000002, best val loss was: 0.1012
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1127], Train Loss: 0.2514, Val Loss: 0.1052, LR: 0.000002, best val loss was: 0.1012
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1128], Train Loss: 0.2650, Val Loss: 0.1112, LR: 0.000002, best val loss was: 0.1012
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1129], Train Loss: 0.2369, Val Loss: 0.1056, LR: 0.000002, best val loss was: 0.1012
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1130], Train Loss: 0.2567, Val Loss: 0.1034, LR: 0.000002, best val loss was: 0.1012
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1131], Train Loss: 0.2452, Val Loss: 0.1064, LR: 0.000002, best val loss was: 0.1012
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1132], Train Loss: 0.2636, Val Loss: 0.1098, LR: 0.000002, best val loss was: 0.1012
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1133], Train Loss: 0.2510, Val Loss: 0.1101, LR: 0.000002, best val loss was: 0.1012
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1134], Train Loss: 0.2471, Val Loss: 0.1063, LR: 0.000002, best val loss was: 0.1012
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1135], Train Loss: 0.2759, Val Loss: 0.0993, LR: 0.000002, best val loss was: 0.0993
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1136], Train Loss: 0.2318, Val Loss: 0.1032, LR: 0.000002, best val loss was: 0.0993
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1137], Train Loss: 0.2471, Val Loss: 0.1053, LR: 0.000002, best val loss was: 0.0993
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1138], Train Loss: 0.2523, Val Loss: 0.1056, LR: 0.000002, best val loss was: 0.0993
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1139], Train Loss: 0.2473, Val Loss: 0.1041, LR: 0.000002, best val loss was: 0.0993
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1140], Train Loss: 0.2361, Val Loss: 0.1092, LR: 0.000002, best val loss was: 0.0993
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1141], Train Loss: 0.2408, Val Loss: 0.1065, LR: 0.000002, best val loss was: 0.0993
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1142], Train Loss: 0.2401, Val Loss: 0.1052, LR: 0.000002, best val loss was: 0.0993
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1143], Train Loss: 0.2602, Val Loss: 0.1050, LR: 0.000002, best val loss was: 0.0993
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1144], Train Loss: 0.2747, Val Loss: 0.1027, LR: 0.000002, best val loss was: 0.0993
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1145], Train Loss: 0.2518, Val Loss: 0.1013, LR: 0.000002, best val loss was: 0.0993
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1146], Train Loss: 0.2811, Val Loss: 0.0981, LR: 0.000002, best val loss was: 0.0981
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1147], Train Loss: 0.2639, Val Loss: 0.1040, LR: 0.000002, best val loss was: 0.0981
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1148], Train Loss: 0.2633, Val Loss: 0.1066, LR: 0.000002, best val loss was: 0.0981
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1149], Train Loss: 0.2769, Val Loss: 0.1110, LR: 0.000002, best val loss was: 0.0981
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1150], Train Loss: 0.2277, Val Loss: 0.1006, LR: 0.000002, best val loss was: 0.0981
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1151], Train Loss: 0.2572, Val Loss: 0.1091, LR: 0.000002, best val loss was: 0.0981
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1152], Train Loss: 0.2240, Val Loss: 0.0993, LR: 0.000002, best val loss was: 0.0981
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1153], Train Loss: 0.2480, Val Loss: 0.1094, LR: 0.000002, best val loss was: 0.0981
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1154], Train Loss: 0.2788, Val Loss: 0.1033, LR: 0.000002, best val loss was: 0.0981
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1155], Train Loss: 0.2610, Val Loss: 0.0973, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1156], Train Loss: 0.2406, Val Loss: 0.1096, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1157], Train Loss: 0.2548, Val Loss: 0.1093, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1158], Train Loss: 0.2445, Val Loss: 0.1056, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1159], Train Loss: 0.2303, Val Loss: 0.1081, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1160], Train Loss: 0.2541, Val Loss: 0.1066, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1161], Train Loss: 0.2175, Val Loss: 0.0995, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1162], Train Loss: 0.2467, Val Loss: 0.1025, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1163], Train Loss: 0.2374, Val Loss: 0.1046, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1164], Train Loss: 0.2631, Val Loss: 0.1044, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1165], Train Loss: 0.2512, Val Loss: 0.1023, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1166], Train Loss: 0.2499, Val Loss: 0.1086, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1167], Train Loss: 0.2476, Val Loss: 0.1115, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1168], Train Loss: 0.2525, Val Loss: 0.1026, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1169], Train Loss: 0.2503, Val Loss: 0.1085, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1170], Train Loss: 0.2535, Val Loss: 0.1069, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1171], Train Loss: 0.2600, Val Loss: 0.1054, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1172], Train Loss: 0.2226, Val Loss: 0.1032, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1173], Train Loss: 0.2781, Val Loss: 0.1013, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1174], Train Loss: 0.2658, Val Loss: 0.1080, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1175], Train Loss: 0.2565, Val Loss: 0.1061, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1176], Train Loss: 0.2549, Val Loss: 0.1100, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1177], Train Loss: 0.2548, Val Loss: 0.1016, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1178], Train Loss: 0.2460, Val Loss: 0.1051, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1179], Train Loss: 0.2395, Val Loss: 0.1016, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1180], Train Loss: 0.2625, Val Loss: 0.1030, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1181], Train Loss: 0.2573, Val Loss: 0.1088, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1182], Train Loss: 0.2531, Val Loss: 0.1024, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1183], Train Loss: 0.2397, Val Loss: 0.1011, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1184], Train Loss: 0.2472, Val Loss: 0.1064, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1185], Train Loss: 0.2898, Val Loss: 0.1031, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1186], Train Loss: 0.2402, Val Loss: 0.0980, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1187], Train Loss: 0.2490, Val Loss: 0.1032, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1188], Train Loss: 0.2423, Val Loss: 0.1053, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1189], Train Loss: 0.2369, Val Loss: 0.1020, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1190], Train Loss: 0.2764, Val Loss: 0.1031, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1191], Train Loss: 0.2397, Val Loss: 0.1009, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1192], Train Loss: 0.2508, Val Loss: 0.1060, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1193], Train Loss: 0.2322, Val Loss: 0.1029, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1194], Train Loss: 0.2348, Val Loss: 0.1080, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1195], Train Loss: 0.2432, Val Loss: 0.1009, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1196], Train Loss: 0.2367, Val Loss: 0.1009, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1197], Train Loss: 0.2312, Val Loss: 0.1047, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1198], Train Loss: 0.2407, Val Loss: 0.1036, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1199], Train Loss: 0.2537, Val Loss: 0.1026, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1200], Train Loss: 0.2600, Val Loss: 0.0998, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1201], Train Loss: 0.2417, Val Loss: 0.0997, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1202], Train Loss: 0.2409, Val Loss: 0.1008, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1203], Train Loss: 0.2480, Val Loss: 0.1086, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1204], Train Loss: 0.2452, Val Loss: 0.1063, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1205], Train Loss: 0.2190, Val Loss: 0.1046, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1206], Train Loss: 0.2440, Val Loss: 0.1088, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1207], Train Loss: 0.2146, Val Loss: 0.1039, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1208], Train Loss: 0.2608, Val Loss: 0.1006, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1209], Train Loss: 0.2243, Val Loss: 0.0993, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1210], Train Loss: 0.2472, Val Loss: 0.1068, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1211], Train Loss: 0.2519, Val Loss: 0.1044, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1212], Train Loss: 0.2479, Val Loss: 0.1052, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1213], Train Loss: 0.2668, Val Loss: 0.1041, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1214], Train Loss: 0.2581, Val Loss: 0.1041, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1215], Train Loss: 0.2477, Val Loss: 0.0999, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1216], Train Loss: 0.2244, Val Loss: 0.1102, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1217], Train Loss: 0.2508, Val Loss: 0.1009, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1218], Train Loss: 0.2285, Val Loss: 0.1070, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1219], Train Loss: 0.2458, Val Loss: 0.1005, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1220], Train Loss: 0.2509, Val Loss: 0.1019, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1221], Train Loss: 0.2498, Val Loss: 0.0991, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1222], Train Loss: 0.2512, Val Loss: 0.1058, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1223], Train Loss: 0.2455, Val Loss: 0.1039, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1224], Train Loss: 0.2483, Val Loss: 0.0993, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1225], Train Loss: 0.2555, Val Loss: 0.1002, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1226], Train Loss: 0.2482, Val Loss: 0.0974, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1227], Train Loss: 0.2611, Val Loss: 0.1058, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1228], Train Loss: 0.2175, Val Loss: 0.1046, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1229], Train Loss: 0.2345, Val Loss: 0.1024, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1230], Train Loss: 0.2312, Val Loss: 0.1086, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1231], Train Loss: 0.2645, Val Loss: 0.1030, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1232], Train Loss: 0.2549, Val Loss: 0.1040, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1233], Train Loss: 0.2729, Val Loss: 0.1046, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1234], Train Loss: 0.2812, Val Loss: 0.1032, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1235], Train Loss: 0.2977, Val Loss: 0.1035, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1236], Train Loss: 0.2400, Val Loss: 0.1060, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1237], Train Loss: 0.2955, Val Loss: 0.1018, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1238], Train Loss: 0.2373, Val Loss: 0.1052, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1239], Train Loss: 0.2400, Val Loss: 0.1002, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1240], Train Loss: 0.2546, Val Loss: 0.1056, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1241], Train Loss: 0.2647, Val Loss: 0.0998, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1242], Train Loss: 0.2367, Val Loss: 0.1025, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1243], Train Loss: 0.2453, Val Loss: 0.1103, LR: 0.000002, best val loss was: 0.0973
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1244], Train Loss: 0.2694, Val Loss: 0.0960, LR: 0.000002, best val loss was: 0.0960
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1245], Train Loss: 0.2572, Val Loss: 0.1016, LR: 0.000002, best val loss was: 0.0960
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1246], Train Loss: 0.2375, Val Loss: 0.1009, LR: 0.000002, best val loss was: 0.0960
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1247], Train Loss: 0.2500, Val Loss: 0.1062, LR: 0.000002, best val loss was: 0.0960
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1248], Train Loss: 0.2142, Val Loss: 0.1009, LR: 0.000002, best val loss was: 0.0960
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1249], Train Loss: 0.2365, Val Loss: 0.1050, LR: 0.000002, best val loss was: 0.0960
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1250], Train Loss: 0.2437, Val Loss: 0.1006, LR: 0.000003, best val loss was: 0.0960
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1251], Train Loss: 0.2279, Val Loss: 0.1087, LR: 0.000003, best val loss was: 0.0960
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1252], Train Loss: 0.2304, Val Loss: 0.1036, LR: 0.000003, best val loss was: 0.0960
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1253], Train Loss: 0.2264, Val Loss: 0.1048, LR: 0.000003, best val loss was: 0.0960
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1254], Train Loss: 0.2373, Val Loss: 0.0972, LR: 0.000003, best val loss was: 0.0960
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1255], Train Loss: 0.2416, Val Loss: 0.1070, LR: 0.000003, best val loss was: 0.0960
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1256], Train Loss: 0.2624, Val Loss: 0.1077, LR: 0.000003, best val loss was: 0.0960
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1257], Train Loss: 0.2393, Val Loss: 0.1049, LR: 0.000003, best val loss was: 0.0960
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1258], Train Loss: 0.2597, Val Loss: 0.1036, LR: 0.000003, best val loss was: 0.0960
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1259], Train Loss: 0.2285, Val Loss: 0.1001, LR: 0.000003, best val loss was: 0.0960
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1260], Train Loss: 0.2435, Val Loss: 0.1050, LR: 0.000003, best val loss was: 0.0960
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1261], Train Loss: 0.2517, Val Loss: 0.0949, LR: 0.000003, best val loss was: 0.0949
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1262], Train Loss: 0.2450, Val Loss: 0.0968, LR: 0.000003, best val loss was: 0.0949
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1263], Train Loss: 0.2347, Val Loss: 0.1046, LR: 0.000003, best val loss was: 0.0949
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1264], Train Loss: 0.2481, Val Loss: 0.1107, LR: 0.000003, best val loss was: 0.0949
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1265], Train Loss: 0.2321, Val Loss: 0.1005, LR: 0.000003, best val loss was: 0.0949
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1266], Train Loss: 0.2269, Val Loss: 0.1032, LR: 0.000003, best val loss was: 0.0949
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1267], Train Loss: 0.2468, Val Loss: 0.1026, LR: 0.000003, best val loss was: 0.0949
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1268], Train Loss: 0.2424, Val Loss: 0.1058, LR: 0.000003, best val loss was: 0.0949
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1269], Train Loss: 0.2321, Val Loss: 0.1079, LR: 0.000003, best val loss was: 0.0949
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1270], Train Loss: 0.2659, Val Loss: 0.1057, LR: 0.000003, best val loss was: 0.0949
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1271], Train Loss: 0.2067, Val Loss: 0.0996, LR: 0.000003, best val loss was: 0.0949
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1272], Train Loss: 0.2243, Val Loss: 0.0985, LR: 0.000003, best val loss was: 0.0949
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1273], Train Loss: 0.2389, Val Loss: 0.1022, LR: 0.000003, best val loss was: 0.0949
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1274], Train Loss: 0.2485, Val Loss: 0.1013, LR: 0.000003, best val loss was: 0.0949
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1275], Train Loss: 0.2514, Val Loss: 0.1040, LR: 0.000003, best val loss was: 0.0949
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1276], Train Loss: 0.2402, Val Loss: 0.0997, LR: 0.000003, best val loss was: 0.0949
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1277], Train Loss: 0.2154, Val Loss: 0.1010, LR: 0.000003, best val loss was: 0.0949
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1278], Train Loss: 0.2617, Val Loss: 0.0934, LR: 0.000003, best val loss was: 0.0934
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1279], Train Loss: 0.2300, Val Loss: 0.1082, LR: 0.000003, best val loss was: 0.0934
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1280], Train Loss: 0.2456, Val Loss: 0.1036, LR: 0.000003, best val loss was: 0.0934
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1281], Train Loss: 0.2184, Val Loss: 0.1059, LR: 0.000003, best val loss was: 0.0934
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1282], Train Loss: 0.2378, Val Loss: 0.0974, LR: 0.000003, best val loss was: 0.0934
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1283], Train Loss: 0.2475, Val Loss: 0.1033, LR: 0.000003, best val loss was: 0.0934
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1284], Train Loss: 0.2209, Val Loss: 0.1014, LR: 0.000003, best val loss was: 0.0934
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1285], Train Loss: 0.2350, Val Loss: 0.1086, LR: 0.000003, best val loss was: 0.0934
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1286], Train Loss: 0.2283, Val Loss: 0.1077, LR: 0.000003, best val loss was: 0.0934
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1287], Train Loss: 0.2442, Val Loss: 0.0980, LR: 0.000003, best val loss was: 0.0934
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1288], Train Loss: 0.2475, Val Loss: 0.0947, LR: 0.000003, best val loss was: 0.0934
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1289], Train Loss: 0.2461, Val Loss: 0.0994, LR: 0.000003, best val loss was: 0.0934
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1290], Train Loss: 0.2472, Val Loss: 0.1007, LR: 0.000003, best val loss was: 0.0934
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1291], Train Loss: 0.2348, Val Loss: 0.1095, LR: 0.000003, best val loss was: 0.0934
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1292], Train Loss: 0.2604, Val Loss: 0.1055, LR: 0.000003, best val loss was: 0.0934
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1293], Train Loss: 0.2122, Val Loss: 0.1074, LR: 0.000003, best val loss was: 0.0934
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1294], Train Loss: 0.2350, Val Loss: 0.1066, LR: 0.000003, best val loss was: 0.0934
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1295], Train Loss: 0.2494, Val Loss: 0.1066, LR: 0.000003, best val loss was: 0.0934
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1296], Train Loss: 0.2318, Val Loss: 0.1079, LR: 0.000003, best val loss was: 0.0934
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1297], Train Loss: 0.2288, Val Loss: 0.0932, LR: 0.000003, best val loss was: 0.0932
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1298], Train Loss: 0.2407, Val Loss: 0.1017, LR: 0.000003, best val loss was: 0.0932
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1299], Train Loss: 0.2565, Val Loss: 0.1012, LR: 0.000003, best val loss was: 0.0932
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1300], Train Loss: 0.2288, Val Loss: 0.0991, LR: 0.000003, best val loss was: 0.0932
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1301], Train Loss: 0.2406, Val Loss: 0.1022, LR: 0.000003, best val loss was: 0.0932
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1302], Train Loss: 0.2316, Val Loss: 0.0948, LR: 0.000003, best val loss was: 0.0932
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1303], Train Loss: 0.2382, Val Loss: 0.0976, LR: 0.000003, best val loss was: 0.0932
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1304], Train Loss: 0.2505, Val Loss: 0.1056, LR: 0.000003, best val loss was: 0.0932
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1305], Train Loss: 0.2476, Val Loss: 0.1113, LR: 0.000003, best val loss was: 0.0932
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1306], Train Loss: 0.2337, Val Loss: 0.1067, LR: 0.000003, best val loss was: 0.0932
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1307], Train Loss: 0.2388, Val Loss: 0.1051, LR: 0.000003, best val loss was: 0.0932
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1308], Train Loss: 0.2518, Val Loss: 0.1058, LR: 0.000003, best val loss was: 0.0932
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1309], Train Loss: 0.2231, Val Loss: 0.1071, LR: 0.000003, best val loss was: 0.0932
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1310], Train Loss: 0.2321, Val Loss: 0.1022, LR: 0.000003, best val loss was: 0.0932
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1311], Train Loss: 0.2263, Val Loss: 0.1056, LR: 0.000003, best val loss was: 0.0932
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1312], Train Loss: 0.2283, Val Loss: 0.1030, LR: 0.000003, best val loss was: 0.0932
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1313], Train Loss: 0.2480, Val Loss: 0.1064, LR: 0.000003, best val loss was: 0.0932
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1314], Train Loss: 0.2563, Val Loss: 0.1044, LR: 0.000003, best val loss was: 0.0932
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1315], Train Loss: 0.2483, Val Loss: 0.1020, LR: 0.000003, best val loss was: 0.0932
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1316], Train Loss: 0.2322, Val Loss: 0.1043, LR: 0.000003, best val loss was: 0.0932
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1317], Train Loss: 0.2335, Val Loss: 0.1075, LR: 0.000003, best val loss was: 0.0932
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1318], Train Loss: 0.2519, Val Loss: 0.0908, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1319], Train Loss: 0.2310, Val Loss: 0.1059, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1320], Train Loss: 0.2626, Val Loss: 0.1079, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1321], Train Loss: 0.2352, Val Loss: 0.1071, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1322], Train Loss: 0.2108, Val Loss: 0.1025, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1323], Train Loss: 0.2540, Val Loss: 0.1092, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1324], Train Loss: 0.2398, Val Loss: 0.0968, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1325], Train Loss: 0.2460, Val Loss: 0.1082, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1326], Train Loss: 0.2603, Val Loss: 0.0990, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1327], Train Loss: 0.2234, Val Loss: 0.0988, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1328], Train Loss: 0.2397, Val Loss: 0.1037, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1329], Train Loss: 0.2354, Val Loss: 0.1043, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1330], Train Loss: 0.2510, Val Loss: 0.1011, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1331], Train Loss: 0.2126, Val Loss: 0.1039, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1332], Train Loss: 0.2359, Val Loss: 0.0964, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1333], Train Loss: 0.2289, Val Loss: 0.1074, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1334], Train Loss: 0.2471, Val Loss: 0.0960, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1335], Train Loss: 0.2285, Val Loss: 0.1046, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1336], Train Loss: 0.2485, Val Loss: 0.0983, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1337], Train Loss: 0.2339, Val Loss: 0.1084, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1338], Train Loss: 0.2558, Val Loss: 0.1033, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1339], Train Loss: 0.2544, Val Loss: 0.1105, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1340], Train Loss: 0.2405, Val Loss: 0.1040, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1341], Train Loss: 0.2405, Val Loss: 0.0948, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1342], Train Loss: 0.2297, Val Loss: 0.0959, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1343], Train Loss: 0.2298, Val Loss: 0.1005, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1344], Train Loss: 0.2478, Val Loss: 0.1091, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1345], Train Loss: 0.2231, Val Loss: 0.1032, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1346], Train Loss: 0.2368, Val Loss: 0.1049, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1347], Train Loss: 0.2368, Val Loss: 0.0943, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1348], Train Loss: 0.2637, Val Loss: 0.0996, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1349], Train Loss: 0.2405, Val Loss: 0.1036, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1350], Train Loss: 0.2374, Val Loss: 0.1057, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1351], Train Loss: 0.2333, Val Loss: 0.1043, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1352], Train Loss: 0.2523, Val Loss: 0.1080, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1353], Train Loss: 0.2543, Val Loss: 0.1100, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1354], Train Loss: 0.2346, Val Loss: 0.1088, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1355], Train Loss: 0.2185, Val Loss: 0.1090, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1356], Train Loss: 0.2347, Val Loss: 0.1046, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1357], Train Loss: 0.2406, Val Loss: 0.1098, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1358], Train Loss: 0.2593, Val Loss: 0.0999, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1359], Train Loss: 0.2386, Val Loss: 0.1069, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1360], Train Loss: 0.2176, Val Loss: 0.0953, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1361], Train Loss: 0.2331, Val Loss: 0.0958, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1362], Train Loss: 0.2389, Val Loss: 0.0963, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1363], Train Loss: 0.2256, Val Loss: 0.1099, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1364], Train Loss: 0.2298, Val Loss: 0.1040, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1365], Train Loss: 0.2392, Val Loss: 0.0956, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1366], Train Loss: 0.2297, Val Loss: 0.1112, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1367], Train Loss: 0.2306, Val Loss: 0.0963, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1368], Train Loss: 0.2192, Val Loss: 0.1114, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1369], Train Loss: 0.2374, Val Loss: 0.1065, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1370], Train Loss: 0.2603, Val Loss: 0.1064, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1371], Train Loss: 0.2196, Val Loss: 0.1036, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1372], Train Loss: 0.2299, Val Loss: 0.1065, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1373], Train Loss: 0.2263, Val Loss: 0.0985, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1374], Train Loss: 0.2283, Val Loss: 0.1016, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1375], Train Loss: 0.2405, Val Loss: 0.0985, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1376], Train Loss: 0.2239, Val Loss: 0.1169, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1377], Train Loss: 0.2411, Val Loss: 0.0997, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1378], Train Loss: 0.2324, Val Loss: 0.1004, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1379], Train Loss: 0.2331, Val Loss: 0.1094, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1380], Train Loss: 0.2389, Val Loss: 0.1088, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1381], Train Loss: 0.2495, Val Loss: 0.1043, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1382], Train Loss: 0.2211, Val Loss: 0.1041, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1383], Train Loss: 0.2386, Val Loss: 0.1192, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1384], Train Loss: 0.2507, Val Loss: 0.1072, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1385], Train Loss: 0.2314, Val Loss: 0.1002, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1386], Train Loss: 0.2031, Val Loss: 0.1055, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1387], Train Loss: 0.2426, Val Loss: 0.0988, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1388], Train Loss: 0.2377, Val Loss: 0.0959, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1389], Train Loss: 0.2477, Val Loss: 0.1047, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1390], Train Loss: 0.2389, Val Loss: 0.1020, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1391], Train Loss: 0.2343, Val Loss: 0.0986, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1392], Train Loss: 0.2171, Val Loss: 0.1018, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1393], Train Loss: 0.2260, Val Loss: 0.0999, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1394], Train Loss: 0.2342, Val Loss: 0.1069, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1395], Train Loss: 0.2297, Val Loss: 0.1021, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1396], Train Loss: 0.2322, Val Loss: 0.1065, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1397], Train Loss: 0.2427, Val Loss: 0.1126, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1398], Train Loss: 0.2564, Val Loss: 0.1065, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1399], Train Loss: 0.2056, Val Loss: 0.1046, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1400], Train Loss: 0.2534, Val Loss: 0.1015, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1401], Train Loss: 0.2453, Val Loss: 0.1032, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1402], Train Loss: 0.2460, Val Loss: 0.1039, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1403], Train Loss: 0.2228, Val Loss: 0.1057, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1404], Train Loss: 0.2282, Val Loss: 0.1059, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1405], Train Loss: 0.2125, Val Loss: 0.1051, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1406], Train Loss: 0.2174, Val Loss: 0.1055, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1407], Train Loss: 0.2135, Val Loss: 0.0999, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1408], Train Loss: 0.2425, Val Loss: 0.1100, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1409], Train Loss: 0.2306, Val Loss: 0.1004, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1410], Train Loss: 0.2132, Val Loss: 0.1040, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1411], Train Loss: 0.2239, Val Loss: 0.1024, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1412], Train Loss: 0.2386, Val Loss: 0.1049, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1413], Train Loss: 0.2198, Val Loss: 0.1049, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1414], Train Loss: 0.2293, Val Loss: 0.1118, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1415], Train Loss: 0.2411, Val Loss: 0.1044, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1416], Train Loss: 0.2269, Val Loss: 0.1047, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1417], Train Loss: 0.2239, Val Loss: 0.1086, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1418], Train Loss: 0.2190, Val Loss: 0.1116, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1419], Train Loss: 0.2336, Val Loss: 0.1054, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1420], Train Loss: 0.2326, Val Loss: 0.1007, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1421], Train Loss: 0.2378, Val Loss: 0.1014, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1422], Train Loss: 0.2258, Val Loss: 0.1019, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1423], Train Loss: 0.2389, Val Loss: 0.1058, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1424], Train Loss: 0.2422, Val Loss: 0.1037, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1425], Train Loss: 0.2280, Val Loss: 0.1123, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1426], Train Loss: 0.2133, Val Loss: 0.1124, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1427], Train Loss: 0.2272, Val Loss: 0.1056, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1428], Train Loss: 0.2202, Val Loss: 0.0998, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1429], Train Loss: 0.2522, Val Loss: 0.1062, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1430], Train Loss: 0.2379, Val Loss: 0.1029, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1431], Train Loss: 0.2472, Val Loss: 0.1056, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1432], Train Loss: 0.2367, Val Loss: 0.1002, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1433], Train Loss: 0.2379, Val Loss: 0.1109, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1434], Train Loss: 0.2336, Val Loss: 0.1046, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1435], Train Loss: 0.2324, Val Loss: 0.1117, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1436], Train Loss: 0.2510, Val Loss: 0.0980, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1437], Train Loss: 0.2174, Val Loss: 0.1103, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1438], Train Loss: 0.2174, Val Loss: 0.1037, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1439], Train Loss: 0.2221, Val Loss: 0.1076, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1440], Train Loss: 0.2235, Val Loss: 0.1205, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1441], Train Loss: 0.2075, Val Loss: 0.1065, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1442], Train Loss: 0.2375, Val Loss: 0.1079, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1443], Train Loss: 0.2251, Val Loss: 0.1045, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1444], Train Loss: 0.2374, Val Loss: 0.1097, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1445], Train Loss: 0.2269, Val Loss: 0.1070, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1446], Train Loss: 0.2122, Val Loss: 0.1056, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1447], Train Loss: 0.2166, Val Loss: 0.1070, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1448], Train Loss: 0.2373, Val Loss: 0.1028, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1449], Train Loss: 0.2406, Val Loss: 0.1014, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1450], Train Loss: 0.2085, Val Loss: 0.1088, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1451], Train Loss: 0.2137, Val Loss: 0.1094, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1452], Train Loss: 0.2101, Val Loss: 0.1044, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1453], Train Loss: 0.2323, Val Loss: 0.1183, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1454], Train Loss: 0.2239, Val Loss: 0.1089, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1455], Train Loss: 0.2357, Val Loss: 0.1120, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1456], Train Loss: 0.2331, Val Loss: 0.1083, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1457], Train Loss: 0.2246, Val Loss: 0.1106, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1458], Train Loss: 0.2365, Val Loss: 0.0997, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1459], Train Loss: 0.2139, Val Loss: 0.1143, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1460], Train Loss: 0.2335, Val Loss: 0.1088, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1461], Train Loss: 0.1999, Val Loss: 0.1042, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1462], Train Loss: 0.2287, Val Loss: 0.1051, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1463], Train Loss: 0.2281, Val Loss: 0.1115, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1464], Train Loss: 0.2314, Val Loss: 0.1037, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1465], Train Loss: 0.2259, Val Loss: 0.1013, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1466], Train Loss: 0.2307, Val Loss: 0.0953, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1467], Train Loss: 0.2350, Val Loss: 0.1143, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1468], Train Loss: 0.2230, Val Loss: 0.1107, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1469], Train Loss: 0.2387, Val Loss: 0.0939, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1470], Train Loss: 0.2076, Val Loss: 0.1086, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1471], Train Loss: 0.2129, Val Loss: 0.1139, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1472], Train Loss: 0.2325, Val Loss: 0.1136, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1473], Train Loss: 0.2419, Val Loss: 0.1040, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1474], Train Loss: 0.2213, Val Loss: 0.1148, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1475], Train Loss: 0.2189, Val Loss: 0.1090, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1476], Train Loss: 0.2357, Val Loss: 0.1075, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1477], Train Loss: 0.2336, Val Loss: 0.1085, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1478], Train Loss: 0.2114, Val Loss: 0.1199, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1479], Train Loss: 0.2115, Val Loss: 0.1111, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1480], Train Loss: 0.2380, Val Loss: 0.1125, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1481], Train Loss: 0.2136, Val Loss: 0.1098, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1482], Train Loss: 0.2169, Val Loss: 0.1042, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1483], Train Loss: 0.2129, Val Loss: 0.1085, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1484], Train Loss: 0.2274, Val Loss: 0.1197, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1485], Train Loss: 0.2358, Val Loss: 0.1214, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1486], Train Loss: 0.2280, Val Loss: 0.1027, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1487], Train Loss: 0.2449, Val Loss: 0.1115, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1488], Train Loss: 0.2223, Val Loss: 0.1015, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1489], Train Loss: 0.2206, Val Loss: 0.1122, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1490], Train Loss: 0.1960, Val Loss: 0.1145, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1491], Train Loss: 0.2400, Val Loss: 0.1072, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1492], Train Loss: 0.2251, Val Loss: 0.1048, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1493], Train Loss: 0.2343, Val Loss: 0.1130, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1494], Train Loss: 0.2322, Val Loss: 0.1075, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1495], Train Loss: 0.2292, Val Loss: 0.1045, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1496], Train Loss: 0.2224, Val Loss: 0.1166, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1497], Train Loss: 0.2458, Val Loss: 0.1156, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1498], Train Loss: 0.2021, Val Loss: 0.1102, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1499], Train Loss: 0.2418, Val Loss: 0.1111, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1500], Train Loss: 0.2287, Val Loss: 0.1080, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1501], Train Loss: 0.2264, Val Loss: 0.1205, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1502], Train Loss: 0.2396, Val Loss: 0.1022, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1503], Train Loss: 0.2356, Val Loss: 0.1012, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1504], Train Loss: 0.2246, Val Loss: 0.1094, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1505], Train Loss: 0.2466, Val Loss: 0.1186, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1506], Train Loss: 0.2389, Val Loss: 0.1059, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1507], Train Loss: 0.2393, Val Loss: 0.1029, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1508], Train Loss: 0.2216, Val Loss: 0.1108, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1509], Train Loss: 0.2383, Val Loss: 0.1076, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1510], Train Loss: 0.2251, Val Loss: 0.0963, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1511], Train Loss: 0.2149, Val Loss: 0.1149, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1512], Train Loss: 0.2350, Val Loss: 0.1056, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1513], Train Loss: 0.2389, Val Loss: 0.1160, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1514], Train Loss: 0.2398, Val Loss: 0.1121, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1515], Train Loss: 0.2299, Val Loss: 0.1162, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1516], Train Loss: 0.2266, Val Loss: 0.1125, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1517], Train Loss: 0.2204, Val Loss: 0.1152, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1518], Train Loss: 0.2169, Val Loss: 0.1154, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1519], Train Loss: 0.2111, Val Loss: 0.1113, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1520], Train Loss: 0.2257, Val Loss: 0.1083, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1521], Train Loss: 0.2301, Val Loss: 0.1107, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1522], Train Loss: 0.2277, Val Loss: 0.1219, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1523], Train Loss: 0.2110, Val Loss: 0.1061, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1524], Train Loss: 0.2190, Val Loss: 0.1084, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1525], Train Loss: 0.2326, Val Loss: 0.1125, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1526], Train Loss: 0.2128, Val Loss: 0.1122, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1527], Train Loss: 0.2247, Val Loss: 0.1191, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1528], Train Loss: 0.2206, Val Loss: 0.1057, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1529], Train Loss: 0.2302, Val Loss: 0.1096, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1530], Train Loss: 0.2303, Val Loss: 0.1069, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1531], Train Loss: 0.2168, Val Loss: 0.1219, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1532], Train Loss: 0.2169, Val Loss: 0.1178, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1533], Train Loss: 0.2289, Val Loss: 0.1074, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1534], Train Loss: 0.2325, Val Loss: 0.1196, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1535], Train Loss: 0.2138, Val Loss: 0.1056, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1536], Train Loss: 0.2173, Val Loss: 0.1114, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1537], Train Loss: 0.2280, Val Loss: 0.1126, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1538], Train Loss: 0.2175, Val Loss: 0.1126, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1539], Train Loss: 0.2218, Val Loss: 0.1163, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1540], Train Loss: 0.2345, Val Loss: 0.1203, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1541], Train Loss: 0.2209, Val Loss: 0.1059, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1542], Train Loss: 0.2376, Val Loss: 0.1158, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1543], Train Loss: 0.2121, Val Loss: 0.1101, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1544], Train Loss: 0.2306, Val Loss: 0.1187, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1545], Train Loss: 0.2275, Val Loss: 0.1140, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1546], Train Loss: 0.2273, Val Loss: 0.1155, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1547], Train Loss: 0.2335, Val Loss: 0.1209, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1548], Train Loss: 0.2224, Val Loss: 0.1240, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1549], Train Loss: 0.2182, Val Loss: 0.0993, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1550], Train Loss: 0.2277, Val Loss: 0.1098, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1551], Train Loss: 0.2348, Val Loss: 0.1193, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1552], Train Loss: 0.2165, Val Loss: 0.1061, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1553], Train Loss: 0.2095, Val Loss: 0.1108, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1554], Train Loss: 0.2249, Val Loss: 0.1102, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1555], Train Loss: 0.2165, Val Loss: 0.1022, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1556], Train Loss: 0.2171, Val Loss: 0.1095, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1557], Train Loss: 0.2055, Val Loss: 0.1141, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1558], Train Loss: 0.2300, Val Loss: 0.1248, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1559], Train Loss: 0.2088, Val Loss: 0.1190, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1560], Train Loss: 0.2286, Val Loss: 0.1154, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1561], Train Loss: 0.2370, Val Loss: 0.1202, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1562], Train Loss: 0.2299, Val Loss: 0.1190, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1563], Train Loss: 0.2277, Val Loss: 0.1166, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1564], Train Loss: 0.2249, Val Loss: 0.1232, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1565], Train Loss: 0.2044, Val Loss: 0.1182, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1566], Train Loss: 0.2049, Val Loss: 0.1215, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1567], Train Loss: 0.2200, Val Loss: 0.1114, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1568], Train Loss: 0.2292, Val Loss: 0.1213, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1569], Train Loss: 0.2111, Val Loss: 0.1172, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1570], Train Loss: 0.2245, Val Loss: 0.1199, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1571], Train Loss: 0.2355, Val Loss: 0.1191, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1572], Train Loss: 0.2197, Val Loss: 0.1168, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1573], Train Loss: 0.2383, Val Loss: 0.1090, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1574], Train Loss: 0.2252, Val Loss: 0.1066, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1575], Train Loss: 0.2111, Val Loss: 0.1072, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1576], Train Loss: 0.2163, Val Loss: 0.1177, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1577], Train Loss: 0.2303, Val Loss: 0.1185, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1578], Train Loss: 0.2329, Val Loss: 0.1208, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1579], Train Loss: 0.2093, Val Loss: 0.1230, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1580], Train Loss: 0.2188, Val Loss: 0.1188, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1581], Train Loss: 0.2284, Val Loss: 0.1152, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1582], Train Loss: 0.2206, Val Loss: 0.1032, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1583], Train Loss: 0.2239, Val Loss: 0.1172, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1584], Train Loss: 0.2225, Val Loss: 0.1171, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1585], Train Loss: 0.2124, Val Loss: 0.1198, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1586], Train Loss: 0.2270, Val Loss: 0.1142, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1587], Train Loss: 0.2341, Val Loss: 0.1148, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1588], Train Loss: 0.2280, Val Loss: 0.1145, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1589], Train Loss: 0.2218, Val Loss: 0.1082, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1590], Train Loss: 0.2347, Val Loss: 0.1238, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1591], Train Loss: 0.1979, Val Loss: 0.1370, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1592], Train Loss: 0.2161, Val Loss: 0.1205, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1593], Train Loss: 0.2217, Val Loss: 0.1087, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1594], Train Loss: 0.2381, Val Loss: 0.1270, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1595], Train Loss: 0.2355, Val Loss: 0.1146, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1596], Train Loss: 0.2098, Val Loss: 0.1211, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1597], Train Loss: 0.2183, Val Loss: 0.1255, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1598], Train Loss: 0.1965, Val Loss: 0.1176, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1599], Train Loss: 0.2355, Val Loss: 0.1234, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1600], Train Loss: 0.2090, Val Loss: 0.1200, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1601], Train Loss: 0.2365, Val Loss: 0.1175, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1602], Train Loss: 0.2351, Val Loss: 0.1126, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1603], Train Loss: 0.2182, Val Loss: 0.1267, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1604], Train Loss: 0.2415, Val Loss: 0.1277, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1605], Train Loss: 0.2077, Val Loss: 0.1118, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1606], Train Loss: 0.2282, Val Loss: 0.1113, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1607], Train Loss: 0.2187, Val Loss: 0.1291, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1608], Train Loss: 0.2230, Val Loss: 0.1167, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1609], Train Loss: 0.2064, Val Loss: 0.1176, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1610], Train Loss: 0.2154, Val Loss: 0.1246, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1611], Train Loss: 0.2312, Val Loss: 0.1207, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1612], Train Loss: 0.2109, Val Loss: 0.1206, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1613], Train Loss: 0.2194, Val Loss: 0.1195, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1614], Train Loss: 0.2144, Val Loss: 0.1166, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1615], Train Loss: 0.2320, Val Loss: 0.1177, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1616], Train Loss: 0.2351, Val Loss: 0.1197, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1617], Train Loss: 0.2181, Val Loss: 0.1137, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1618], Train Loss: 0.2298, Val Loss: 0.1132, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1619], Train Loss: 0.2081, Val Loss: 0.1283, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1620], Train Loss: 0.2382, Val Loss: 0.1220, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1621], Train Loss: 0.2063, Val Loss: 0.1253, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1622], Train Loss: 0.2241, Val Loss: 0.1365, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1623], Train Loss: 0.2066, Val Loss: 0.1177, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1624], Train Loss: 0.2290, Val Loss: 0.1284, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1625], Train Loss: 0.2190, Val Loss: 0.1216, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1626], Train Loss: 0.2278, Val Loss: 0.1263, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1627], Train Loss: 0.2226, Val Loss: 0.1245, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1628], Train Loss: 0.2164, Val Loss: 0.1176, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1629], Train Loss: 0.2330, Val Loss: 0.1220, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1630], Train Loss: 0.2190, Val Loss: 0.1248, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1631], Train Loss: 0.2044, Val Loss: 0.1238, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1632], Train Loss: 0.2127, Val Loss: 0.1253, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1633], Train Loss: 0.2180, Val Loss: 0.1219, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1634], Train Loss: 0.2170, Val Loss: 0.1153, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1635], Train Loss: 0.2339, Val Loss: 0.1419, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1636], Train Loss: 0.2309, Val Loss: 0.1288, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1637], Train Loss: 0.2077, Val Loss: 0.1283, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1638], Train Loss: 0.2120, Val Loss: 0.1232, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1639], Train Loss: 0.2230, Val Loss: 0.1083, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1640], Train Loss: 0.2141, Val Loss: 0.1299, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1641], Train Loss: 0.2421, Val Loss: 0.1196, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1642], Train Loss: 0.2075, Val Loss: 0.1209, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1643], Train Loss: 0.2328, Val Loss: 0.1286, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1644], Train Loss: 0.2139, Val Loss: 0.1203, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1645], Train Loss: 0.2251, Val Loss: 0.1317, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1646], Train Loss: 0.2295, Val Loss: 0.1205, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1647], Train Loss: 0.2222, Val Loss: 0.1197, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1648], Train Loss: 0.2392, Val Loss: 0.1224, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1649], Train Loss: 0.2260, Val Loss: 0.1210, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1650], Train Loss: 0.2228, Val Loss: 0.1309, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1651], Train Loss: 0.2151, Val Loss: 0.1281, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1652], Train Loss: 0.2278, Val Loss: 0.1103, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1653], Train Loss: 0.2160, Val Loss: 0.1267, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1654], Train Loss: 0.2115, Val Loss: 0.1317, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1655], Train Loss: 0.2563, Val Loss: 0.1228, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1656], Train Loss: 0.2109, Val Loss: 0.1264, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1657], Train Loss: 0.2132, Val Loss: 0.1194, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1658], Train Loss: 0.2283, Val Loss: 0.1214, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1659], Train Loss: 0.2250, Val Loss: 0.1249, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1660], Train Loss: 0.2125, Val Loss: 0.1300, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1661], Train Loss: 0.2352, Val Loss: 0.1301, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1662], Train Loss: 0.2010, Val Loss: 0.1161, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1663], Train Loss: 0.2173, Val Loss: 0.1295, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1664], Train Loss: 0.2126, Val Loss: 0.1141, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1665], Train Loss: 0.2294, Val Loss: 0.1320, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1666], Train Loss: 0.2123, Val Loss: 0.1121, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1667], Train Loss: 0.2226, Val Loss: 0.1308, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1668], Train Loss: 0.2117, Val Loss: 0.1203, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1669], Train Loss: 0.1927, Val Loss: 0.1313, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1670], Train Loss: 0.2049, Val Loss: 0.1196, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1671], Train Loss: 0.2176, Val Loss: 0.1289, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1672], Train Loss: 0.2043, Val Loss: 0.1162, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1673], Train Loss: 0.2300, Val Loss: 0.1309, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1674], Train Loss: 0.2256, Val Loss: 0.1299, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1675], Train Loss: 0.2135, Val Loss: 0.1118, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1676], Train Loss: 0.2090, Val Loss: 0.1168, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1677], Train Loss: 0.2312, Val Loss: 0.1220, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1678], Train Loss: 0.2253, Val Loss: 0.1285, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1679], Train Loss: 0.2172, Val Loss: 0.1254, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1680], Train Loss: 0.2250, Val Loss: 0.1371, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1681], Train Loss: 0.2171, Val Loss: 0.1316, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1682], Train Loss: 0.2236, Val Loss: 0.1288, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1683], Train Loss: 0.2094, Val Loss: 0.1318, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1684], Train Loss: 0.2224, Val Loss: 0.1029, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1685], Train Loss: 0.2258, Val Loss: 0.1146, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1686], Train Loss: 0.2200, Val Loss: 0.1432, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1687], Train Loss: 0.2069, Val Loss: 0.1277, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1688], Train Loss: 0.2240, Val Loss: 0.1246, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1689], Train Loss: 0.2232, Val Loss: 0.1275, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1690], Train Loss: 0.2316, Val Loss: 0.1231, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1691], Train Loss: 0.2139, Val Loss: 0.1306, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1692], Train Loss: 0.2239, Val Loss: 0.1253, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1693], Train Loss: 0.2047, Val Loss: 0.1300, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1694], Train Loss: 0.2198, Val Loss: 0.1227, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1695], Train Loss: 0.2345, Val Loss: 0.1210, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1696], Train Loss: 0.2183, Val Loss: 0.1217, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1697], Train Loss: 0.2373, Val Loss: 0.1192, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1698], Train Loss: 0.1900, Val Loss: 0.1309, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1699], Train Loss: 0.2219, Val Loss: 0.1232, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1700], Train Loss: 0.2236, Val Loss: 0.1208, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1701], Train Loss: 0.2193, Val Loss: 0.1353, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1702], Train Loss: 0.2244, Val Loss: 0.1247, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1703], Train Loss: 0.2378, Val Loss: 0.1213, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1704], Train Loss: 0.2398, Val Loss: 0.1174, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1705], Train Loss: 0.2087, Val Loss: 0.1301, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1706], Train Loss: 0.1905, Val Loss: 0.1260, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1707], Train Loss: 0.2119, Val Loss: 0.1237, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1708], Train Loss: 0.2203, Val Loss: 0.1304, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1709], Train Loss: 0.2288, Val Loss: 0.1202, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1710], Train Loss: 0.2182, Val Loss: 0.1352, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1711], Train Loss: 0.2275, Val Loss: 0.1343, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1712], Train Loss: 0.2289, Val Loss: 0.1329, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1713], Train Loss: 0.2213, Val Loss: 0.1185, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1714], Train Loss: 0.2219, Val Loss: 0.1231, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1715], Train Loss: 0.2077, Val Loss: 0.1258, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1716], Train Loss: 0.2132, Val Loss: 0.1343, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1717], Train Loss: 0.2227, Val Loss: 0.1220, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1718], Train Loss: 0.2291, Val Loss: 0.1322, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1719], Train Loss: 0.2162, Val Loss: 0.1400, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1720], Train Loss: 0.2147, Val Loss: 0.1354, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1721], Train Loss: 0.2105, Val Loss: 0.1303, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1722], Train Loss: 0.2153, Val Loss: 0.1387, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1723], Train Loss: 0.2119, Val Loss: 0.1330, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1724], Train Loss: 0.2191, Val Loss: 0.1432, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1725], Train Loss: 0.2124, Val Loss: 0.1374, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1726], Train Loss: 0.2240, Val Loss: 0.1255, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1727], Train Loss: 0.2071, Val Loss: 0.1131, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1728], Train Loss: 0.2368, Val Loss: 0.1365, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1729], Train Loss: 0.2302, Val Loss: 0.1235, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1730], Train Loss: 0.2290, Val Loss: 0.1352, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1731], Train Loss: 0.2242, Val Loss: 0.1257, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1732], Train Loss: 0.2152, Val Loss: 0.1472, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1733], Train Loss: 0.2070, Val Loss: 0.1344, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1734], Train Loss: 0.2121, Val Loss: 0.1276, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1735], Train Loss: 0.2145, Val Loss: 0.1349, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1736], Train Loss: 0.2095, Val Loss: 0.1286, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1737], Train Loss: 0.2045, Val Loss: 0.1374, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1738], Train Loss: 0.2366, Val Loss: 0.1195, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1739], Train Loss: 0.2167, Val Loss: 0.1321, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1740], Train Loss: 0.2277, Val Loss: 0.1221, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1741], Train Loss: 0.2106, Val Loss: 0.1238, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1742], Train Loss: 0.2205, Val Loss: 0.1217, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1743], Train Loss: 0.2176, Val Loss: 0.1399, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1744], Train Loss: 0.2199, Val Loss: 0.1243, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1745], Train Loss: 0.2111, Val Loss: 0.1324, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1746], Train Loss: 0.2204, Val Loss: 0.1259, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1747], Train Loss: 0.2394, Val Loss: 0.1475, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1748], Train Loss: 0.2244, Val Loss: 0.1328, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1749], Train Loss: 0.2158, Val Loss: 0.1405, LR: 0.000003, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1750], Train Loss: 0.2181, Val Loss: 0.1162, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1751], Train Loss: 0.2415, Val Loss: 0.1196, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1752], Train Loss: 0.2120, Val Loss: 0.1270, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1753], Train Loss: 0.2192, Val Loss: 0.1284, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1754], Train Loss: 0.2172, Val Loss: 0.1253, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1755], Train Loss: 0.2101, Val Loss: 0.1299, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1756], Train Loss: 0.2261, Val Loss: 0.1335, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1757], Train Loss: 0.2154, Val Loss: 0.1341, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1758], Train Loss: 0.2095, Val Loss: 0.1202, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1759], Train Loss: 0.2115, Val Loss: 0.1336, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1760], Train Loss: 0.2296, Val Loss: 0.1360, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1761], Train Loss: 0.2161, Val Loss: 0.1319, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1762], Train Loss: 0.2338, Val Loss: 0.1361, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1763], Train Loss: 0.2315, Val Loss: 0.1287, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1764], Train Loss: 0.2315, Val Loss: 0.1312, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1765], Train Loss: 0.2125, Val Loss: 0.1321, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1766], Train Loss: 0.2052, Val Loss: 0.1212, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1767], Train Loss: 0.2116, Val Loss: 0.1168, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1768], Train Loss: 0.2253, Val Loss: 0.1261, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1769], Train Loss: 0.2209, Val Loss: 0.1284, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1770], Train Loss: 0.2001, Val Loss: 0.1303, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1771], Train Loss: 0.2245, Val Loss: 0.1412, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1772], Train Loss: 0.2011, Val Loss: 0.1231, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1773], Train Loss: 0.2022, Val Loss: 0.1196, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1774], Train Loss: 0.2319, Val Loss: 0.1506, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1775], Train Loss: 0.2210, Val Loss: 0.1350, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1776], Train Loss: 0.2140, Val Loss: 0.1302, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1777], Train Loss: 0.2106, Val Loss: 0.1191, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1778], Train Loss: 0.2138, Val Loss: 0.1241, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1779], Train Loss: 0.2222, Val Loss: 0.1291, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1780], Train Loss: 0.1982, Val Loss: 0.1350, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1781], Train Loss: 0.2456, Val Loss: 0.1336, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1782], Train Loss: 0.2244, Val Loss: 0.1339, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1783], Train Loss: 0.2306, Val Loss: 0.1335, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1784], Train Loss: 0.2057, Val Loss: 0.1213, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1785], Train Loss: 0.2305, Val Loss: 0.1229, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1786], Train Loss: 0.2066, Val Loss: 0.1193, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1787], Train Loss: 0.2173, Val Loss: 0.1354, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1788], Train Loss: 0.2046, Val Loss: 0.1457, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1789], Train Loss: 0.2194, Val Loss: 0.1476, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1790], Train Loss: 0.2127, Val Loss: 0.1386, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1791], Train Loss: 0.2174, Val Loss: 0.1351, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1792], Train Loss: 0.2257, Val Loss: 0.1394, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1793], Train Loss: 0.2272, Val Loss: 0.1287, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1794], Train Loss: 0.2173, Val Loss: 0.1305, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1795], Train Loss: 0.2074, Val Loss: 0.1324, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1796], Train Loss: 0.2054, Val Loss: 0.1334, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1797], Train Loss: 0.2152, Val Loss: 0.1258, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1798], Train Loss: 0.2238, Val Loss: 0.1309, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1799], Train Loss: 0.2084, Val Loss: 0.1251, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1800], Train Loss: 0.2210, Val Loss: 0.1282, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1801], Train Loss: 0.2082, Val Loss: 0.1411, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1802], Train Loss: 0.2263, Val Loss: 0.1376, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1803], Train Loss: 0.2295, Val Loss: 0.1417, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1804], Train Loss: 0.2187, Val Loss: 0.1282, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1805], Train Loss: 0.2409, Val Loss: 0.1367, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1806], Train Loss: 0.2372, Val Loss: 0.1377, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1807], Train Loss: 0.2177, Val Loss: 0.1231, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1808], Train Loss: 0.2271, Val Loss: 0.1402, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1809], Train Loss: 0.2265, Val Loss: 0.1375, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1810], Train Loss: 0.2193, Val Loss: 0.1326, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1811], Train Loss: 0.2022, Val Loss: 0.1380, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1812], Train Loss: 0.2160, Val Loss: 0.1258, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1813], Train Loss: 0.2158, Val Loss: 0.1491, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1814], Train Loss: 0.2179, Val Loss: 0.1240, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1815], Train Loss: 0.2186, Val Loss: 0.1245, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1816], Train Loss: 0.2089, Val Loss: 0.1358, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1817], Train Loss: 0.2205, Val Loss: 0.1230, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1818], Train Loss: 0.2289, Val Loss: 0.1273, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1819], Train Loss: 0.2265, Val Loss: 0.1251, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1820], Train Loss: 0.2146, Val Loss: 0.1242, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1821], Train Loss: 0.2115, Val Loss: 0.1351, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1822], Train Loss: 0.2194, Val Loss: 0.1328, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1823], Train Loss: 0.2136, Val Loss: 0.1367, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1824], Train Loss: 0.2219, Val Loss: 0.1373, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1825], Train Loss: 0.2359, Val Loss: 0.1338, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1826], Train Loss: 0.2003, Val Loss: 0.1425, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1827], Train Loss: 0.2004, Val Loss: 0.1334, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1828], Train Loss: 0.2293, Val Loss: 0.1188, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1829], Train Loss: 0.2207, Val Loss: 0.1330, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1830], Train Loss: 0.2250, Val Loss: 0.1348, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1831], Train Loss: 0.2163, Val Loss: 0.1343, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1832], Train Loss: 0.2114, Val Loss: 0.1166, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1833], Train Loss: 0.2366, Val Loss: 0.1285, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1834], Train Loss: 0.2116, Val Loss: 0.1375, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1835], Train Loss: 0.2158, Val Loss: 0.1501, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1836], Train Loss: 0.2405, Val Loss: 0.1458, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1837], Train Loss: 0.2501, Val Loss: 0.1367, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1838], Train Loss: 0.2109, Val Loss: 0.1411, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1839], Train Loss: 0.2118, Val Loss: 0.1347, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1840], Train Loss: 0.2363, Val Loss: 0.1222, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1841], Train Loss: 0.2221, Val Loss: 0.1367, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1842], Train Loss: 0.2182, Val Loss: 0.1329, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1843], Train Loss: 0.2160, Val Loss: 0.1198, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1844], Train Loss: 0.2447, Val Loss: 0.1371, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1845], Train Loss: 0.2296, Val Loss: 0.1268, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1846], Train Loss: 0.2164, Val Loss: 0.1250, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1847], Train Loss: 0.2284, Val Loss: 0.1398, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1848], Train Loss: 0.2046, Val Loss: 0.1461, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1849], Train Loss: 0.2202, Val Loss: 0.1138, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1850], Train Loss: 0.2134, Val Loss: 0.1344, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1851], Train Loss: 0.2268, Val Loss: 0.1254, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1852], Train Loss: 0.2128, Val Loss: 0.1334, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1853], Train Loss: 0.2211, Val Loss: 0.1224, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1854], Train Loss: 0.2144, Val Loss: 0.1291, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1855], Train Loss: 0.2164, Val Loss: 0.1364, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1856], Train Loss: 0.2176, Val Loss: 0.1317, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1857], Train Loss: 0.2101, Val Loss: 0.1349, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1858], Train Loss: 0.2195, Val Loss: 0.1391, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1859], Train Loss: 0.2239, Val Loss: 0.1421, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1860], Train Loss: 0.2184, Val Loss: 0.1564, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1861], Train Loss: 0.2255, Val Loss: 0.1504, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1862], Train Loss: 0.2274, Val Loss: 0.1423, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1863], Train Loss: 0.2343, Val Loss: 0.1247, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1864], Train Loss: 0.2198, Val Loss: 0.1433, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1865], Train Loss: 0.2128, Val Loss: 0.1359, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1866], Train Loss: 0.2010, Val Loss: 0.1364, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1867], Train Loss: 0.2139, Val Loss: 0.1320, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1868], Train Loss: 0.2195, Val Loss: 0.1269, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1869], Train Loss: 0.2115, Val Loss: 0.1465, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1870], Train Loss: 0.2210, Val Loss: 0.1340, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1871], Train Loss: 0.2167, Val Loss: 0.1182, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1872], Train Loss: 0.2239, Val Loss: 0.1425, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1873], Train Loss: 0.2117, Val Loss: 0.1248, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1874], Train Loss: 0.2021, Val Loss: 0.1241, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1875], Train Loss: 0.2227, Val Loss: 0.1459, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1876], Train Loss: 0.2420, Val Loss: 0.1413, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1877], Train Loss: 0.2172, Val Loss: 0.1348, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1878], Train Loss: 0.2104, Val Loss: 0.1283, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1879], Train Loss: 0.2236, Val Loss: 0.1336, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1880], Train Loss: 0.2264, Val Loss: 0.1191, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1881], Train Loss: 0.1980, Val Loss: 0.1577, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1882], Train Loss: 0.2171, Val Loss: 0.1383, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1883], Train Loss: 0.2150, Val Loss: 0.1249, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1884], Train Loss: 0.2053, Val Loss: 0.1403, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1885], Train Loss: 0.2207, Val Loss: 0.1413, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1886], Train Loss: 0.2343, Val Loss: 0.1368, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1887], Train Loss: 0.2003, Val Loss: 0.1324, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1888], Train Loss: 0.2292, Val Loss: 0.1471, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1889], Train Loss: 0.2245, Val Loss: 0.1424, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1890], Train Loss: 0.2292, Val Loss: 0.1377, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1891], Train Loss: 0.2231, Val Loss: 0.1328, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1892], Train Loss: 0.2158, Val Loss: 0.1384, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1893], Train Loss: 0.2346, Val Loss: 0.1366, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1894], Train Loss: 0.2081, Val Loss: 0.1305, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1895], Train Loss: 0.2088, Val Loss: 0.1263, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1896], Train Loss: 0.2139, Val Loss: 0.1370, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1897], Train Loss: 0.2180, Val Loss: 0.1455, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1898], Train Loss: 0.2288, Val Loss: 0.1438, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1899], Train Loss: 0.2228, Val Loss: 0.1575, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1900], Train Loss: 0.2151, Val Loss: 0.1266, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1901], Train Loss: 0.2032, Val Loss: 0.1415, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1902], Train Loss: 0.2163, Val Loss: 0.1422, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1903], Train Loss: 0.2161, Val Loss: 0.1327, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1904], Train Loss: 0.2237, Val Loss: 0.1336, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1905], Train Loss: 0.2197, Val Loss: 0.1482, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1906], Train Loss: 0.2104, Val Loss: 0.1312, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1907], Train Loss: 0.2240, Val Loss: 0.1547, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1908], Train Loss: 0.2012, Val Loss: 0.1579, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1909], Train Loss: 0.2123, Val Loss: 0.1270, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1910], Train Loss: 0.2328, Val Loss: 0.1148, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1911], Train Loss: 0.2051, Val Loss: 0.1371, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1912], Train Loss: 0.2137, Val Loss: 0.1400, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1913], Train Loss: 0.2267, Val Loss: 0.1465, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1914], Train Loss: 0.2011, Val Loss: 0.1426, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1915], Train Loss: 0.2075, Val Loss: 0.1383, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1916], Train Loss: 0.2120, Val Loss: 0.1330, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1917], Train Loss: 0.2316, Val Loss: 0.1329, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1918], Train Loss: 0.2225, Val Loss: 0.1263, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1919], Train Loss: 0.2123, Val Loss: 0.1241, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1920], Train Loss: 0.2046, Val Loss: 0.1376, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1921], Train Loss: 0.2226, Val Loss: 0.1306, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1922], Train Loss: 0.1954, Val Loss: 0.1289, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1923], Train Loss: 0.2256, Val Loss: 0.1267, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1924], Train Loss: 0.2122, Val Loss: 0.1230, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1925], Train Loss: 0.2222, Val Loss: 0.1230, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1926], Train Loss: 0.2222, Val Loss: 0.1373, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1927], Train Loss: 0.2299, Val Loss: 0.1317, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1928], Train Loss: 0.2143, Val Loss: 0.1350, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1929], Train Loss: 0.2183, Val Loss: 0.1398, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1930], Train Loss: 0.2206, Val Loss: 0.1334, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1931], Train Loss: 0.2213, Val Loss: 0.1277, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1932], Train Loss: 0.2183, Val Loss: 0.1355, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1933], Train Loss: 0.2171, Val Loss: 0.1393, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1934], Train Loss: 0.2043, Val Loss: 0.1374, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1935], Train Loss: 0.2188, Val Loss: 0.1377, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1936], Train Loss: 0.2140, Val Loss: 0.1337, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1937], Train Loss: 0.1998, Val Loss: 0.1429, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1938], Train Loss: 0.2200, Val Loss: 0.1291, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1939], Train Loss: 0.2109, Val Loss: 0.1337, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1940], Train Loss: 0.2143, Val Loss: 0.1312, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1941], Train Loss: 0.2137, Val Loss: 0.1179, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1942], Train Loss: 0.2258, Val Loss: 0.1384, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1943], Train Loss: 0.2298, Val Loss: 0.1283, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1944], Train Loss: 0.2335, Val Loss: 0.1254, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1945], Train Loss: 0.2309, Val Loss: 0.1392, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1946], Train Loss: 0.2382, Val Loss: 0.1372, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1947], Train Loss: 0.2253, Val Loss: 0.1288, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1948], Train Loss: 0.2202, Val Loss: 0.1458, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1949], Train Loss: 0.2148, Val Loss: 0.1064, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1950], Train Loss: 0.2179, Val Loss: 0.1277, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1951], Train Loss: 0.2011, Val Loss: 0.1389, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1952], Train Loss: 0.2206, Val Loss: 0.1419, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1953], Train Loss: 0.2154, Val Loss: 0.1407, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1954], Train Loss: 0.2327, Val Loss: 0.1309, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1955], Train Loss: 0.2223, Val Loss: 0.1309, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1956], Train Loss: 0.2293, Val Loss: 0.1285, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1957], Train Loss: 0.2198, Val Loss: 0.1325, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1958], Train Loss: 0.2189, Val Loss: 0.1274, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1959], Train Loss: 0.2358, Val Loss: 0.1316, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1960], Train Loss: 0.2215, Val Loss: 0.1431, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1961], Train Loss: 0.2169, Val Loss: 0.1192, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1962], Train Loss: 0.2119, Val Loss: 0.1432, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1963], Train Loss: 0.2124, Val Loss: 0.1372, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1964], Train Loss: 0.2186, Val Loss: 0.1437, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1965], Train Loss: 0.2206, Val Loss: 0.1303, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1966], Train Loss: 0.2339, Val Loss: 0.1337, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1967], Train Loss: 0.2010, Val Loss: 0.1455, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1968], Train Loss: 0.2112, Val Loss: 0.1349, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1969], Train Loss: 0.2229, Val Loss: 0.1431, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1970], Train Loss: 0.2350, Val Loss: 0.1357, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1971], Train Loss: 0.2311, Val Loss: 0.1359, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1972], Train Loss: 0.2123, Val Loss: 0.1319, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1973], Train Loss: 0.2232, Val Loss: 0.1534, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1974], Train Loss: 0.2280, Val Loss: 0.1370, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1975], Train Loss: 0.2200, Val Loss: 0.1489, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1976], Train Loss: 0.2304, Val Loss: 0.1403, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1977], Train Loss: 0.2250, Val Loss: 0.1336, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1978], Train Loss: 0.2264, Val Loss: 0.1248, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1979], Train Loss: 0.2249, Val Loss: 0.1286, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1980], Train Loss: 0.2131, Val Loss: 0.1277, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1981], Train Loss: 0.2137, Val Loss: 0.1396, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1982], Train Loss: 0.2244, Val Loss: 0.1403, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1983], Train Loss: 0.2202, Val Loss: 0.1422, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1984], Train Loss: 0.2236, Val Loss: 0.1196, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1985], Train Loss: 0.2167, Val Loss: 0.1358, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1986], Train Loss: 0.2352, Val Loss: 0.1503, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1987], Train Loss: 0.1965, Val Loss: 0.1375, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1988], Train Loss: 0.2150, Val Loss: 0.1452, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1989], Train Loss: 0.2001, Val Loss: 0.1383, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1990], Train Loss: 0.2269, Val Loss: 0.1332, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1991], Train Loss: 0.2089, Val Loss: 0.1389, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1992], Train Loss: 0.2214, Val Loss: 0.1464, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1993], Train Loss: 0.2110, Val Loss: 0.1650, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1994], Train Loss: 0.2232, Val Loss: 0.1376, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1995], Train Loss: 0.2164, Val Loss: 0.1503, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1996], Train Loss: 0.2212, Val Loss: 0.1329, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1997], Train Loss: 0.2232, Val Loss: 0.1382, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1998], Train Loss: 0.2294, Val Loss: 0.1325, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [1999], Train Loss: 0.2280, Val Loss: 0.1433, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2000], Train Loss: 0.2250, Val Loss: 0.1368, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2001], Train Loss: 0.2274, Val Loss: 0.1508, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2002], Train Loss: 0.2382, Val Loss: 0.1300, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2003], Train Loss: 0.2269, Val Loss: 0.1329, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2004], Train Loss: 0.2208, Val Loss: 0.1538, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2005], Train Loss: 0.2299, Val Loss: 0.1375, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2006], Train Loss: 0.2243, Val Loss: 0.1392, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2007], Train Loss: 0.2200, Val Loss: 0.1363, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2008], Train Loss: 0.2283, Val Loss: 0.1332, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2009], Train Loss: 0.2105, Val Loss: 0.1607, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2010], Train Loss: 0.2156, Val Loss: 0.1395, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2011], Train Loss: 0.2322, Val Loss: 0.1284, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2012], Train Loss: 0.2188, Val Loss: 0.1495, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2013], Train Loss: 0.2147, Val Loss: 0.1388, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2014], Train Loss: 0.2086, Val Loss: 0.1529, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2015], Train Loss: 0.2199, Val Loss: 0.1284, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2016], Train Loss: 0.2239, Val Loss: 0.1380, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2017], Train Loss: 0.2252, Val Loss: 0.1248, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2018], Train Loss: 0.2176, Val Loss: 0.1325, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2019], Train Loss: 0.2239, Val Loss: 0.1454, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2020], Train Loss: 0.2035, Val Loss: 0.1377, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2021], Train Loss: 0.2076, Val Loss: 0.1308, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2022], Train Loss: 0.2197, Val Loss: 0.1456, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2023], Train Loss: 0.2106, Val Loss: 0.1408, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2024], Train Loss: 0.2290, Val Loss: 0.1501, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2025], Train Loss: 0.2313, Val Loss: 0.1347, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2026], Train Loss: 0.2290, Val Loss: 0.1381, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2027], Train Loss: 0.2332, Val Loss: 0.1268, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2028], Train Loss: 0.2120, Val Loss: 0.1477, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2029], Train Loss: 0.2201, Val Loss: 0.1331, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2030], Train Loss: 0.2385, Val Loss: 0.1272, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2031], Train Loss: 0.2329, Val Loss: 0.1496, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2032], Train Loss: 0.2179, Val Loss: 0.1372, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2033], Train Loss: 0.2126, Val Loss: 0.1516, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2034], Train Loss: 0.2229, Val Loss: 0.1335, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2035], Train Loss: 0.2233, Val Loss: 0.1389, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2036], Train Loss: 0.2404, Val Loss: 0.1421, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2037], Train Loss: 0.2242, Val Loss: 0.1377, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2038], Train Loss: 0.2295, Val Loss: 0.1353, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2039], Train Loss: 0.2266, Val Loss: 0.1467, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2040], Train Loss: 0.2012, Val Loss: 0.1629, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2041], Train Loss: 0.2129, Val Loss: 0.1327, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2042], Train Loss: 0.2208, Val Loss: 0.1524, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2043], Train Loss: 0.2272, Val Loss: 0.1393, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2044], Train Loss: 0.2227, Val Loss: 0.1392, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2045], Train Loss: 0.2006, Val Loss: 0.1277, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2046], Train Loss: 0.2153, Val Loss: 0.1369, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2047], Train Loss: 0.2264, Val Loss: 0.1325, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2048], Train Loss: 0.2188, Val Loss: 0.1406, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2049], Train Loss: 0.2219, Val Loss: 0.1430, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2050], Train Loss: 0.2189, Val Loss: 0.1200, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2051], Train Loss: 0.2270, Val Loss: 0.1349, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2052], Train Loss: 0.2269, Val Loss: 0.1425, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2053], Train Loss: 0.2153, Val Loss: 0.1288, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2054], Train Loss: 0.2080, Val Loss: 0.1301, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2055], Train Loss: 0.2132, Val Loss: 0.1283, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2056], Train Loss: 0.2329, Val Loss: 0.1488, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2057], Train Loss: 0.2048, Val Loss: 0.1362, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2058], Train Loss: 0.2174, Val Loss: 0.1353, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2059], Train Loss: 0.2236, Val Loss: 0.1373, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2060], Train Loss: 0.2141, Val Loss: 0.1501, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2061], Train Loss: 0.2279, Val Loss: 0.1534, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2062], Train Loss: 0.2087, Val Loss: 0.1603, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2063], Train Loss: 0.2103, Val Loss: 0.1409, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2064], Train Loss: 0.1985, Val Loss: 0.1432, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2065], Train Loss: 0.2200, Val Loss: 0.1437, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2066], Train Loss: 0.2170, Val Loss: 0.1297, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2067], Train Loss: 0.2177, Val Loss: 0.1365, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2068], Train Loss: 0.2052, Val Loss: 0.1385, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2069], Train Loss: 0.2103, Val Loss: 0.1245, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2070], Train Loss: 0.2059, Val Loss: 0.1433, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2071], Train Loss: 0.2318, Val Loss: 0.1356, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2072], Train Loss: 0.2190, Val Loss: 0.1278, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2073], Train Loss: 0.2055, Val Loss: 0.1482, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2074], Train Loss: 0.2201, Val Loss: 0.1428, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2075], Train Loss: 0.2377, Val Loss: 0.1185, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2076], Train Loss: 0.2129, Val Loss: 0.1372, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2077], Train Loss: 0.2128, Val Loss: 0.1314, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2078], Train Loss: 0.2181, Val Loss: 0.1464, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2079], Train Loss: 0.2156, Val Loss: 0.1233, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2080], Train Loss: 0.2181, Val Loss: 0.1475, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2081], Train Loss: 0.2221, Val Loss: 0.1382, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2082], Train Loss: 0.2124, Val Loss: 0.1468, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2083], Train Loss: 0.2265, Val Loss: 0.1289, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2084], Train Loss: 0.2068, Val Loss: 0.1317, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2085], Train Loss: 0.2165, Val Loss: 0.1255, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2086], Train Loss: 0.2257, Val Loss: 0.1269, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2087], Train Loss: 0.2285, Val Loss: 0.1400, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2088], Train Loss: 0.2191, Val Loss: 0.1356, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2089], Train Loss: 0.2143, Val Loss: 0.1433, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2090], Train Loss: 0.2262, Val Loss: 0.1330, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2091], Train Loss: 0.2262, Val Loss: 0.1177, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2092], Train Loss: 0.2245, Val Loss: 0.1208, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2093], Train Loss: 0.2124, Val Loss: 0.1434, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2094], Train Loss: 0.2152, Val Loss: 0.1462, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2095], Train Loss: 0.2140, Val Loss: 0.1334, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2096], Train Loss: 0.2399, Val Loss: 0.1400, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2097], Train Loss: 0.2096, Val Loss: 0.1374, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2098], Train Loss: 0.2253, Val Loss: 0.1427, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2099], Train Loss: 0.2290, Val Loss: 0.1397, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2100], Train Loss: 0.2170, Val Loss: 0.1262, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2101], Train Loss: 0.2213, Val Loss: 0.1436, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2102], Train Loss: 0.2296, Val Loss: 0.1288, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2103], Train Loss: 0.2224, Val Loss: 0.1385, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2104], Train Loss: 0.2171, Val Loss: 0.1460, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2105], Train Loss: 0.2202, Val Loss: 0.1542, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2106], Train Loss: 0.2304, Val Loss: 0.1471, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2107], Train Loss: 0.2234, Val Loss: 0.1391, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2108], Train Loss: 0.2188, Val Loss: 0.1357, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2109], Train Loss: 0.2009, Val Loss: 0.1346, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2110], Train Loss: 0.2406, Val Loss: 0.1410, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2111], Train Loss: 0.2266, Val Loss: 0.1324, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2112], Train Loss: 0.2115, Val Loss: 0.1346, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2113], Train Loss: 0.2168, Val Loss: 0.1411, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2114], Train Loss: 0.2202, Val Loss: 0.1418, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2115], Train Loss: 0.2235, Val Loss: 0.1332, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2116], Train Loss: 0.2239, Val Loss: 0.1424, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2117], Train Loss: 0.2312, Val Loss: 0.1312, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2118], Train Loss: 0.2303, Val Loss: 0.1411, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2119], Train Loss: 0.2221, Val Loss: 0.1324, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2120], Train Loss: 0.2167, Val Loss: 0.1346, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2121], Train Loss: 0.2271, Val Loss: 0.1504, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2122], Train Loss: 0.2157, Val Loss: 0.1224, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2123], Train Loss: 0.2298, Val Loss: 0.1391, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2124], Train Loss: 0.2320, Val Loss: 0.1493, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2125], Train Loss: 0.2159, Val Loss: 0.1353, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2126], Train Loss: 0.2217, Val Loss: 0.1442, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2127], Train Loss: 0.2212, Val Loss: 0.1318, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2128], Train Loss: 0.2139, Val Loss: 0.1297, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2129], Train Loss: 0.2263, Val Loss: 0.1484, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2130], Train Loss: 0.2219, Val Loss: 0.1494, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2131], Train Loss: 0.2093, Val Loss: 0.1225, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2132], Train Loss: 0.2286, Val Loss: 0.1326, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2133], Train Loss: 0.2068, Val Loss: 0.1420, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2134], Train Loss: 0.2094, Val Loss: 0.1411, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2135], Train Loss: 0.2348, Val Loss: 0.1243, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2136], Train Loss: 0.2274, Val Loss: 0.1394, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2137], Train Loss: 0.2177, Val Loss: 0.1286, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2138], Train Loss: 0.2298, Val Loss: 0.1458, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2139], Train Loss: 0.2243, Val Loss: 0.1275, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2140], Train Loss: 0.2236, Val Loss: 0.1305, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2141], Train Loss: 0.2240, Val Loss: 0.1415, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2142], Train Loss: 0.2129, Val Loss: 0.1286, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2143], Train Loss: 0.1946, Val Loss: 0.1289, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2144], Train Loss: 0.2240, Val Loss: 0.1242, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2145], Train Loss: 0.2268, Val Loss: 0.1302, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2146], Train Loss: 0.2041, Val Loss: 0.1326, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2147], Train Loss: 0.2093, Val Loss: 0.1427, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2148], Train Loss: 0.2232, Val Loss: 0.1536, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2149], Train Loss: 0.2146, Val Loss: 0.1275, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2150], Train Loss: 0.2183, Val Loss: 0.1295, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2151], Train Loss: 0.2221, Val Loss: 0.1389, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2152], Train Loss: 0.2099, Val Loss: 0.1265, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2153], Train Loss: 0.2112, Val Loss: 0.1159, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2154], Train Loss: 0.1965, Val Loss: 0.1354, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2155], Train Loss: 0.2252, Val Loss: 0.1308, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2156], Train Loss: 0.2243, Val Loss: 0.1218, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2157], Train Loss: 0.2230, Val Loss: 0.1444, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2158], Train Loss: 0.2209, Val Loss: 0.1397, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2159], Train Loss: 0.2068, Val Loss: 0.1206, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2160], Train Loss: 0.2354, Val Loss: 0.1309, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2161], Train Loss: 0.2118, Val Loss: 0.1349, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2162], Train Loss: 0.2306, Val Loss: 0.1353, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2163], Train Loss: 0.2071, Val Loss: 0.1266, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2164], Train Loss: 0.2086, Val Loss: 0.1252, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2165], Train Loss: 0.2126, Val Loss: 0.1342, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2166], Train Loss: 0.2304, Val Loss: 0.1318, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2167], Train Loss: 0.2174, Val Loss: 0.1340, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2168], Train Loss: 0.2151, Val Loss: 0.1301, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2169], Train Loss: 0.2112, Val Loss: 0.1378, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2170], Train Loss: 0.2092, Val Loss: 0.1479, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2171], Train Loss: 0.1952, Val Loss: 0.1410, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2172], Train Loss: 0.2223, Val Loss: 0.1224, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2173], Train Loss: 0.2121, Val Loss: 0.1441, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2174], Train Loss: 0.2240, Val Loss: 0.1298, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2175], Train Loss: 0.2261, Val Loss: 0.1227, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2176], Train Loss: 0.2075, Val Loss: 0.1320, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2177], Train Loss: 0.2057, Val Loss: 0.1174, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2178], Train Loss: 0.2293, Val Loss: 0.1333, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2179], Train Loss: 0.2136, Val Loss: 0.1365, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2180], Train Loss: 0.2181, Val Loss: 0.1205, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2181], Train Loss: 0.1965, Val Loss: 0.1174, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2182], Train Loss: 0.2269, Val Loss: 0.1243, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2183], Train Loss: 0.2115, Val Loss: 0.1287, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2184], Train Loss: 0.2080, Val Loss: 0.1357, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2185], Train Loss: 0.2044, Val Loss: 0.1374, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2186], Train Loss: 0.2189, Val Loss: 0.1345, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2187], Train Loss: 0.2176, Val Loss: 0.1359, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2188], Train Loss: 0.2129, Val Loss: 0.1213, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2189], Train Loss: 0.2154, Val Loss: 0.1318, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2190], Train Loss: 0.2131, Val Loss: 0.1292, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2191], Train Loss: 0.2232, Val Loss: 0.1164, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2192], Train Loss: 0.2028, Val Loss: 0.1225, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2193], Train Loss: 0.2094, Val Loss: 0.1262, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2194], Train Loss: 0.2090, Val Loss: 0.1371, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2195], Train Loss: 0.2150, Val Loss: 0.1260, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2196], Train Loss: 0.2326, Val Loss: 0.1316, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2197], Train Loss: 0.2079, Val Loss: 0.1429, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2198], Train Loss: 0.2070, Val Loss: 0.1117, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2199], Train Loss: 0.2115, Val Loss: 0.1277, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2200], Train Loss: 0.1984, Val Loss: 0.1188, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2201], Train Loss: 0.2021, Val Loss: 0.1121, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2202], Train Loss: 0.2094, Val Loss: 0.1165, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2203], Train Loss: 0.2230, Val Loss: 0.1357, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2204], Train Loss: 0.2310, Val Loss: 0.1251, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2205], Train Loss: 0.2037, Val Loss: 0.1315, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2206], Train Loss: 0.2157, Val Loss: 0.1191, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2207], Train Loss: 0.2285, Val Loss: 0.1199, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2208], Train Loss: 0.2141, Val Loss: 0.1194, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2209], Train Loss: 0.2268, Val Loss: 0.1361, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2210], Train Loss: 0.2027, Val Loss: 0.1149, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2211], Train Loss: 0.2222, Val Loss: 0.1294, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2212], Train Loss: 0.2207, Val Loss: 0.1311, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2213], Train Loss: 0.2171, Val Loss: 0.1103, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2214], Train Loss: 0.2157, Val Loss: 0.1156, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2215], Train Loss: 0.2140, Val Loss: 0.1193, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2216], Train Loss: 0.2138, Val Loss: 0.1230, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2217], Train Loss: 0.2179, Val Loss: 0.1374, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2218], Train Loss: 0.2121, Val Loss: 0.1322, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2219], Train Loss: 0.2134, Val Loss: 0.1160, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2220], Train Loss: 0.2142, Val Loss: 0.1186, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2221], Train Loss: 0.2065, Val Loss: 0.1177, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2222], Train Loss: 0.2237, Val Loss: 0.1337, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2223], Train Loss: 0.2010, Val Loss: 0.1100, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2224], Train Loss: 0.2226, Val Loss: 0.1129, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2225], Train Loss: 0.2096, Val Loss: 0.1285, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2226], Train Loss: 0.2150, Val Loss: 0.1110, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2227], Train Loss: 0.2034, Val Loss: 0.1102, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2228], Train Loss: 0.2156, Val Loss: 0.1184, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2229], Train Loss: 0.2119, Val Loss: 0.1274, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2230], Train Loss: 0.2073, Val Loss: 0.1045, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2231], Train Loss: 0.1913, Val Loss: 0.1087, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2232], Train Loss: 0.2107, Val Loss: 0.1186, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2233], Train Loss: 0.1998, Val Loss: 0.1175, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2234], Train Loss: 0.2061, Val Loss: 0.1040, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2235], Train Loss: 0.2208, Val Loss: 0.1149, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2236], Train Loss: 0.1982, Val Loss: 0.1137, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2237], Train Loss: 0.2091, Val Loss: 0.1086, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2238], Train Loss: 0.2059, Val Loss: 0.1096, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2239], Train Loss: 0.2187, Val Loss: 0.1106, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2240], Train Loss: 0.2036, Val Loss: 0.1014, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2241], Train Loss: 0.2122, Val Loss: 0.1008, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2242], Train Loss: 0.2007, Val Loss: 0.1095, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2243], Train Loss: 0.2030, Val Loss: 0.1153, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2244], Train Loss: 0.2075, Val Loss: 0.0960, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2245], Train Loss: 0.1932, Val Loss: 0.1063, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2246], Train Loss: 0.1855, Val Loss: 0.1000, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2247], Train Loss: 0.2046, Val Loss: 0.1041, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2248], Train Loss: 0.1873, Val Loss: 0.1005, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2249], Train Loss: 0.1893, Val Loss: 0.1041, LR: 0.000004, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2250], Train Loss: 0.2096, Val Loss: 0.1052, LR: 0.000005, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2251], Train Loss: 0.2186, Val Loss: 0.1123, LR: 0.000005, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2252], Train Loss: 0.1884, Val Loss: 0.1149, LR: 0.000005, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2253], Train Loss: 0.1946, Val Loss: 0.1095, LR: 0.000005, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2254], Train Loss: 0.1817, Val Loss: 0.1072, LR: 0.000005, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2255], Train Loss: 0.2029, Val Loss: 0.1053, LR: 0.000005, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2256], Train Loss: 0.2102, Val Loss: 0.1072, LR: 0.000005, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2257], Train Loss: 0.2034, Val Loss: 0.1049, LR: 0.000005, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2258], Train Loss: 0.1953, Val Loss: 0.1013, LR: 0.000005, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2259], Train Loss: 0.1927, Val Loss: 0.0998, LR: 0.000005, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2260], Train Loss: 0.1956, Val Loss: 0.1013, LR: 0.000005, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2261], Train Loss: 0.1968, Val Loss: 0.0924, LR: 0.000005, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2262], Train Loss: 0.2029, Val Loss: 0.0925, LR: 0.000005, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2263], Train Loss: 0.1999, Val Loss: 0.1004, LR: 0.000005, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2264], Train Loss: 0.1913, Val Loss: 0.0992, LR: 0.000005, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2265], Train Loss: 0.2041, Val Loss: 0.1007, LR: 0.000005, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2266], Train Loss: 0.1858, Val Loss: 0.0997, LR: 0.000005, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2267], Train Loss: 0.1977, Val Loss: 0.1050, LR: 0.000005, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2268], Train Loss: 0.1912, Val Loss: 0.0988, LR: 0.000005, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2269], Train Loss: 0.2046, Val Loss: 0.0940, LR: 0.000005, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2270], Train Loss: 0.1818, Val Loss: 0.0975, LR: 0.000005, best val loss was: 0.0908
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2271], Train Loss: 0.1878, Val Loss: 0.0875, LR: 0.000005, best val loss was: 0.0875
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2272], Train Loss: 0.1863, Val Loss: 0.0876, LR: 0.000005, best val loss was: 0.0875
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2273], Train Loss: 0.1926, Val Loss: 0.0948, LR: 0.000005, best val loss was: 0.0875
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2274], Train Loss: 0.1934, Val Loss: 0.0855, LR: 0.000005, best val loss was: 0.0855
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2275], Train Loss: 0.1956, Val Loss: 0.0954, LR: 0.000005, best val loss was: 0.0855
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2276], Train Loss: 0.1883, Val Loss: 0.0860, LR: 0.000005, best val loss was: 0.0855
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2277], Train Loss: 0.1958, Val Loss: 0.0900, LR: 0.000005, best val loss was: 0.0855
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2278], Train Loss: 0.1770, Val Loss: 0.0875, LR: 0.000005, best val loss was: 0.0855
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2279], Train Loss: 0.1897, Val Loss: 0.0929, LR: 0.000005, best val loss was: 0.0855
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2280], Train Loss: 0.1981, Val Loss: 0.0908, LR: 0.000005, best val loss was: 0.0855
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2281], Train Loss: 0.1814, Val Loss: 0.0788, LR: 0.000005, best val loss was: 0.0788
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2282], Train Loss: 0.1708, Val Loss: 0.0878, LR: 0.000005, best val loss was: 0.0788
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2283], Train Loss: 0.2021, Val Loss: 0.0848, LR: 0.000005, best val loss was: 0.0788
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2284], Train Loss: 0.1786, Val Loss: 0.0831, LR: 0.000005, best val loss was: 0.0788
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2285], Train Loss: 0.1868, Val Loss: 0.0866, LR: 0.000005, best val loss was: 0.0788
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2286], Train Loss: 0.1889, Val Loss: 0.0787, LR: 0.000005, best val loss was: 0.0787
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2287], Train Loss: 0.1960, Val Loss: 0.0863, LR: 0.000005, best val loss was: 0.0787
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2288], Train Loss: 0.1914, Val Loss: 0.0944, LR: 0.000005, best val loss was: 0.0787
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2289], Train Loss: 0.1829, Val Loss: 0.0787, LR: 0.000005, best val loss was: 0.0787
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2290], Train Loss: 0.1751, Val Loss: 0.0813, LR: 0.000005, best val loss was: 0.0787
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2291], Train Loss: 0.1846, Val Loss: 0.0810, LR: 0.000005, best val loss was: 0.0787
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2292], Train Loss: 0.1779, Val Loss: 0.0823, LR: 0.000005, best val loss was: 0.0787
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2293], Train Loss: 0.1979, Val Loss: 0.0765, LR: 0.000005, best val loss was: 0.0765
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2294], Train Loss: 0.1841, Val Loss: 0.0811, LR: 0.000005, best val loss was: 0.0765
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2295], Train Loss: 0.1800, Val Loss: 0.0872, LR: 0.000005, best val loss was: 0.0765
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2296], Train Loss: 0.1897, Val Loss: 0.0809, LR: 0.000005, best val loss was: 0.0765
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2297], Train Loss: 0.1743, Val Loss: 0.0836, LR: 0.000005, best val loss was: 0.0765
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2298], Train Loss: 0.1655, Val Loss: 0.0807, LR: 0.000005, best val loss was: 0.0765
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2299], Train Loss: 0.1870, Val Loss: 0.0797, LR: 0.000005, best val loss was: 0.0765
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2300], Train Loss: 0.1793, Val Loss: 0.0851, LR: 0.000005, best val loss was: 0.0765
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2301], Train Loss: 0.1806, Val Loss: 0.0783, LR: 0.000005, best val loss was: 0.0765
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2302], Train Loss: 0.1830, Val Loss: 0.0776, LR: 0.000005, best val loss was: 0.0765
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2303], Train Loss: 0.1730, Val Loss: 0.0695, LR: 0.000005, best val loss was: 0.0695
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2304], Train Loss: 0.1626, Val Loss: 0.0783, LR: 0.000005, best val loss was: 0.0695
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2305], Train Loss: 0.2005, Val Loss: 0.0784, LR: 0.000005, best val loss was: 0.0695
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2306], Train Loss: 0.1614, Val Loss: 0.0764, LR: 0.000005, best val loss was: 0.0695
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2307], Train Loss: 0.1850, Val Loss: 0.0777, LR: 0.000005, best val loss was: 0.0695
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2308], Train Loss: 0.1673, Val Loss: 0.0726, LR: 0.000005, best val loss was: 0.0695
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2309], Train Loss: 0.1763, Val Loss: 0.0698, LR: 0.000005, best val loss was: 0.0695
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2310], Train Loss: 0.1967, Val Loss: 0.0729, LR: 0.000005, best val loss was: 0.0695
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2311], Train Loss: 0.1789, Val Loss: 0.0661, LR: 0.000005, best val loss was: 0.0661
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2312], Train Loss: 0.1841, Val Loss: 0.0770, LR: 0.000005, best val loss was: 0.0661
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2313], Train Loss: 0.1808, Val Loss: 0.0692, LR: 0.000005, best val loss was: 0.0661
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2314], Train Loss: 0.1722, Val Loss: 0.0715, LR: 0.000005, best val loss was: 0.0661
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2315], Train Loss: 0.1667, Val Loss: 0.0710, LR: 0.000005, best val loss was: 0.0661
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2316], Train Loss: 0.1676, Val Loss: 0.0672, LR: 0.000005, best val loss was: 0.0661
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2317], Train Loss: 0.1601, Val Loss: 0.0682, LR: 0.000005, best val loss was: 0.0661
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2318], Train Loss: 0.1799, Val Loss: 0.0699, LR: 0.000005, best val loss was: 0.0661
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2319], Train Loss: 0.1827, Val Loss: 0.0687, LR: 0.000005, best val loss was: 0.0661
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2320], Train Loss: 0.1571, Val Loss: 0.0671, LR: 0.000005, best val loss was: 0.0661
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2321], Train Loss: 0.1704, Val Loss: 0.0695, LR: 0.000005, best val loss was: 0.0661
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2322], Train Loss: 0.1718, Val Loss: 0.0656, LR: 0.000005, best val loss was: 0.0656
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2323], Train Loss: 0.1763, Val Loss: 0.0792, LR: 0.000005, best val loss was: 0.0656
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2324], Train Loss: 0.1767, Val Loss: 0.0626, LR: 0.000005, best val loss was: 0.0626
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2325], Train Loss: 0.1721, Val Loss: 0.0681, LR: 0.000005, best val loss was: 0.0626
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2326], Train Loss: 0.1775, Val Loss: 0.0717, LR: 0.000005, best val loss was: 0.0626
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2327], Train Loss: 0.1773, Val Loss: 0.0709, LR: 0.000005, best val loss was: 0.0626
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2328], Train Loss: 0.1649, Val Loss: 0.0702, LR: 0.000005, best val loss was: 0.0626
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2329], Train Loss: 0.1738, Val Loss: 0.0677, LR: 0.000005, best val loss was: 0.0626
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2330], Train Loss: 0.1437, Val Loss: 0.0658, LR: 0.000005, best val loss was: 0.0626
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2331], Train Loss: 0.1579, Val Loss: 0.0645, LR: 0.000005, best val loss was: 0.0626
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2332], Train Loss: 0.1661, Val Loss: 0.0691, LR: 0.000005, best val loss was: 0.0626
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2333], Train Loss: 0.1432, Val Loss: 0.0626, LR: 0.000005, best val loss was: 0.0626
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2334], Train Loss: 0.1693, Val Loss: 0.0597, LR: 0.000005, best val loss was: 0.0597
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2335], Train Loss: 0.1722, Val Loss: 0.0671, LR: 0.000005, best val loss was: 0.0597
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2336], Train Loss: 0.1470, Val Loss: 0.0638, LR: 0.000005, best val loss was: 0.0597
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2337], Train Loss: 0.1633, Val Loss: 0.0641, LR: 0.000005, best val loss was: 0.0597
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2338], Train Loss: 0.1611, Val Loss: 0.0635, LR: 0.000005, best val loss was: 0.0597
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2339], Train Loss: 0.1690, Val Loss: 0.0633, LR: 0.000005, best val loss was: 0.0597
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2340], Train Loss: 0.1634, Val Loss: 0.0587, LR: 0.000005, best val loss was: 0.0587
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2341], Train Loss: 0.1721, Val Loss: 0.0594, LR: 0.000005, best val loss was: 0.0587
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2342], Train Loss: 0.1578, Val Loss: 0.0597, LR: 0.000005, best val loss was: 0.0587
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2343], Train Loss: 0.1680, Val Loss: 0.0636, LR: 0.000005, best val loss was: 0.0587
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2344], Train Loss: 0.1492, Val Loss: 0.0636, LR: 0.000005, best val loss was: 0.0587
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2345], Train Loss: 0.1608, Val Loss: 0.0674, LR: 0.000005, best val loss was: 0.0587
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2346], Train Loss: 0.1726, Val Loss: 0.0611, LR: 0.000005, best val loss was: 0.0587
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2347], Train Loss: 0.1651, Val Loss: 0.0583, LR: 0.000005, best val loss was: 0.0583
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2348], Train Loss: 0.1435, Val Loss: 0.0579, LR: 0.000005, best val loss was: 0.0579
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2349], Train Loss: 0.1660, Val Loss: 0.0572, LR: 0.000005, best val loss was: 0.0572
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2350], Train Loss: 0.1418, Val Loss: 0.0576, LR: 0.000005, best val loss was: 0.0572
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2351], Train Loss: 0.1487, Val Loss: 0.0602, LR: 0.000005, best val loss was: 0.0572
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2352], Train Loss: 0.1540, Val Loss: 0.0535, LR: 0.000005, best val loss was: 0.0535
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2353], Train Loss: 0.1490, Val Loss: 0.0592, LR: 0.000005, best val loss was: 0.0535
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2354], Train Loss: 0.1580, Val Loss: 0.0597, LR: 0.000005, best val loss was: 0.0535
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2355], Train Loss: 0.1721, Val Loss: 0.0553, LR: 0.000005, best val loss was: 0.0535
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2356], Train Loss: 0.1430, Val Loss: 0.0647, LR: 0.000005, best val loss was: 0.0535
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2357], Train Loss: 0.1522, Val Loss: 0.0577, LR: 0.000005, best val loss was: 0.0535
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2358], Train Loss: 0.1586, Val Loss: 0.0537, LR: 0.000005, best val loss was: 0.0535
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2359], Train Loss: 0.1391, Val Loss: 0.0598, LR: 0.000005, best val loss was: 0.0535
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2360], Train Loss: 0.1395, Val Loss: 0.0540, LR: 0.000005, best val loss was: 0.0535
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2361], Train Loss: 0.1479, Val Loss: 0.0579, LR: 0.000005, best val loss was: 0.0535
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2362], Train Loss: 0.1593, Val Loss: 0.0584, LR: 0.000005, best val loss was: 0.0535
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2363], Train Loss: 0.1510, Val Loss: 0.0558, LR: 0.000005, best val loss was: 0.0535
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2364], Train Loss: 0.1700, Val Loss: 0.0587, LR: 0.000005, best val loss was: 0.0535
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2365], Train Loss: 0.1644, Val Loss: 0.0551, LR: 0.000005, best val loss was: 0.0535
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2366], Train Loss: 0.1544, Val Loss: 0.0580, LR: 0.000005, best val loss was: 0.0535
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2367], Train Loss: 0.1516, Val Loss: 0.0530, LR: 0.000005, best val loss was: 0.0530
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2368], Train Loss: 0.1497, Val Loss: 0.0538, LR: 0.000005, best val loss was: 0.0530
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2369], Train Loss: 0.1485, Val Loss: 0.0518, LR: 0.000005, best val loss was: 0.0518
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2370], Train Loss: 0.1539, Val Loss: 0.0536, LR: 0.000005, best val loss was: 0.0518
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2371], Train Loss: 0.1395, Val Loss: 0.0538, LR: 0.000005, best val loss was: 0.0518
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2372], Train Loss: 0.1645, Val Loss: 0.0489, LR: 0.000005, best val loss was: 0.0489
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2373], Train Loss: 0.1508, Val Loss: 0.0539, LR: 0.000005, best val loss was: 0.0489
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2374], Train Loss: 0.1440, Val Loss: 0.0535, LR: 0.000005, best val loss was: 0.0489
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2375], Train Loss: 0.1467, Val Loss: 0.0538, LR: 0.000005, best val loss was: 0.0489
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2376], Train Loss: 0.1357, Val Loss: 0.0511, LR: 0.000005, best val loss was: 0.0489
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2377], Train Loss: 0.1488, Val Loss: 0.0530, LR: 0.000005, best val loss was: 0.0489
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2378], Train Loss: 0.1378, Val Loss: 0.0555, LR: 0.000005, best val loss was: 0.0489
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2379], Train Loss: 0.1679, Val Loss: 0.0556, LR: 0.000005, best val loss was: 0.0489
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2380], Train Loss: 0.1407, Val Loss: 0.0533, LR: 0.000005, best val loss was: 0.0489
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2381], Train Loss: 0.1469, Val Loss: 0.0511, LR: 0.000005, best val loss was: 0.0489
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2382], Train Loss: 0.1513, Val Loss: 0.0480, LR: 0.000005, best val loss was: 0.0480
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2383], Train Loss: 0.1268, Val Loss: 0.0485, LR: 0.000005, best val loss was: 0.0480
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2384], Train Loss: 0.1426, Val Loss: 0.0492, LR: 0.000005, best val loss was: 0.0480
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2385], Train Loss: 0.1467, Val Loss: 0.0441, LR: 0.000005, best val loss was: 0.0441
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2386], Train Loss: 0.1413, Val Loss: 0.0454, LR: 0.000005, best val loss was: 0.0441
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2387], Train Loss: 0.1414, Val Loss: 0.0509, LR: 0.000005, best val loss was: 0.0441
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2388], Train Loss: 0.1419, Val Loss: 0.0488, LR: 0.000005, best val loss was: 0.0441
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2389], Train Loss: 0.1318, Val Loss: 0.0507, LR: 0.000005, best val loss was: 0.0441
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2390], Train Loss: 0.1336, Val Loss: 0.0498, LR: 0.000005, best val loss was: 0.0441
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2391], Train Loss: 0.1395, Val Loss: 0.0434, LR: 0.000005, best val loss was: 0.0434
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2392], Train Loss: 0.1552, Val Loss: 0.0496, LR: 0.000005, best val loss was: 0.0434
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2393], Train Loss: 0.1363, Val Loss: 0.0467, LR: 0.000005, best val loss was: 0.0434
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2394], Train Loss: 0.1375, Val Loss: 0.0456, LR: 0.000005, best val loss was: 0.0434
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2395], Train Loss: 0.1449, Val Loss: 0.0464, LR: 0.000005, best val loss was: 0.0434
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2396], Train Loss: 0.1315, Val Loss: 0.0482, LR: 0.000005, best val loss was: 0.0434
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2397], Train Loss: 0.1317, Val Loss: 0.0444, LR: 0.000005, best val loss was: 0.0434
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2398], Train Loss: 0.1337, Val Loss: 0.0436, LR: 0.000005, best val loss was: 0.0434
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2399], Train Loss: 0.1392, Val Loss: 0.0477, LR: 0.000005, best val loss was: 0.0434
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2400], Train Loss: 0.1461, Val Loss: 0.0474, LR: 0.000005, best val loss was: 0.0434
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2401], Train Loss: 0.1218, Val Loss: 0.0427, LR: 0.000005, best val loss was: 0.0427
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2402], Train Loss: 0.1364, Val Loss: 0.0410, LR: 0.000005, best val loss was: 0.0410
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2403], Train Loss: 0.1244, Val Loss: 0.0419, LR: 0.000005, best val loss was: 0.0410
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2404], Train Loss: 0.1357, Val Loss: 0.0401, LR: 0.000005, best val loss was: 0.0401
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2405], Train Loss: 0.1228, Val Loss: 0.0406, LR: 0.000005, best val loss was: 0.0401
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2406], Train Loss: 0.1348, Val Loss: 0.0432, LR: 0.000005, best val loss was: 0.0401
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2407], Train Loss: 0.1226, Val Loss: 0.0454, LR: 0.000005, best val loss was: 0.0401
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2408], Train Loss: 0.1241, Val Loss: 0.0405, LR: 0.000005, best val loss was: 0.0401
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2409], Train Loss: 0.1331, Val Loss: 0.0435, LR: 0.000005, best val loss was: 0.0401
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2410], Train Loss: 0.1287, Val Loss: 0.0429, LR: 0.000005, best val loss was: 0.0401
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2411], Train Loss: 0.1281, Val Loss: 0.0411, LR: 0.000005, best val loss was: 0.0401
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2412], Train Loss: 0.1330, Val Loss: 0.0452, LR: 0.000005, best val loss was: 0.0401
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2413], Train Loss: 0.1108, Val Loss: 0.0420, LR: 0.000005, best val loss was: 0.0401
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2414], Train Loss: 0.1146, Val Loss: 0.0422, LR: 0.000005, best val loss was: 0.0401
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2415], Train Loss: 0.1234, Val Loss: 0.0393, LR: 0.000005, best val loss was: 0.0393
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2416], Train Loss: 0.1317, Val Loss: 0.0444, LR: 0.000005, best val loss was: 0.0393
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2417], Train Loss: 0.1224, Val Loss: 0.0434, LR: 0.000005, best val loss was: 0.0393
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2418], Train Loss: 0.1222, Val Loss: 0.0431, LR: 0.000005, best val loss was: 0.0393
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2419], Train Loss: 0.1299, Val Loss: 0.0401, LR: 0.000005, best val loss was: 0.0393
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2420], Train Loss: 0.1200, Val Loss: 0.0426, LR: 0.000005, best val loss was: 0.0393
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2421], Train Loss: 0.1268, Val Loss: 0.0389, LR: 0.000005, best val loss was: 0.0389
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2422], Train Loss: 0.1196, Val Loss: 0.0425, LR: 0.000005, best val loss was: 0.0389
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2423], Train Loss: 0.1234, Val Loss: 0.0427, LR: 0.000005, best val loss was: 0.0389
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2424], Train Loss: 0.1266, Val Loss: 0.0394, LR: 0.000005, best val loss was: 0.0389
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2425], Train Loss: 0.1063, Val Loss: 0.0419, LR: 0.000005, best val loss was: 0.0389
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2426], Train Loss: 0.1262, Val Loss: 0.0409, LR: 0.000005, best val loss was: 0.0389
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2427], Train Loss: 0.1124, Val Loss: 0.0387, LR: 0.000005, best val loss was: 0.0387
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2428], Train Loss: 0.1192, Val Loss: 0.0390, LR: 0.000005, best val loss was: 0.0387
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2429], Train Loss: 0.1132, Val Loss: 0.0398, LR: 0.000005, best val loss was: 0.0387
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2430], Train Loss: 0.1281, Val Loss: 0.0376, LR: 0.000005, best val loss was: 0.0376
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2431], Train Loss: 0.1105, Val Loss: 0.0375, LR: 0.000005, best val loss was: 0.0375
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2432], Train Loss: 0.1105, Val Loss: 0.0439, LR: 0.000005, best val loss was: 0.0375
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2433], Train Loss: 0.0993, Val Loss: 0.0383, LR: 0.000005, best val loss was: 0.0375
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2434], Train Loss: 0.1040, Val Loss: 0.0389, LR: 0.000005, best val loss was: 0.0375
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2435], Train Loss: 0.1093, Val Loss: 0.0452, LR: 0.000005, best val loss was: 0.0375
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2436], Train Loss: 0.1286, Val Loss: 0.0390, LR: 0.000005, best val loss was: 0.0375
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2437], Train Loss: 0.1103, Val Loss: 0.0373, LR: 0.000005, best val loss was: 0.0373
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2438], Train Loss: 0.1173, Val Loss: 0.0344, LR: 0.000005, best val loss was: 0.0344
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2439], Train Loss: 0.1116, Val Loss: 0.0407, LR: 0.000005, best val loss was: 0.0344
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2440], Train Loss: 0.1082, Val Loss: 0.0385, LR: 0.000005, best val loss was: 0.0344
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2441], Train Loss: 0.1078, Val Loss: 0.0367, LR: 0.000005, best val loss was: 0.0344
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2442], Train Loss: 0.1191, Val Loss: 0.0338, LR: 0.000005, best val loss was: 0.0338
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2443], Train Loss: 0.1056, Val Loss: 0.0360, LR: 0.000005, best val loss was: 0.0338
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2444], Train Loss: 0.1023, Val Loss: 0.0390, LR: 0.000005, best val loss was: 0.0338
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2445], Train Loss: 0.1142, Val Loss: 0.0362, LR: 0.000005, best val loss was: 0.0338
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2446], Train Loss: 0.1055, Val Loss: 0.0363, LR: 0.000005, best val loss was: 0.0338
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2447], Train Loss: 0.1205, Val Loss: 0.0408, LR: 0.000005, best val loss was: 0.0338
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2448], Train Loss: 0.1094, Val Loss: 0.0355, LR: 0.000005, best val loss was: 0.0338
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2449], Train Loss: 0.0948, Val Loss: 0.0417, LR: 0.000005, best val loss was: 0.0338
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2450], Train Loss: 0.1217, Val Loss: 0.0370, LR: 0.000005, best val loss was: 0.0338
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2451], Train Loss: 0.0888, Val Loss: 0.0409, LR: 0.000005, best val loss was: 0.0338
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2452], Train Loss: 0.1265, Val Loss: 0.0357, LR: 0.000005, best val loss was: 0.0338
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2453], Train Loss: 0.1184, Val Loss: 0.0388, LR: 0.000005, best val loss was: 0.0338
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2454], Train Loss: 0.1081, Val Loss: 0.0323, LR: 0.000005, best val loss was: 0.0323
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2455], Train Loss: 0.1141, Val Loss: 0.0342, LR: 0.000005, best val loss was: 0.0323
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2456], Train Loss: 0.1031, Val Loss: 0.0425, LR: 0.000005, best val loss was: 0.0323
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2457], Train Loss: 0.1028, Val Loss: 0.0331, LR: 0.000005, best val loss was: 0.0323
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2458], Train Loss: 0.1176, Val Loss: 0.0363, LR: 0.000005, best val loss was: 0.0323
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2459], Train Loss: 0.1119, Val Loss: 0.0352, LR: 0.000005, best val loss was: 0.0323
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2460], Train Loss: 0.0961, Val Loss: 0.0365, LR: 0.000005, best val loss was: 0.0323
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2461], Train Loss: 0.1016, Val Loss: 0.0370, LR: 0.000005, best val loss was: 0.0323
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2462], Train Loss: 0.1073, Val Loss: 0.0398, LR: 0.000005, best val loss was: 0.0323
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2463], Train Loss: 0.1073, Val Loss: 0.0328, LR: 0.000005, best val loss was: 0.0323
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2464], Train Loss: 0.1064, Val Loss: 0.0345, LR: 0.000005, best val loss was: 0.0323
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2465], Train Loss: 0.1123, Val Loss: 0.0290, LR: 0.000005, best val loss was: 0.0290
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2466], Train Loss: 0.0999, Val Loss: 0.0400, LR: 0.000005, best val loss was: 0.0290
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2467], Train Loss: 0.0943, Val Loss: 0.0345, LR: 0.000005, best val loss was: 0.0290
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2468], Train Loss: 0.1153, Val Loss: 0.0346, LR: 0.000005, best val loss was: 0.0290
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2469], Train Loss: 0.0958, Val Loss: 0.0382, LR: 0.000005, best val loss was: 0.0290
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2470], Train Loss: 0.1065, Val Loss: 0.0360, LR: 0.000005, best val loss was: 0.0290
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2471], Train Loss: 0.0999, Val Loss: 0.0365, LR: 0.000005, best val loss was: 0.0290
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2472], Train Loss: 0.0998, Val Loss: 0.0283, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2473], Train Loss: 0.1074, Val Loss: 0.0394, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2474], Train Loss: 0.1002, Val Loss: 0.0318, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2475], Train Loss: 0.1151, Val Loss: 0.0335, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2476], Train Loss: 0.0958, Val Loss: 0.0417, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2477], Train Loss: 0.1042, Val Loss: 0.0296, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2478], Train Loss: 0.1033, Val Loss: 0.0318, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2479], Train Loss: 0.1005, Val Loss: 0.0377, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2480], Train Loss: 0.1087, Val Loss: 0.0321, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2481], Train Loss: 0.0922, Val Loss: 0.0393, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2482], Train Loss: 0.1028, Val Loss: 0.0310, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2483], Train Loss: 0.0943, Val Loss: 0.0374, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2484], Train Loss: 0.0970, Val Loss: 0.0286, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2485], Train Loss: 0.0871, Val Loss: 0.0345, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2486], Train Loss: 0.1018, Val Loss: 0.0358, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2487], Train Loss: 0.1051, Val Loss: 0.0328, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2488], Train Loss: 0.0898, Val Loss: 0.0368, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2489], Train Loss: 0.1043, Val Loss: 0.0345, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2490], Train Loss: 0.0930, Val Loss: 0.0345, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2491], Train Loss: 0.1085, Val Loss: 0.0364, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2492], Train Loss: 0.0932, Val Loss: 0.0384, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2493], Train Loss: 0.0934, Val Loss: 0.0346, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2494], Train Loss: 0.0900, Val Loss: 0.0309, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2495], Train Loss: 0.0960, Val Loss: 0.0374, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2496], Train Loss: 0.1003, Val Loss: 0.0390, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2497], Train Loss: 0.0941, Val Loss: 0.0298, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2498], Train Loss: 0.0971, Val Loss: 0.0385, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2499], Train Loss: 0.1031, Val Loss: 0.0391, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2500], Train Loss: 0.0923, Val Loss: 0.0302, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2501], Train Loss: 0.0987, Val Loss: 0.0368, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2502], Train Loss: 0.0996, Val Loss: 0.0323, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2503], Train Loss: 0.0944, Val Loss: 0.0333, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2504], Train Loss: 0.1027, Val Loss: 0.0310, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2505], Train Loss: 0.1050, Val Loss: 0.0440, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2506], Train Loss: 0.0906, Val Loss: 0.0385, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2507], Train Loss: 0.1014, Val Loss: 0.0419, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2508], Train Loss: 0.0982, Val Loss: 0.0346, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2509], Train Loss: 0.0866, Val Loss: 0.0373, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2510], Train Loss: 0.0929, Val Loss: 0.0385, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2511], Train Loss: 0.0875, Val Loss: 0.0436, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2512], Train Loss: 0.0845, Val Loss: 0.0353, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2513], Train Loss: 0.0946, Val Loss: 0.0398, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2514], Train Loss: 0.0990, Val Loss: 0.0305, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2515], Train Loss: 0.0996, Val Loss: 0.0392, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2516], Train Loss: 0.0882, Val Loss: 0.0397, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2517], Train Loss: 0.0951, Val Loss: 0.0416, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2518], Train Loss: 0.0850, Val Loss: 0.0328, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2519], Train Loss: 0.1002, Val Loss: 0.0453, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2520], Train Loss: 0.0877, Val Loss: 0.0286, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2521], Train Loss: 0.0799, Val Loss: 0.0512, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2522], Train Loss: 0.0911, Val Loss: 0.0321, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2523], Train Loss: 0.0978, Val Loss: 0.0435, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2524], Train Loss: 0.0959, Val Loss: 0.0410, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2525], Train Loss: 0.0928, Val Loss: 0.0405, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2526], Train Loss: 0.1114, Val Loss: 0.0385, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2527], Train Loss: 0.0973, Val Loss: 0.0352, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2528], Train Loss: 0.1040, Val Loss: 0.0394, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2529], Train Loss: 0.0949, Val Loss: 0.0310, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2530], Train Loss: 0.0863, Val Loss: 0.0381, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2531], Train Loss: 0.0988, Val Loss: 0.0386, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2532], Train Loss: 0.0845, Val Loss: 0.0354, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2533], Train Loss: 0.0803, Val Loss: 0.0344, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2534], Train Loss: 0.0950, Val Loss: 0.0364, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2535], Train Loss: 0.0909, Val Loss: 0.0307, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2536], Train Loss: 0.0959, Val Loss: 0.0486, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2537], Train Loss: 0.0961, Val Loss: 0.0312, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2538], Train Loss: 0.0858, Val Loss: 0.0449, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2539], Train Loss: 0.0951, Val Loss: 0.0409, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2540], Train Loss: 0.0901, Val Loss: 0.0332, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2541], Train Loss: 0.0893, Val Loss: 0.0390, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2542], Train Loss: 0.0946, Val Loss: 0.0426, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2543], Train Loss: 0.0940, Val Loss: 0.0357, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2544], Train Loss: 0.0912, Val Loss: 0.0439, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2545], Train Loss: 0.0903, Val Loss: 0.0330, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2546], Train Loss: 0.0927, Val Loss: 0.0459, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2547], Train Loss: 0.0970, Val Loss: 0.0362, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2548], Train Loss: 0.0820, Val Loss: 0.0342, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2549], Train Loss: 0.0886, Val Loss: 0.0342, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2550], Train Loss: 0.0918, Val Loss: 0.0376, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2551], Train Loss: 0.0916, Val Loss: 0.0369, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2552], Train Loss: 0.0871, Val Loss: 0.0385, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2553], Train Loss: 0.0908, Val Loss: 0.0415, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2554], Train Loss: 0.0925, Val Loss: 0.0363, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2555], Train Loss: 0.0873, Val Loss: 0.0440, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2556], Train Loss: 0.0797, Val Loss: 0.0363, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2557], Train Loss: 0.0897, Val Loss: 0.0476, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2558], Train Loss: 0.0945, Val Loss: 0.0367, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2559], Train Loss: 0.1017, Val Loss: 0.0395, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2560], Train Loss: 0.0901, Val Loss: 0.0480, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2561], Train Loss: 0.0887, Val Loss: 0.0439, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2562], Train Loss: 0.0787, Val Loss: 0.0479, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2563], Train Loss: 0.0951, Val Loss: 0.0379, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2564], Train Loss: 0.0947, Val Loss: 0.0344, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2565], Train Loss: 0.0879, Val Loss: 0.0431, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2566], Train Loss: 0.0803, Val Loss: 0.0358, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2567], Train Loss: 0.1031, Val Loss: 0.0379, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2568], Train Loss: 0.0991, Val Loss: 0.0511, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2569], Train Loss: 0.0820, Val Loss: 0.0362, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2570], Train Loss: 0.0948, Val Loss: 0.0352, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2571], Train Loss: 0.0816, Val Loss: 0.0423, LR: 0.000005, best val loss was: 0.0283
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2572], Train Loss: 0.0799, Val Loss: 0.0274, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2573], Train Loss: 0.0849, Val Loss: 0.0534, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2574], Train Loss: 0.0902, Val Loss: 0.0362, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2575], Train Loss: 0.0821, Val Loss: 0.0557, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2576], Train Loss: 0.1051, Val Loss: 0.0404, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2577], Train Loss: 0.0826, Val Loss: 0.0366, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2578], Train Loss: 0.0916, Val Loss: 0.0431, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2579], Train Loss: 0.0869, Val Loss: 0.0419, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2580], Train Loss: 0.0873, Val Loss: 0.0378, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2581], Train Loss: 0.0903, Val Loss: 0.0398, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2582], Train Loss: 0.0799, Val Loss: 0.0375, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2583], Train Loss: 0.0859, Val Loss: 0.0407, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2584], Train Loss: 0.0948, Val Loss: 0.0356, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2585], Train Loss: 0.0835, Val Loss: 0.0484, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2586], Train Loss: 0.0804, Val Loss: 0.0330, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2587], Train Loss: 0.0810, Val Loss: 0.0552, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2588], Train Loss: 0.0860, Val Loss: 0.0362, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2589], Train Loss: 0.0735, Val Loss: 0.0419, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2590], Train Loss: 0.0851, Val Loss: 0.0427, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2591], Train Loss: 0.0737, Val Loss: 0.0483, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2592], Train Loss: 0.1015, Val Loss: 0.0373, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2593], Train Loss: 0.0900, Val Loss: 0.0430, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2594], Train Loss: 0.0852, Val Loss: 0.0343, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2595], Train Loss: 0.0823, Val Loss: 0.0419, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2596], Train Loss: 0.0898, Val Loss: 0.0435, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2597], Train Loss: 0.0770, Val Loss: 0.0424, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2598], Train Loss: 0.0844, Val Loss: 0.0426, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2599], Train Loss: 0.0734, Val Loss: 0.0438, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2600], Train Loss: 0.0729, Val Loss: 0.0404, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2601], Train Loss: 0.0815, Val Loss: 0.0374, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2602], Train Loss: 0.0893, Val Loss: 0.0423, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2603], Train Loss: 0.0891, Val Loss: 0.0407, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2604], Train Loss: 0.0849, Val Loss: 0.0433, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2605], Train Loss: 0.0820, Val Loss: 0.0335, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2606], Train Loss: 0.0873, Val Loss: 0.0490, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2607], Train Loss: 0.0789, Val Loss: 0.0420, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2608], Train Loss: 0.0866, Val Loss: 0.0419, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2609], Train Loss: 0.0890, Val Loss: 0.0360, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2610], Train Loss: 0.0798, Val Loss: 0.0476, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2611], Train Loss: 0.0761, Val Loss: 0.0410, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2612], Train Loss: 0.0878, Val Loss: 0.0399, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2613], Train Loss: 0.0860, Val Loss: 0.0388, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2614], Train Loss: 0.0870, Val Loss: 0.0362, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2615], Train Loss: 0.0813, Val Loss: 0.0425, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2616], Train Loss: 0.0833, Val Loss: 0.0451, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2617], Train Loss: 0.0859, Val Loss: 0.0477, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2618], Train Loss: 0.0847, Val Loss: 0.0368, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2619], Train Loss: 0.0842, Val Loss: 0.0395, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2620], Train Loss: 0.0847, Val Loss: 0.0412, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2621], Train Loss: 0.0846, Val Loss: 0.0415, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2622], Train Loss: 0.0817, Val Loss: 0.0468, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2623], Train Loss: 0.0866, Val Loss: 0.0374, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2624], Train Loss: 0.0846, Val Loss: 0.0362, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2625], Train Loss: 0.0850, Val Loss: 0.0427, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2626], Train Loss: 0.0776, Val Loss: 0.0314, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2627], Train Loss: 0.0801, Val Loss: 0.0473, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2628], Train Loss: 0.0933, Val Loss: 0.0365, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2629], Train Loss: 0.0856, Val Loss: 0.0416, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2630], Train Loss: 0.0904, Val Loss: 0.0451, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2631], Train Loss: 0.0921, Val Loss: 0.0496, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2632], Train Loss: 0.0773, Val Loss: 0.0330, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2633], Train Loss: 0.0755, Val Loss: 0.0477, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2634], Train Loss: 0.0893, Val Loss: 0.0354, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2635], Train Loss: 0.0845, Val Loss: 0.0529, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2636], Train Loss: 0.0882, Val Loss: 0.0373, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2637], Train Loss: 0.0837, Val Loss: 0.0536, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2638], Train Loss: 0.0785, Val Loss: 0.0352, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2639], Train Loss: 0.0760, Val Loss: 0.0470, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2640], Train Loss: 0.0791, Val Loss: 0.0407, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2641], Train Loss: 0.0881, Val Loss: 0.0424, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2642], Train Loss: 0.0826, Val Loss: 0.0436, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2643], Train Loss: 0.0840, Val Loss: 0.0399, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2644], Train Loss: 0.0786, Val Loss: 0.0473, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2645], Train Loss: 0.0854, Val Loss: 0.0280, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2646], Train Loss: 0.0834, Val Loss: 0.0517, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2647], Train Loss: 0.0853, Val Loss: 0.0362, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2648], Train Loss: 0.0842, Val Loss: 0.0449, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2649], Train Loss: 0.0872, Val Loss: 0.0364, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2650], Train Loss: 0.0831, Val Loss: 0.0342, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2651], Train Loss: 0.0877, Val Loss: 0.0473, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2652], Train Loss: 0.0836, Val Loss: 0.0430, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2653], Train Loss: 0.0808, Val Loss: 0.0465, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2654], Train Loss: 0.0841, Val Loss: 0.0439, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2655], Train Loss: 0.0781, Val Loss: 0.0486, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2656], Train Loss: 0.0826, Val Loss: 0.0419, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2657], Train Loss: 0.0748, Val Loss: 0.0427, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2658], Train Loss: 0.0825, Val Loss: 0.0428, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2659], Train Loss: 0.0756, Val Loss: 0.0399, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2660], Train Loss: 0.0831, Val Loss: 0.0428, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2661], Train Loss: 0.0800, Val Loss: 0.0378, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2662], Train Loss: 0.0790, Val Loss: 0.0475, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2663], Train Loss: 0.0795, Val Loss: 0.0472, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2664], Train Loss: 0.0855, Val Loss: 0.0401, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2665], Train Loss: 0.0825, Val Loss: 0.0380, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2666], Train Loss: 0.0941, Val Loss: 0.0466, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2667], Train Loss: 0.0801, Val Loss: 0.0479, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2668], Train Loss: 0.0779, Val Loss: 0.0511, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2669], Train Loss: 0.0808, Val Loss: 0.0365, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2670], Train Loss: 0.0758, Val Loss: 0.0362, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2671], Train Loss: 0.0726, Val Loss: 0.0675, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2672], Train Loss: 0.0855, Val Loss: 0.0385, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2673], Train Loss: 0.0729, Val Loss: 0.0422, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2674], Train Loss: 0.0812, Val Loss: 0.0392, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2675], Train Loss: 0.0805, Val Loss: 0.0383, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2676], Train Loss: 0.0850, Val Loss: 0.0497, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2677], Train Loss: 0.0833, Val Loss: 0.0353, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2678], Train Loss: 0.0730, Val Loss: 0.0556, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2679], Train Loss: 0.0808, Val Loss: 0.0277, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2680], Train Loss: 0.0796, Val Loss: 0.0482, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2681], Train Loss: 0.0775, Val Loss: 0.0376, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2682], Train Loss: 0.0709, Val Loss: 0.0395, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2683], Train Loss: 0.0753, Val Loss: 0.0396, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2684], Train Loss: 0.0738, Val Loss: 0.0457, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2685], Train Loss: 0.0785, Val Loss: 0.0478, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2686], Train Loss: 0.0745, Val Loss: 0.0382, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2687], Train Loss: 0.0753, Val Loss: 0.0501, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2688], Train Loss: 0.0786, Val Loss: 0.0372, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2689], Train Loss: 0.0753, Val Loss: 0.0568, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2690], Train Loss: 0.0732, Val Loss: 0.0387, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2691], Train Loss: 0.0758, Val Loss: 0.0557, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2692], Train Loss: 0.0760, Val Loss: 0.0432, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2693], Train Loss: 0.0762, Val Loss: 0.0433, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2694], Train Loss: 0.0710, Val Loss: 0.0598, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2695], Train Loss: 0.0734, Val Loss: 0.0391, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2696], Train Loss: 0.0753, Val Loss: 0.0488, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2697], Train Loss: 0.0800, Val Loss: 0.0318, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2698], Train Loss: 0.0784, Val Loss: 0.0435, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2699], Train Loss: 0.0763, Val Loss: 0.0480, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2700], Train Loss: 0.0767, Val Loss: 0.0424, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2701], Train Loss: 0.0715, Val Loss: 0.0522, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2702], Train Loss: 0.0774, Val Loss: 0.0397, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2703], Train Loss: 0.0705, Val Loss: 0.0502, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2704], Train Loss: 0.0752, Val Loss: 0.0384, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2705], Train Loss: 0.0674, Val Loss: 0.0468, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2706], Train Loss: 0.0695, Val Loss: 0.0413, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2707], Train Loss: 0.0818, Val Loss: 0.0492, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2708], Train Loss: 0.0775, Val Loss: 0.0433, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2709], Train Loss: 0.0839, Val Loss: 0.0354, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2710], Train Loss: 0.0830, Val Loss: 0.0460, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2711], Train Loss: 0.0723, Val Loss: 0.0413, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2712], Train Loss: 0.0721, Val Loss: 0.0424, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2713], Train Loss: 0.0830, Val Loss: 0.0471, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2714], Train Loss: 0.0752, Val Loss: 0.0359, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2715], Train Loss: 0.0681, Val Loss: 0.0458, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2716], Train Loss: 0.0806, Val Loss: 0.0418, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2717], Train Loss: 0.0711, Val Loss: 0.0424, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2718], Train Loss: 0.0783, Val Loss: 0.0509, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2719], Train Loss: 0.0664, Val Loss: 0.0371, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2720], Train Loss: 0.0891, Val Loss: 0.0446, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2721], Train Loss: 0.0743, Val Loss: 0.0415, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2722], Train Loss: 0.0694, Val Loss: 0.0393, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2723], Train Loss: 0.0806, Val Loss: 0.0441, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2724], Train Loss: 0.0771, Val Loss: 0.0379, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2725], Train Loss: 0.0769, Val Loss: 0.0448, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2726], Train Loss: 0.0726, Val Loss: 0.0411, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2727], Train Loss: 0.0779, Val Loss: 0.0428, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2728], Train Loss: 0.0731, Val Loss: 0.0438, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2729], Train Loss: 0.0739, Val Loss: 0.0538, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2730], Train Loss: 0.0738, Val Loss: 0.0420, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2731], Train Loss: 0.0773, Val Loss: 0.0441, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2732], Train Loss: 0.0770, Val Loss: 0.0494, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2733], Train Loss: 0.0823, Val Loss: 0.0449, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2734], Train Loss: 0.0788, Val Loss: 0.0478, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2735], Train Loss: 0.0684, Val Loss: 0.0381, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2736], Train Loss: 0.0779, Val Loss: 0.0398, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2737], Train Loss: 0.0772, Val Loss: 0.0517, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2738], Train Loss: 0.0775, Val Loss: 0.0369, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2739], Train Loss: 0.0721, Val Loss: 0.0579, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2740], Train Loss: 0.0748, Val Loss: 0.0418, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2741], Train Loss: 0.0621, Val Loss: 0.0481, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2742], Train Loss: 0.0818, Val Loss: 0.0407, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2743], Train Loss: 0.0694, Val Loss: 0.0474, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2744], Train Loss: 0.0753, Val Loss: 0.0514, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2745], Train Loss: 0.0684, Val Loss: 0.0473, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2746], Train Loss: 0.0716, Val Loss: 0.0486, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2747], Train Loss: 0.0666, Val Loss: 0.0485, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2748], Train Loss: 0.0709, Val Loss: 0.0485, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2749], Train Loss: 0.0757, Val Loss: 0.0459, LR: 0.000005, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2750], Train Loss: 0.0658, Val Loss: 0.0617, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2751], Train Loss: 0.0700, Val Loss: 0.0488, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2752], Train Loss: 0.0784, Val Loss: 0.0517, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2753], Train Loss: 0.0795, Val Loss: 0.0448, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2754], Train Loss: 0.0728, Val Loss: 0.0444, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2755], Train Loss: 0.0678, Val Loss: 0.0402, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2756], Train Loss: 0.0745, Val Loss: 0.0483, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2757], Train Loss: 0.0731, Val Loss: 0.0373, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2758], Train Loss: 0.0745, Val Loss: 0.0582, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2759], Train Loss: 0.0732, Val Loss: 0.0442, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2760], Train Loss: 0.0696, Val Loss: 0.0516, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2761], Train Loss: 0.0678, Val Loss: 0.0453, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2762], Train Loss: 0.0855, Val Loss: 0.0492, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2763], Train Loss: 0.0693, Val Loss: 0.0399, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2764], Train Loss: 0.0633, Val Loss: 0.0475, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2765], Train Loss: 0.0658, Val Loss: 0.0477, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2766], Train Loss: 0.0793, Val Loss: 0.0421, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2767], Train Loss: 0.0791, Val Loss: 0.0516, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2768], Train Loss: 0.0700, Val Loss: 0.0521, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2769], Train Loss: 0.0726, Val Loss: 0.0444, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2770], Train Loss: 0.0765, Val Loss: 0.0459, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2771], Train Loss: 0.0719, Val Loss: 0.0454, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2772], Train Loss: 0.0742, Val Loss: 0.0534, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2773], Train Loss: 0.0725, Val Loss: 0.0501, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2774], Train Loss: 0.0680, Val Loss: 0.0473, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2775], Train Loss: 0.0677, Val Loss: 0.0459, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2776], Train Loss: 0.0660, Val Loss: 0.0451, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2777], Train Loss: 0.0738, Val Loss: 0.0492, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2778], Train Loss: 0.0675, Val Loss: 0.0417, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2779], Train Loss: 0.0697, Val Loss: 0.0385, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2780], Train Loss: 0.0769, Val Loss: 0.0474, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2781], Train Loss: 0.0711, Val Loss: 0.0401, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2782], Train Loss: 0.0723, Val Loss: 0.0380, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2783], Train Loss: 0.0684, Val Loss: 0.0376, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2784], Train Loss: 0.0741, Val Loss: 0.0323, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2785], Train Loss: 0.0733, Val Loss: 0.0590, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2786], Train Loss: 0.0739, Val Loss: 0.0368, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2787], Train Loss: 0.0680, Val Loss: 0.0421, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2788], Train Loss: 0.0693, Val Loss: 0.0435, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2789], Train Loss: 0.0778, Val Loss: 0.0522, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2790], Train Loss: 0.0701, Val Loss: 0.0431, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2791], Train Loss: 0.0689, Val Loss: 0.0472, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2792], Train Loss: 0.0717, Val Loss: 0.0470, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2793], Train Loss: 0.0688, Val Loss: 0.0439, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2794], Train Loss: 0.0695, Val Loss: 0.0356, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2795], Train Loss: 0.0695, Val Loss: 0.0560, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2796], Train Loss: 0.0711, Val Loss: 0.0476, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2797], Train Loss: 0.0703, Val Loss: 0.0499, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2798], Train Loss: 0.0756, Val Loss: 0.0354, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2799], Train Loss: 0.0754, Val Loss: 0.0603, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2800], Train Loss: 0.0644, Val Loss: 0.0371, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2801], Train Loss: 0.0651, Val Loss: 0.0433, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2802], Train Loss: 0.0714, Val Loss: 0.0453, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2803], Train Loss: 0.0683, Val Loss: 0.0372, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2804], Train Loss: 0.0778, Val Loss: 0.0538, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2805], Train Loss: 0.0617, Val Loss: 0.0369, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2806], Train Loss: 0.0666, Val Loss: 0.0530, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2807], Train Loss: 0.0675, Val Loss: 0.0469, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2808], Train Loss: 0.0670, Val Loss: 0.0478, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2809], Train Loss: 0.0682, Val Loss: 0.0380, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2810], Train Loss: 0.0728, Val Loss: 0.0664, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2811], Train Loss: 0.0692, Val Loss: 0.0328, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2812], Train Loss: 0.0803, Val Loss: 0.0500, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2813], Train Loss: 0.0749, Val Loss: 0.0433, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2814], Train Loss: 0.0686, Val Loss: 0.0551, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2815], Train Loss: 0.0663, Val Loss: 0.0420, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2816], Train Loss: 0.0711, Val Loss: 0.0589, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2817], Train Loss: 0.0758, Val Loss: 0.0434, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2818], Train Loss: 0.0724, Val Loss: 0.0389, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2819], Train Loss: 0.0603, Val Loss: 0.0592, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2820], Train Loss: 0.0680, Val Loss: 0.0396, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2821], Train Loss: 0.0650, Val Loss: 0.0569, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2822], Train Loss: 0.0683, Val Loss: 0.0438, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2823], Train Loss: 0.0731, Val Loss: 0.0543, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2824], Train Loss: 0.0709, Val Loss: 0.0454, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2825], Train Loss: 0.0688, Val Loss: 0.0484, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2826], Train Loss: 0.0746, Val Loss: 0.0515, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2827], Train Loss: 0.0759, Val Loss: 0.0386, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2828], Train Loss: 0.0640, Val Loss: 0.0593, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2829], Train Loss: 0.0668, Val Loss: 0.0448, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2830], Train Loss: 0.0742, Val Loss: 0.0369, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2831], Train Loss: 0.0749, Val Loss: 0.0680, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2832], Train Loss: 0.0680, Val Loss: 0.0379, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2833], Train Loss: 0.0711, Val Loss: 0.0595, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2834], Train Loss: 0.0680, Val Loss: 0.0509, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2835], Train Loss: 0.0604, Val Loss: 0.0442, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2836], Train Loss: 0.0694, Val Loss: 0.0492, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2837], Train Loss: 0.0628, Val Loss: 0.0570, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2838], Train Loss: 0.0720, Val Loss: 0.0465, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2839], Train Loss: 0.0698, Val Loss: 0.0506, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2840], Train Loss: 0.0698, Val Loss: 0.0466, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2841], Train Loss: 0.0701, Val Loss: 0.0572, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2842], Train Loss: 0.0791, Val Loss: 0.0468, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2843], Train Loss: 0.0716, Val Loss: 0.0527, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2844], Train Loss: 0.0673, Val Loss: 0.0431, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2845], Train Loss: 0.0615, Val Loss: 0.0581, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2846], Train Loss: 0.0700, Val Loss: 0.0440, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2847], Train Loss: 0.0660, Val Loss: 0.0521, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2848], Train Loss: 0.0716, Val Loss: 0.0411, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2849], Train Loss: 0.0684, Val Loss: 0.0739, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2850], Train Loss: 0.0644, Val Loss: 0.0501, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2851], Train Loss: 0.0675, Val Loss: 0.0462, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2852], Train Loss: 0.0647, Val Loss: 0.0528, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2853], Train Loss: 0.0593, Val Loss: 0.0452, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2854], Train Loss: 0.0679, Val Loss: 0.0595, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2855], Train Loss: 0.0738, Val Loss: 0.0423, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2856], Train Loss: 0.0639, Val Loss: 0.0473, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2857], Train Loss: 0.0722, Val Loss: 0.0564, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2858], Train Loss: 0.0717, Val Loss: 0.0439, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2859], Train Loss: 0.0739, Val Loss: 0.0588, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2860], Train Loss: 0.0662, Val Loss: 0.0450, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2861], Train Loss: 0.0684, Val Loss: 0.0678, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2862], Train Loss: 0.0691, Val Loss: 0.0396, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2863], Train Loss: 0.0666, Val Loss: 0.0604, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2864], Train Loss: 0.0690, Val Loss: 0.0590, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2865], Train Loss: 0.0642, Val Loss: 0.0516, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2866], Train Loss: 0.0630, Val Loss: 0.0516, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2867], Train Loss: 0.0647, Val Loss: 0.0513, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2868], Train Loss: 0.0695, Val Loss: 0.0441, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2869], Train Loss: 0.0730, Val Loss: 0.0635, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2870], Train Loss: 0.0699, Val Loss: 0.0486, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2871], Train Loss: 0.0750, Val Loss: 0.0522, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2872], Train Loss: 0.0631, Val Loss: 0.0451, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2873], Train Loss: 0.0646, Val Loss: 0.0536, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2874], Train Loss: 0.0676, Val Loss: 0.0519, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2875], Train Loss: 0.0650, Val Loss: 0.0533, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2876], Train Loss: 0.0666, Val Loss: 0.0457, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2877], Train Loss: 0.0768, Val Loss: 0.0517, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2878], Train Loss: 0.0642, Val Loss: 0.0610, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2879], Train Loss: 0.0680, Val Loss: 0.0360, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2880], Train Loss: 0.0647, Val Loss: 0.0603, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2881], Train Loss: 0.0710, Val Loss: 0.0560, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2882], Train Loss: 0.0727, Val Loss: 0.0466, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2883], Train Loss: 0.0691, Val Loss: 0.0598, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2884], Train Loss: 0.0651, Val Loss: 0.0428, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2885], Train Loss: 0.0677, Val Loss: 0.0578, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2886], Train Loss: 0.0736, Val Loss: 0.0486, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2887], Train Loss: 0.0724, Val Loss: 0.0519, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2888], Train Loss: 0.0716, Val Loss: 0.0562, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2889], Train Loss: 0.0715, Val Loss: 0.0756, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2890], Train Loss: 0.0622, Val Loss: 0.0433, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2891], Train Loss: 0.0689, Val Loss: 0.0644, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2892], Train Loss: 0.0638, Val Loss: 0.0444, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2893], Train Loss: 0.0607, Val Loss: 0.0531, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2894], Train Loss: 0.0772, Val Loss: 0.0507, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2895], Train Loss: 0.0671, Val Loss: 0.0430, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2896], Train Loss: 0.0653, Val Loss: 0.0634, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2897], Train Loss: 0.0601, Val Loss: 0.0503, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2898], Train Loss: 0.0647, Val Loss: 0.0676, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2899], Train Loss: 0.0667, Val Loss: 0.0394, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2900], Train Loss: 0.0593, Val Loss: 0.0660, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2901], Train Loss: 0.0660, Val Loss: 0.0534, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2902], Train Loss: 0.0704, Val Loss: 0.0454, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2903], Train Loss: 0.0638, Val Loss: 0.0666, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2904], Train Loss: 0.0650, Val Loss: 0.0457, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2905], Train Loss: 0.0597, Val Loss: 0.0583, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2906], Train Loss: 0.0651, Val Loss: 0.0494, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2907], Train Loss: 0.0615, Val Loss: 0.0532, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2908], Train Loss: 0.0628, Val Loss: 0.0501, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2909], Train Loss: 0.0599, Val Loss: 0.0486, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2910], Train Loss: 0.0751, Val Loss: 0.0539, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2911], Train Loss: 0.0618, Val Loss: 0.0527, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2912], Train Loss: 0.0721, Val Loss: 0.0470, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2913], Train Loss: 0.0733, Val Loss: 0.0488, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2914], Train Loss: 0.0615, Val Loss: 0.0458, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2915], Train Loss: 0.0624, Val Loss: 0.0526, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2916], Train Loss: 0.0695, Val Loss: 0.0358, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2917], Train Loss: 0.0645, Val Loss: 0.0448, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2918], Train Loss: 0.0694, Val Loss: 0.0465, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2919], Train Loss: 0.0720, Val Loss: 0.0468, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2920], Train Loss: 0.0749, Val Loss: 0.0451, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2921], Train Loss: 0.0688, Val Loss: 0.0502, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2922], Train Loss: 0.0582, Val Loss: 0.0461, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2923], Train Loss: 0.0701, Val Loss: 0.0669, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2924], Train Loss: 0.0594, Val Loss: 0.0386, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2925], Train Loss: 0.0689, Val Loss: 0.0489, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2926], Train Loss: 0.0614, Val Loss: 0.0423, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2927], Train Loss: 0.0624, Val Loss: 0.0480, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2928], Train Loss: 0.0597, Val Loss: 0.0509, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2929], Train Loss: 0.0625, Val Loss: 0.0553, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2930], Train Loss: 0.0597, Val Loss: 0.0486, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2931], Train Loss: 0.0671, Val Loss: 0.0554, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2932], Train Loss: 0.0654, Val Loss: 0.0492, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2933], Train Loss: 0.0662, Val Loss: 0.0542, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2934], Train Loss: 0.0737, Val Loss: 0.0432, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2935], Train Loss: 0.0642, Val Loss: 0.0615, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2936], Train Loss: 0.0623, Val Loss: 0.0544, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2937], Train Loss: 0.0698, Val Loss: 0.0392, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2938], Train Loss: 0.0737, Val Loss: 0.0563, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2939], Train Loss: 0.0636, Val Loss: 0.0433, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2940], Train Loss: 0.0633, Val Loss: 0.0479, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2941], Train Loss: 0.0677, Val Loss: 0.0562, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2942], Train Loss: 0.0609, Val Loss: 0.0445, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2943], Train Loss: 0.0684, Val Loss: 0.0451, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2944], Train Loss: 0.0719, Val Loss: 0.0698, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2945], Train Loss: 0.0706, Val Loss: 0.0414, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2946], Train Loss: 0.0649, Val Loss: 0.0523, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2947], Train Loss: 0.0636, Val Loss: 0.0495, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2948], Train Loss: 0.0643, Val Loss: 0.0405, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2949], Train Loss: 0.0622, Val Loss: 0.0590, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2950], Train Loss: 0.0641, Val Loss: 0.0471, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2951], Train Loss: 0.0695, Val Loss: 0.0607, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2952], Train Loss: 0.0602, Val Loss: 0.0389, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2953], Train Loss: 0.0637, Val Loss: 0.0463, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2954], Train Loss: 0.0631, Val Loss: 0.0541, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2955], Train Loss: 0.0617, Val Loss: 0.0468, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2956], Train Loss: 0.0622, Val Loss: 0.0450, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2957], Train Loss: 0.0721, Val Loss: 0.0598, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2958], Train Loss: 0.0612, Val Loss: 0.0445, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2959], Train Loss: 0.0684, Val Loss: 0.0591, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2960], Train Loss: 0.0689, Val Loss: 0.0577, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2961], Train Loss: 0.0700, Val Loss: 0.0508, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2962], Train Loss: 0.0618, Val Loss: 0.0480, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2963], Train Loss: 0.0738, Val Loss: 0.0537, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2964], Train Loss: 0.0656, Val Loss: 0.0479, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2965], Train Loss: 0.0649, Val Loss: 0.0569, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2966], Train Loss: 0.0624, Val Loss: 0.0459, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2967], Train Loss: 0.0712, Val Loss: 0.0550, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2968], Train Loss: 0.0684, Val Loss: 0.0548, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2969], Train Loss: 0.0613, Val Loss: 0.0599, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2970], Train Loss: 0.0682, Val Loss: 0.0466, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2971], Train Loss: 0.0746, Val Loss: 0.0607, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2972], Train Loss: 0.0637, Val Loss: 0.0455, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2973], Train Loss: 0.0546, Val Loss: 0.0531, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2974], Train Loss: 0.0585, Val Loss: 0.0507, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2975], Train Loss: 0.0632, Val Loss: 0.0510, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2976], Train Loss: 0.0604, Val Loss: 0.0479, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2977], Train Loss: 0.0614, Val Loss: 0.0488, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2978], Train Loss: 0.0695, Val Loss: 0.0663, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2979], Train Loss: 0.0666, Val Loss: 0.0470, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2980], Train Loss: 0.0647, Val Loss: 0.0517, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2981], Train Loss: 0.0697, Val Loss: 0.0701, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2982], Train Loss: 0.0576, Val Loss: 0.0464, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2983], Train Loss: 0.0674, Val Loss: 0.0565, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2984], Train Loss: 0.0604, Val Loss: 0.0436, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2985], Train Loss: 0.0621, Val Loss: 0.0499, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2986], Train Loss: 0.0589, Val Loss: 0.0478, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2987], Train Loss: 0.0682, Val Loss: 0.0573, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2988], Train Loss: 0.0658, Val Loss: 0.0429, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2989], Train Loss: 0.0632, Val Loss: 0.0516, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2990], Train Loss: 0.0749, Val Loss: 0.0407, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2991], Train Loss: 0.0644, Val Loss: 0.0464, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2992], Train Loss: 0.0737, Val Loss: 0.0426, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2993], Train Loss: 0.0673, Val Loss: 0.0467, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2994], Train Loss: 0.0628, Val Loss: 0.0539, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2995], Train Loss: 0.0668, Val Loss: 0.0377, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2996], Train Loss: 0.0612, Val Loss: 0.0625, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2997], Train Loss: 0.0733, Val Loss: 0.0368, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2998], Train Loss: 0.0610, Val Loss: 0.0703, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [2999], Train Loss: 0.0642, Val Loss: 0.0372, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3000], Train Loss: 0.0594, Val Loss: 0.0447, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3001], Train Loss: 0.0637, Val Loss: 0.0638, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3002], Train Loss: 0.0708, Val Loss: 0.0397, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3003], Train Loss: 0.0642, Val Loss: 0.0526, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3004], Train Loss: 0.0615, Val Loss: 0.0523, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3005], Train Loss: 0.0633, Val Loss: 0.0531, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3006], Train Loss: 0.0674, Val Loss: 0.0601, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3007], Train Loss: 0.0678, Val Loss: 0.0584, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3008], Train Loss: 0.0615, Val Loss: 0.0521, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3009], Train Loss: 0.0586, Val Loss: 0.0635, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3010], Train Loss: 0.0629, Val Loss: 0.0449, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3011], Train Loss: 0.0654, Val Loss: 0.0449, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3012], Train Loss: 0.0571, Val Loss: 0.0484, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3013], Train Loss: 0.0578, Val Loss: 0.0488, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3014], Train Loss: 0.0629, Val Loss: 0.0533, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3015], Train Loss: 0.0630, Val Loss: 0.0478, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3016], Train Loss: 0.0682, Val Loss: 0.0472, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3017], Train Loss: 0.0637, Val Loss: 0.0443, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3018], Train Loss: 0.0703, Val Loss: 0.0595, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3019], Train Loss: 0.0573, Val Loss: 0.0423, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3020], Train Loss: 0.0700, Val Loss: 0.0559, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3021], Train Loss: 0.0624, Val Loss: 0.0471, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3022], Train Loss: 0.0628, Val Loss: 0.0490, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3023], Train Loss: 0.0627, Val Loss: 0.0514, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3024], Train Loss: 0.0671, Val Loss: 0.0485, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3025], Train Loss: 0.0577, Val Loss: 0.0409, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3026], Train Loss: 0.0676, Val Loss: 0.0504, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3027], Train Loss: 0.0565, Val Loss: 0.0469, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3028], Train Loss: 0.0677, Val Loss: 0.0684, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3029], Train Loss: 0.0643, Val Loss: 0.0372, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3030], Train Loss: 0.0635, Val Loss: 0.0674, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3031], Train Loss: 0.0648, Val Loss: 0.0448, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3032], Train Loss: 0.0567, Val Loss: 0.0550, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3033], Train Loss: 0.0612, Val Loss: 0.0467, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3034], Train Loss: 0.0619, Val Loss: 0.0562, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3035], Train Loss: 0.0660, Val Loss: 0.0435, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3036], Train Loss: 0.0647, Val Loss: 0.0575, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3037], Train Loss: 0.0528, Val Loss: 0.0458, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3038], Train Loss: 0.0668, Val Loss: 0.0735, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3039], Train Loss: 0.0663, Val Loss: 0.0332, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3040], Train Loss: 0.0642, Val Loss: 0.0583, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3041], Train Loss: 0.0683, Val Loss: 0.0458, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3042], Train Loss: 0.0560, Val Loss: 0.0542, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3043], Train Loss: 0.0656, Val Loss: 0.0473, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3044], Train Loss: 0.0696, Val Loss: 0.0745, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3045], Train Loss: 0.0661, Val Loss: 0.0378, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3046], Train Loss: 0.0691, Val Loss: 0.0623, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3047], Train Loss: 0.0655, Val Loss: 0.0457, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3048], Train Loss: 0.0639, Val Loss: 0.0574, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3049], Train Loss: 0.0716, Val Loss: 0.0394, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3050], Train Loss: 0.0558, Val Loss: 0.0533, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3051], Train Loss: 0.0693, Val Loss: 0.0434, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3052], Train Loss: 0.0676, Val Loss: 0.0561, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3053], Train Loss: 0.0662, Val Loss: 0.0496, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3054], Train Loss: 0.0687, Val Loss: 0.0399, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3055], Train Loss: 0.0693, Val Loss: 0.0701, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3056], Train Loss: 0.0611, Val Loss: 0.0419, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3057], Train Loss: 0.0676, Val Loss: 0.0735, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3058], Train Loss: 0.0645, Val Loss: 0.0449, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3059], Train Loss: 0.0617, Val Loss: 0.0648, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3060], Train Loss: 0.0695, Val Loss: 0.0410, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3061], Train Loss: 0.0660, Val Loss: 0.0565, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3062], Train Loss: 0.0680, Val Loss: 0.0363, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3063], Train Loss: 0.0624, Val Loss: 0.0549, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3064], Train Loss: 0.0634, Val Loss: 0.0473, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3065], Train Loss: 0.0648, Val Loss: 0.0572, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3066], Train Loss: 0.0622, Val Loss: 0.0378, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3067], Train Loss: 0.0566, Val Loss: 0.0649, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3068], Train Loss: 0.0589, Val Loss: 0.0495, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3069], Train Loss: 0.0687, Val Loss: 0.0453, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3070], Train Loss: 0.0648, Val Loss: 0.0472, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3071], Train Loss: 0.0680, Val Loss: 0.0584, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3072], Train Loss: 0.0618, Val Loss: 0.0539, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3073], Train Loss: 0.0621, Val Loss: 0.0433, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3074], Train Loss: 0.0641, Val Loss: 0.0457, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3075], Train Loss: 0.0583, Val Loss: 0.0558, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3076], Train Loss: 0.0701, Val Loss: 0.0377, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3077], Train Loss: 0.0617, Val Loss: 0.0665, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3078], Train Loss: 0.0548, Val Loss: 0.0471, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3079], Train Loss: 0.0628, Val Loss: 0.0577, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3080], Train Loss: 0.0622, Val Loss: 0.0537, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3081], Train Loss: 0.0637, Val Loss: 0.0442, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3082], Train Loss: 0.0630, Val Loss: 0.0567, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3083], Train Loss: 0.0582, Val Loss: 0.0507, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3084], Train Loss: 0.0670, Val Loss: 0.0539, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3085], Train Loss: 0.0608, Val Loss: 0.0528, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3086], Train Loss: 0.0678, Val Loss: 0.0560, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3087], Train Loss: 0.0571, Val Loss: 0.0425, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3088], Train Loss: 0.0595, Val Loss: 0.0587, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3089], Train Loss: 0.0555, Val Loss: 0.0397, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3090], Train Loss: 0.0571, Val Loss: 0.0759, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3091], Train Loss: 0.0608, Val Loss: 0.0453, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3092], Train Loss: 0.0631, Val Loss: 0.0618, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3093], Train Loss: 0.0612, Val Loss: 0.0482, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3094], Train Loss: 0.0692, Val Loss: 0.0481, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3095], Train Loss: 0.0707, Val Loss: 0.0477, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3096], Train Loss: 0.0656, Val Loss: 0.0462, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3097], Train Loss: 0.0589, Val Loss: 0.0453, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3098], Train Loss: 0.0678, Val Loss: 0.0514, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3099], Train Loss: 0.0603, Val Loss: 0.0640, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3100], Train Loss: 0.0617, Val Loss: 0.0442, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3101], Train Loss: 0.0617, Val Loss: 0.0469, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3102], Train Loss: 0.0674, Val Loss: 0.0446, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3103], Train Loss: 0.0563, Val Loss: 0.0638, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3104], Train Loss: 0.0653, Val Loss: 0.0422, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3105], Train Loss: 0.0747, Val Loss: 0.0454, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3106], Train Loss: 0.0666, Val Loss: 0.0539, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3107], Train Loss: 0.0647, Val Loss: 0.0390, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3108], Train Loss: 0.0621, Val Loss: 0.0585, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3109], Train Loss: 0.0670, Val Loss: 0.0379, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3110], Train Loss: 0.0639, Val Loss: 0.0505, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3111], Train Loss: 0.0699, Val Loss: 0.0460, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3112], Train Loss: 0.0627, Val Loss: 0.0528, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3113], Train Loss: 0.0635, Val Loss: 0.0356, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3114], Train Loss: 0.0591, Val Loss: 0.0485, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3115], Train Loss: 0.0592, Val Loss: 0.0573, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3116], Train Loss: 0.0655, Val Loss: 0.0431, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3117], Train Loss: 0.0679, Val Loss: 0.0494, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3118], Train Loss: 0.0608, Val Loss: 0.0440, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3119], Train Loss: 0.0679, Val Loss: 0.0571, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3120], Train Loss: 0.0739, Val Loss: 0.0412, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3121], Train Loss: 0.0656, Val Loss: 0.0533, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3122], Train Loss: 0.0628, Val Loss: 0.0422, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3123], Train Loss: 0.0678, Val Loss: 0.0544, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3124], Train Loss: 0.0604, Val Loss: 0.0414, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3125], Train Loss: 0.0585, Val Loss: 0.0603, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3126], Train Loss: 0.0623, Val Loss: 0.0435, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3127], Train Loss: 0.0580, Val Loss: 0.0594, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3128], Train Loss: 0.0669, Val Loss: 0.0502, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3129], Train Loss: 0.0637, Val Loss: 0.0674, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3130], Train Loss: 0.0627, Val Loss: 0.0407, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3131], Train Loss: 0.0581, Val Loss: 0.0635, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3132], Train Loss: 0.0641, Val Loss: 0.0385, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3133], Train Loss: 0.0663, Val Loss: 0.0508, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3134], Train Loss: 0.0617, Val Loss: 0.0447, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3135], Train Loss: 0.0551, Val Loss: 0.0561, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3136], Train Loss: 0.0625, Val Loss: 0.0411, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3137], Train Loss: 0.0648, Val Loss: 0.0643, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3138], Train Loss: 0.0613, Val Loss: 0.0427, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3139], Train Loss: 0.0654, Val Loss: 0.0596, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3140], Train Loss: 0.0596, Val Loss: 0.0489, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3141], Train Loss: 0.0630, Val Loss: 0.0414, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3142], Train Loss: 0.0600, Val Loss: 0.0508, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3143], Train Loss: 0.0634, Val Loss: 0.0481, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3144], Train Loss: 0.0663, Val Loss: 0.0435, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3145], Train Loss: 0.0644, Val Loss: 0.0552, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3146], Train Loss: 0.0620, Val Loss: 0.0564, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3147], Train Loss: 0.0603, Val Loss: 0.0453, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3148], Train Loss: 0.0677, Val Loss: 0.0539, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3149], Train Loss: 0.0669, Val Loss: 0.0509, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3150], Train Loss: 0.0598, Val Loss: 0.0562, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3151], Train Loss: 0.0632, Val Loss: 0.0401, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3152], Train Loss: 0.0612, Val Loss: 0.0472, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3153], Train Loss: 0.0620, Val Loss: 0.0521, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3154], Train Loss: 0.0590, Val Loss: 0.0540, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3155], Train Loss: 0.0589, Val Loss: 0.0342, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3156], Train Loss: 0.0591, Val Loss: 0.0533, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3157], Train Loss: 0.0633, Val Loss: 0.0392, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3158], Train Loss: 0.0640, Val Loss: 0.0788, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3159], Train Loss: 0.0623, Val Loss: 0.0419, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3160], Train Loss: 0.0628, Val Loss: 0.0635, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3161], Train Loss: 0.0592, Val Loss: 0.0461, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3162], Train Loss: 0.0635, Val Loss: 0.0475, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3163], Train Loss: 0.0566, Val Loss: 0.0482, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3164], Train Loss: 0.0602, Val Loss: 0.0461, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3165], Train Loss: 0.0646, Val Loss: 0.0451, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3166], Train Loss: 0.0596, Val Loss: 0.0536, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3167], Train Loss: 0.0619, Val Loss: 0.0507, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3168], Train Loss: 0.0653, Val Loss: 0.0491, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3169], Train Loss: 0.0704, Val Loss: 0.0455, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3170], Train Loss: 0.0665, Val Loss: 0.0492, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3171], Train Loss: 0.0621, Val Loss: 0.0505, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3172], Train Loss: 0.0613, Val Loss: 0.0558, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3173], Train Loss: 0.0606, Val Loss: 0.0434, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3174], Train Loss: 0.0662, Val Loss: 0.0412, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3175], Train Loss: 0.0661, Val Loss: 0.0591, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3176], Train Loss: 0.0690, Val Loss: 0.0390, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3177], Train Loss: 0.0554, Val Loss: 0.0521, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3178], Train Loss: 0.0644, Val Loss: 0.0469, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3179], Train Loss: 0.0573, Val Loss: 0.0444, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3180], Train Loss: 0.0691, Val Loss: 0.0437, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3181], Train Loss: 0.0597, Val Loss: 0.0430, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3182], Train Loss: 0.0604, Val Loss: 0.0478, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3183], Train Loss: 0.0667, Val Loss: 0.0438, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3184], Train Loss: 0.0562, Val Loss: 0.0485, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3185], Train Loss: 0.0577, Val Loss: 0.0430, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3186], Train Loss: 0.0666, Val Loss: 0.0510, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3187], Train Loss: 0.0554, Val Loss: 0.0431, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3188], Train Loss: 0.0609, Val Loss: 0.0458, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3189], Train Loss: 0.0532, Val Loss: 0.0505, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3190], Train Loss: 0.0615, Val Loss: 0.0365, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3191], Train Loss: 0.0549, Val Loss: 0.0490, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3192], Train Loss: 0.0631, Val Loss: 0.0437, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3193], Train Loss: 0.0673, Val Loss: 0.0502, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3194], Train Loss: 0.0673, Val Loss: 0.0387, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3195], Train Loss: 0.0589, Val Loss: 0.0448, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3196], Train Loss: 0.0720, Val Loss: 0.0547, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3197], Train Loss: 0.0618, Val Loss: 0.0435, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3198], Train Loss: 0.0596, Val Loss: 0.0479, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3199], Train Loss: 0.0628, Val Loss: 0.0405, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3200], Train Loss: 0.0641, Val Loss: 0.0574, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3201], Train Loss: 0.0562, Val Loss: 0.0423, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3202], Train Loss: 0.0599, Val Loss: 0.0485, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3203], Train Loss: 0.0564, Val Loss: 0.0476, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3204], Train Loss: 0.0631, Val Loss: 0.0452, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3205], Train Loss: 0.0610, Val Loss: 0.0505, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3206], Train Loss: 0.0649, Val Loss: 0.0418, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3207], Train Loss: 0.0653, Val Loss: 0.0496, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3208], Train Loss: 0.0634, Val Loss: 0.0475, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3209], Train Loss: 0.0578, Val Loss: 0.0473, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3210], Train Loss: 0.0600, Val Loss: 0.0452, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3211], Train Loss: 0.0549, Val Loss: 0.0464, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3212], Train Loss: 0.0678, Val Loss: 0.0439, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3213], Train Loss: 0.0594, Val Loss: 0.0498, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3214], Train Loss: 0.0580, Val Loss: 0.0447, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3215], Train Loss: 0.0582, Val Loss: 0.0545, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3216], Train Loss: 0.0635, Val Loss: 0.0431, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3217], Train Loss: 0.0617, Val Loss: 0.0491, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3218], Train Loss: 0.0722, Val Loss: 0.0438, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3219], Train Loss: 0.0592, Val Loss: 0.0498, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3220], Train Loss: 0.0677, Val Loss: 0.0399, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3221], Train Loss: 0.0654, Val Loss: 0.0472, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3222], Train Loss: 0.0592, Val Loss: 0.0506, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3223], Train Loss: 0.0533, Val Loss: 0.0470, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3224], Train Loss: 0.0571, Val Loss: 0.0436, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3225], Train Loss: 0.0653, Val Loss: 0.0444, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3226], Train Loss: 0.0690, Val Loss: 0.0474, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3227], Train Loss: 0.0598, Val Loss: 0.0418, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3228], Train Loss: 0.0564, Val Loss: 0.0469, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3229], Train Loss: 0.0683, Val Loss: 0.0390, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3230], Train Loss: 0.0626, Val Loss: 0.0512, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3231], Train Loss: 0.0617, Val Loss: 0.0429, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3232], Train Loss: 0.0650, Val Loss: 0.0512, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3233], Train Loss: 0.0623, Val Loss: 0.0487, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3234], Train Loss: 0.0602, Val Loss: 0.0337, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3235], Train Loss: 0.0597, Val Loss: 0.0613, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3236], Train Loss: 0.0601, Val Loss: 0.0345, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3237], Train Loss: 0.0541, Val Loss: 0.0509, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3238], Train Loss: 0.0601, Val Loss: 0.0402, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3239], Train Loss: 0.0678, Val Loss: 0.0508, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3240], Train Loss: 0.0616, Val Loss: 0.0513, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3241], Train Loss: 0.0636, Val Loss: 0.0609, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3242], Train Loss: 0.0556, Val Loss: 0.0472, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3243], Train Loss: 0.0614, Val Loss: 0.0579, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3244], Train Loss: 0.0666, Val Loss: 0.0424, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3245], Train Loss: 0.0654, Val Loss: 0.0541, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3246], Train Loss: 0.0630, Val Loss: 0.0462, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3247], Train Loss: 0.0598, Val Loss: 0.0500, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3248], Train Loss: 0.0611, Val Loss: 0.0461, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3249], Train Loss: 0.0572, Val Loss: 0.0597, LR: 0.000006, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3250], Train Loss: 0.0574, Val Loss: 0.0401, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3251], Train Loss: 0.0659, Val Loss: 0.0475, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3252], Train Loss: 0.0652, Val Loss: 0.0630, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3253], Train Loss: 0.0642, Val Loss: 0.0366, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3254], Train Loss: 0.0660, Val Loss: 0.0486, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3255], Train Loss: 0.0609, Val Loss: 0.0425, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3256], Train Loss: 0.0640, Val Loss: 0.0543, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3257], Train Loss: 0.0597, Val Loss: 0.0384, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3258], Train Loss: 0.0625, Val Loss: 0.0636, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3259], Train Loss: 0.0595, Val Loss: 0.0368, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3260], Train Loss: 0.0675, Val Loss: 0.0656, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3261], Train Loss: 0.0546, Val Loss: 0.0420, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3262], Train Loss: 0.0584, Val Loss: 0.0468, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3263], Train Loss: 0.0603, Val Loss: 0.0451, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3264], Train Loss: 0.0634, Val Loss: 0.0528, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3265], Train Loss: 0.0590, Val Loss: 0.0459, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3266], Train Loss: 0.0561, Val Loss: 0.0525, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3267], Train Loss: 0.0515, Val Loss: 0.0434, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3268], Train Loss: 0.0587, Val Loss: 0.0482, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3269], Train Loss: 0.0700, Val Loss: 0.0499, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3270], Train Loss: 0.0547, Val Loss: 0.0498, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3271], Train Loss: 0.0617, Val Loss: 0.0488, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3272], Train Loss: 0.0630, Val Loss: 0.0447, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3273], Train Loss: 0.0635, Val Loss: 0.0523, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3274], Train Loss: 0.0593, Val Loss: 0.0445, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3275], Train Loss: 0.0697, Val Loss: 0.0357, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3276], Train Loss: 0.0694, Val Loss: 0.0489, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3277], Train Loss: 0.0564, Val Loss: 0.0446, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3278], Train Loss: 0.0607, Val Loss: 0.0485, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3279], Train Loss: 0.0577, Val Loss: 0.0512, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3280], Train Loss: 0.0601, Val Loss: 0.0378, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3281], Train Loss: 0.0691, Val Loss: 0.0542, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3282], Train Loss: 0.0593, Val Loss: 0.0481, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3283], Train Loss: 0.0578, Val Loss: 0.0410, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3284], Train Loss: 0.0737, Val Loss: 0.0613, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3285], Train Loss: 0.0658, Val Loss: 0.0361, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3286], Train Loss: 0.0535, Val Loss: 0.0752, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3287], Train Loss: 0.0578, Val Loss: 0.0438, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3288], Train Loss: 0.0658, Val Loss: 0.0529, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3289], Train Loss: 0.0568, Val Loss: 0.0509, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3290], Train Loss: 0.0658, Val Loss: 0.0475, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3291], Train Loss: 0.0553, Val Loss: 0.0540, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3292], Train Loss: 0.0688, Val Loss: 0.0441, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3293], Train Loss: 0.0597, Val Loss: 0.0587, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3294], Train Loss: 0.0649, Val Loss: 0.0351, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3295], Train Loss: 0.0561, Val Loss: 0.0558, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3296], Train Loss: 0.0590, Val Loss: 0.0379, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3297], Train Loss: 0.0610, Val Loss: 0.0538, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3298], Train Loss: 0.0596, Val Loss: 0.0372, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3299], Train Loss: 0.0618, Val Loss: 0.0488, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3300], Train Loss: 0.0543, Val Loss: 0.0493, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3301], Train Loss: 0.0699, Val Loss: 0.0362, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3302], Train Loss: 0.0604, Val Loss: 0.0568, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3303], Train Loss: 0.0621, Val Loss: 0.0382, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3304], Train Loss: 0.0561, Val Loss: 0.0547, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3305], Train Loss: 0.0628, Val Loss: 0.0532, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3306], Train Loss: 0.0599, Val Loss: 0.0372, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3307], Train Loss: 0.0554, Val Loss: 0.0677, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3308], Train Loss: 0.0609, Val Loss: 0.0376, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3309], Train Loss: 0.0606, Val Loss: 0.0603, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3310], Train Loss: 0.0560, Val Loss: 0.0447, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3311], Train Loss: 0.0584, Val Loss: 0.0578, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3312], Train Loss: 0.0561, Val Loss: 0.0430, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3313], Train Loss: 0.0714, Val Loss: 0.0523, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3314], Train Loss: 0.0593, Val Loss: 0.0436, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3315], Train Loss: 0.0675, Val Loss: 0.0478, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3316], Train Loss: 0.0637, Val Loss: 0.0416, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3317], Train Loss: 0.0685, Val Loss: 0.0535, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3318], Train Loss: 0.0600, Val Loss: 0.0566, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3319], Train Loss: 0.0634, Val Loss: 0.0409, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3320], Train Loss: 0.0643, Val Loss: 0.0502, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3321], Train Loss: 0.0597, Val Loss: 0.0565, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3322], Train Loss: 0.0540, Val Loss: 0.0439, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3323], Train Loss: 0.0594, Val Loss: 0.0607, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3324], Train Loss: 0.0609, Val Loss: 0.0471, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3325], Train Loss: 0.0625, Val Loss: 0.0532, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3326], Train Loss: 0.0639, Val Loss: 0.0396, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3327], Train Loss: 0.0664, Val Loss: 0.0598, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3328], Train Loss: 0.0615, Val Loss: 0.0422, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3329], Train Loss: 0.0575, Val Loss: 0.0546, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3330], Train Loss: 0.0642, Val Loss: 0.0427, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3331], Train Loss: 0.0571, Val Loss: 0.0451, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3332], Train Loss: 0.0576, Val Loss: 0.0505, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3333], Train Loss: 0.0616, Val Loss: 0.0394, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3334], Train Loss: 0.0642, Val Loss: 0.0439, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3335], Train Loss: 0.0603, Val Loss: 0.0416, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3336], Train Loss: 0.0621, Val Loss: 0.0460, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3337], Train Loss: 0.0587, Val Loss: 0.0465, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3338], Train Loss: 0.0623, Val Loss: 0.0528, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3339], Train Loss: 0.0586, Val Loss: 0.0442, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3340], Train Loss: 0.0595, Val Loss: 0.0501, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3341], Train Loss: 0.0660, Val Loss: 0.0379, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3342], Train Loss: 0.0544, Val Loss: 0.0489, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3343], Train Loss: 0.0629, Val Loss: 0.0405, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3344], Train Loss: 0.0680, Val Loss: 0.0366, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3345], Train Loss: 0.0649, Val Loss: 0.0423, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3346], Train Loss: 0.0582, Val Loss: 0.0449, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3347], Train Loss: 0.0580, Val Loss: 0.0484, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3348], Train Loss: 0.0570, Val Loss: 0.0518, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3349], Train Loss: 0.0615, Val Loss: 0.0297, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3350], Train Loss: 0.0547, Val Loss: 0.0535, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3351], Train Loss: 0.0664, Val Loss: 0.0369, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3352], Train Loss: 0.0478, Val Loss: 0.0442, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3353], Train Loss: 0.0522, Val Loss: 0.0394, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3354], Train Loss: 0.0613, Val Loss: 0.0599, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3355], Train Loss: 0.0548, Val Loss: 0.0382, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3356], Train Loss: 0.0551, Val Loss: 0.0602, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3357], Train Loss: 0.0652, Val Loss: 0.0390, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3358], Train Loss: 0.0611, Val Loss: 0.0548, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3359], Train Loss: 0.0640, Val Loss: 0.0362, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3360], Train Loss: 0.0545, Val Loss: 0.0586, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3361], Train Loss: 0.0623, Val Loss: 0.0400, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3362], Train Loss: 0.0646, Val Loss: 0.0406, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3363], Train Loss: 0.0601, Val Loss: 0.0376, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3364], Train Loss: 0.0627, Val Loss: 0.0542, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3365], Train Loss: 0.0574, Val Loss: 0.0444, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3366], Train Loss: 0.0557, Val Loss: 0.0466, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3367], Train Loss: 0.0583, Val Loss: 0.0342, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3368], Train Loss: 0.0618, Val Loss: 0.0499, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3369], Train Loss: 0.0656, Val Loss: 0.0454, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3370], Train Loss: 0.0628, Val Loss: 0.0415, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3371], Train Loss: 0.0560, Val Loss: 0.0395, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3372], Train Loss: 0.0634, Val Loss: 0.0611, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3373], Train Loss: 0.0648, Val Loss: 0.0338, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3374], Train Loss: 0.0602, Val Loss: 0.0528, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3375], Train Loss: 0.0592, Val Loss: 0.0428, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3376], Train Loss: 0.0645, Val Loss: 0.0429, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3377], Train Loss: 0.0581, Val Loss: 0.0499, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3378], Train Loss: 0.0544, Val Loss: 0.0401, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3379], Train Loss: 0.0649, Val Loss: 0.0450, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3380], Train Loss: 0.0616, Val Loss: 0.0414, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3381], Train Loss: 0.0613, Val Loss: 0.0485, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3382], Train Loss: 0.0611, Val Loss: 0.0386, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3383], Train Loss: 0.0604, Val Loss: 0.0377, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3384], Train Loss: 0.0565, Val Loss: 0.0443, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3385], Train Loss: 0.0551, Val Loss: 0.0411, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3386], Train Loss: 0.0570, Val Loss: 0.0420, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3387], Train Loss: 0.0519, Val Loss: 0.0450, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3388], Train Loss: 0.0627, Val Loss: 0.0406, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3389], Train Loss: 0.0543, Val Loss: 0.0479, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3390], Train Loss: 0.0599, Val Loss: 0.0353, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3391], Train Loss: 0.0547, Val Loss: 0.0611, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3392], Train Loss: 0.0616, Val Loss: 0.0304, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3393], Train Loss: 0.0576, Val Loss: 0.0664, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3394], Train Loss: 0.0558, Val Loss: 0.0362, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3395], Train Loss: 0.0699, Val Loss: 0.0493, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3396], Train Loss: 0.0617, Val Loss: 0.0430, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3397], Train Loss: 0.0558, Val Loss: 0.0545, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3398], Train Loss: 0.0607, Val Loss: 0.0398, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3399], Train Loss: 0.0556, Val Loss: 0.0543, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3400], Train Loss: 0.0600, Val Loss: 0.0475, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3401], Train Loss: 0.0586, Val Loss: 0.0452, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3402], Train Loss: 0.0640, Val Loss: 0.0385, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3403], Train Loss: 0.0653, Val Loss: 0.0433, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3404], Train Loss: 0.0563, Val Loss: 0.0408, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3405], Train Loss: 0.0566, Val Loss: 0.0504, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3406], Train Loss: 0.0579, Val Loss: 0.0398, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3407], Train Loss: 0.0654, Val Loss: 0.0502, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3408], Train Loss: 0.0701, Val Loss: 0.0365, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3409], Train Loss: 0.0679, Val Loss: 0.0430, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3410], Train Loss: 0.0617, Val Loss: 0.0321, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3411], Train Loss: 0.0612, Val Loss: 0.0482, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3412], Train Loss: 0.0574, Val Loss: 0.0313, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3413], Train Loss: 0.0637, Val Loss: 0.0486, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3414], Train Loss: 0.0681, Val Loss: 0.0380, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3415], Train Loss: 0.0589, Val Loss: 0.0480, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3416], Train Loss: 0.0597, Val Loss: 0.0391, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3417], Train Loss: 0.0519, Val Loss: 0.0543, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3418], Train Loss: 0.0600, Val Loss: 0.0413, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3419], Train Loss: 0.0535, Val Loss: 0.0391, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3420], Train Loss: 0.0495, Val Loss: 0.0446, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3421], Train Loss: 0.0591, Val Loss: 0.0420, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3422], Train Loss: 0.0609, Val Loss: 0.0371, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3423], Train Loss: 0.0620, Val Loss: 0.0445, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3424], Train Loss: 0.0560, Val Loss: 0.0420, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3425], Train Loss: 0.0603, Val Loss: 0.0489, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3426], Train Loss: 0.0569, Val Loss: 0.0366, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3427], Train Loss: 0.0639, Val Loss: 0.0617, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3428], Train Loss: 0.0593, Val Loss: 0.0453, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3429], Train Loss: 0.0569, Val Loss: 0.0430, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3430], Train Loss: 0.0573, Val Loss: 0.0522, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3431], Train Loss: 0.0605, Val Loss: 0.0473, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3432], Train Loss: 0.0713, Val Loss: 0.0475, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3433], Train Loss: 0.0544, Val Loss: 0.0528, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3434], Train Loss: 0.0577, Val Loss: 0.0471, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3435], Train Loss: 0.0505, Val Loss: 0.0577, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3436], Train Loss: 0.0592, Val Loss: 0.0443, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3437], Train Loss: 0.0626, Val Loss: 0.0452, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3438], Train Loss: 0.0625, Val Loss: 0.0496, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3439], Train Loss: 0.0625, Val Loss: 0.0393, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3440], Train Loss: 0.0567, Val Loss: 0.0476, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3441], Train Loss: 0.0580, Val Loss: 0.0454, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3442], Train Loss: 0.0609, Val Loss: 0.0382, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3443], Train Loss: 0.0541, Val Loss: 0.0547, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3444], Train Loss: 0.0578, Val Loss: 0.0326, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3445], Train Loss: 0.0625, Val Loss: 0.0457, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3446], Train Loss: 0.0592, Val Loss: 0.0506, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3447], Train Loss: 0.0509, Val Loss: 0.0405, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3448], Train Loss: 0.0631, Val Loss: 0.0545, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3449], Train Loss: 0.0590, Val Loss: 0.0397, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3450], Train Loss: 0.0570, Val Loss: 0.0509, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3451], Train Loss: 0.0488, Val Loss: 0.0427, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3452], Train Loss: 0.0541, Val Loss: 0.0514, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3453], Train Loss: 0.0564, Val Loss: 0.0365, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3454], Train Loss: 0.0550, Val Loss: 0.0505, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3455], Train Loss: 0.0633, Val Loss: 0.0284, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3456], Train Loss: 0.0624, Val Loss: 0.0499, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3457], Train Loss: 0.0540, Val Loss: 0.0391, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3458], Train Loss: 0.0571, Val Loss: 0.0510, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3459], Train Loss: 0.0610, Val Loss: 0.0321, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3460], Train Loss: 0.0587, Val Loss: 0.0633, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3461], Train Loss: 0.0629, Val Loss: 0.0320, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3462], Train Loss: 0.0557, Val Loss: 0.0587, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3463], Train Loss: 0.0570, Val Loss: 0.0391, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3464], Train Loss: 0.0567, Val Loss: 0.0588, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3465], Train Loss: 0.0559, Val Loss: 0.0356, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3466], Train Loss: 0.0610, Val Loss: 0.0565, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3467], Train Loss: 0.0648, Val Loss: 0.0452, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3468], Train Loss: 0.0524, Val Loss: 0.0403, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3469], Train Loss: 0.0597, Val Loss: 0.0432, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3470], Train Loss: 0.0550, Val Loss: 0.0498, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3471], Train Loss: 0.0587, Val Loss: 0.0382, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3472], Train Loss: 0.0611, Val Loss: 0.0415, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3473], Train Loss: 0.0590, Val Loss: 0.0664, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3474], Train Loss: 0.0593, Val Loss: 0.0339, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3475], Train Loss: 0.0600, Val Loss: 0.0593, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3476], Train Loss: 0.0533, Val Loss: 0.0383, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3477], Train Loss: 0.0612, Val Loss: 0.0558, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3478], Train Loss: 0.0538, Val Loss: 0.0493, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3479], Train Loss: 0.0589, Val Loss: 0.0605, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3480], Train Loss: 0.0623, Val Loss: 0.0437, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3481], Train Loss: 0.0557, Val Loss: 0.0565, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3482], Train Loss: 0.0569, Val Loss: 0.0406, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3483], Train Loss: 0.0572, Val Loss: 0.0446, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3484], Train Loss: 0.0643, Val Loss: 0.0484, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3485], Train Loss: 0.0571, Val Loss: 0.0450, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3486], Train Loss: 0.0576, Val Loss: 0.0399, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3487], Train Loss: 0.0584, Val Loss: 0.0616, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3488], Train Loss: 0.0515, Val Loss: 0.0360, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3489], Train Loss: 0.0598, Val Loss: 0.0547, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3490], Train Loss: 0.0605, Val Loss: 0.0372, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3491], Train Loss: 0.0617, Val Loss: 0.0456, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3492], Train Loss: 0.0613, Val Loss: 0.0469, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3493], Train Loss: 0.0534, Val Loss: 0.0471, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3494], Train Loss: 0.0556, Val Loss: 0.0389, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3495], Train Loss: 0.0564, Val Loss: 0.0489, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3496], Train Loss: 0.0599, Val Loss: 0.0458, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3497], Train Loss: 0.0633, Val Loss: 0.0415, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3498], Train Loss: 0.0568, Val Loss: 0.0499, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3499], Train Loss: 0.0605, Val Loss: 0.0431, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3500], Train Loss: 0.0599, Val Loss: 0.0495, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3501], Train Loss: 0.0608, Val Loss: 0.0444, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3502], Train Loss: 0.0644, Val Loss: 0.0565, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3503], Train Loss: 0.0611, Val Loss: 0.0384, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3504], Train Loss: 0.0610, Val Loss: 0.0546, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3505], Train Loss: 0.0563, Val Loss: 0.0453, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3506], Train Loss: 0.0522, Val Loss: 0.0439, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3507], Train Loss: 0.0589, Val Loss: 0.0497, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3508], Train Loss: 0.0606, Val Loss: 0.0407, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3509], Train Loss: 0.0550, Val Loss: 0.0427, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3510], Train Loss: 0.0568, Val Loss: 0.0469, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3511], Train Loss: 0.0582, Val Loss: 0.0508, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3512], Train Loss: 0.0598, Val Loss: 0.0456, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3513], Train Loss: 0.0585, Val Loss: 0.0511, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3514], Train Loss: 0.0551, Val Loss: 0.0381, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3515], Train Loss: 0.0606, Val Loss: 0.0515, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3516], Train Loss: 0.0575, Val Loss: 0.0431, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3517], Train Loss: 0.0556, Val Loss: 0.0462, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3518], Train Loss: 0.0614, Val Loss: 0.0447, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3519], Train Loss: 0.0572, Val Loss: 0.0489, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3520], Train Loss: 0.0548, Val Loss: 0.0424, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3521], Train Loss: 0.0601, Val Loss: 0.0453, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3522], Train Loss: 0.0586, Val Loss: 0.0460, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3523], Train Loss: 0.0597, Val Loss: 0.0434, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3524], Train Loss: 0.0612, Val Loss: 0.0514, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3525], Train Loss: 0.0581, Val Loss: 0.0338, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3526], Train Loss: 0.0572, Val Loss: 0.0498, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3527], Train Loss: 0.0586, Val Loss: 0.0504, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3528], Train Loss: 0.0628, Val Loss: 0.0395, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3529], Train Loss: 0.0561, Val Loss: 0.0554, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3530], Train Loss: 0.0570, Val Loss: 0.0369, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3531], Train Loss: 0.0600, Val Loss: 0.0548, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3532], Train Loss: 0.0632, Val Loss: 0.0342, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3533], Train Loss: 0.0600, Val Loss: 0.0529, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3534], Train Loss: 0.0713, Val Loss: 0.0364, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3535], Train Loss: 0.0618, Val Loss: 0.0496, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3536], Train Loss: 0.0545, Val Loss: 0.0354, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3537], Train Loss: 0.0626, Val Loss: 0.0371, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3538], Train Loss: 0.0583, Val Loss: 0.0451, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3539], Train Loss: 0.0539, Val Loss: 0.0333, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3540], Train Loss: 0.0626, Val Loss: 0.0537, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3541], Train Loss: 0.0596, Val Loss: 0.0430, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3542], Train Loss: 0.0614, Val Loss: 0.0367, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3543], Train Loss: 0.0614, Val Loss: 0.0330, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3544], Train Loss: 0.0594, Val Loss: 0.0445, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3545], Train Loss: 0.0598, Val Loss: 0.0375, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3546], Train Loss: 0.0634, Val Loss: 0.0358, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3547], Train Loss: 0.0558, Val Loss: 0.0422, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3548], Train Loss: 0.0588, Val Loss: 0.0371, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3549], Train Loss: 0.0568, Val Loss: 0.0486, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3550], Train Loss: 0.0553, Val Loss: 0.0385, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3551], Train Loss: 0.0616, Val Loss: 0.0457, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3552], Train Loss: 0.0624, Val Loss: 0.0352, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3553], Train Loss: 0.0587, Val Loss: 0.0394, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3554], Train Loss: 0.0539, Val Loss: 0.0488, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3555], Train Loss: 0.0547, Val Loss: 0.0481, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3556], Train Loss: 0.0568, Val Loss: 0.0401, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3557], Train Loss: 0.0561, Val Loss: 0.0431, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3558], Train Loss: 0.0557, Val Loss: 0.0435, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3559], Train Loss: 0.0627, Val Loss: 0.0387, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3560], Train Loss: 0.0569, Val Loss: 0.0501, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3561], Train Loss: 0.0568, Val Loss: 0.0332, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3562], Train Loss: 0.0579, Val Loss: 0.0494, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3563], Train Loss: 0.0549, Val Loss: 0.0426, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3564], Train Loss: 0.0608, Val Loss: 0.0390, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3565], Train Loss: 0.0582, Val Loss: 0.0453, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3566], Train Loss: 0.0519, Val Loss: 0.0560, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3567], Train Loss: 0.0605, Val Loss: 0.0377, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3568], Train Loss: 0.0525, Val Loss: 0.0531, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3569], Train Loss: 0.0581, Val Loss: 0.0375, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3570], Train Loss: 0.0544, Val Loss: 0.0465, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3571], Train Loss: 0.0610, Val Loss: 0.0415, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3572], Train Loss: 0.0593, Val Loss: 0.0305, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3573], Train Loss: 0.0534, Val Loss: 0.0600, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3574], Train Loss: 0.0591, Val Loss: 0.0315, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3575], Train Loss: 0.0602, Val Loss: 0.0513, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3576], Train Loss: 0.0582, Val Loss: 0.0390, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3577], Train Loss: 0.0575, Val Loss: 0.0484, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3578], Train Loss: 0.0641, Val Loss: 0.0343, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3579], Train Loss: 0.0607, Val Loss: 0.0490, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3580], Train Loss: 0.0555, Val Loss: 0.0428, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3581], Train Loss: 0.0571, Val Loss: 0.0431, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3582], Train Loss: 0.0573, Val Loss: 0.0446, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3583], Train Loss: 0.0510, Val Loss: 0.0431, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3584], Train Loss: 0.0593, Val Loss: 0.0478, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3585], Train Loss: 0.0603, Val Loss: 0.0451, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3586], Train Loss: 0.0591, Val Loss: 0.0510, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3587], Train Loss: 0.0586, Val Loss: 0.0413, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3588], Train Loss: 0.0563, Val Loss: 0.0413, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3589], Train Loss: 0.0553, Val Loss: 0.0363, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3590], Train Loss: 0.0620, Val Loss: 0.0542, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3591], Train Loss: 0.0484, Val Loss: 0.0377, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3592], Train Loss: 0.0545, Val Loss: 0.0429, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3593], Train Loss: 0.0551, Val Loss: 0.0489, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3594], Train Loss: 0.0574, Val Loss: 0.0415, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3595], Train Loss: 0.0604, Val Loss: 0.0554, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3596], Train Loss: 0.0618, Val Loss: 0.0365, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3597], Train Loss: 0.0664, Val Loss: 0.0565, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3598], Train Loss: 0.0549, Val Loss: 0.0390, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3599], Train Loss: 0.0548, Val Loss: 0.0475, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3600], Train Loss: 0.0569, Val Loss: 0.0360, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3601], Train Loss: 0.0603, Val Loss: 0.0415, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3602], Train Loss: 0.0605, Val Loss: 0.0434, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3603], Train Loss: 0.0618, Val Loss: 0.0381, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3604], Train Loss: 0.0659, Val Loss: 0.0329, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3605], Train Loss: 0.0570, Val Loss: 0.0579, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3606], Train Loss: 0.0516, Val Loss: 0.0315, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3607], Train Loss: 0.0632, Val Loss: 0.0508, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3608], Train Loss: 0.0565, Val Loss: 0.0387, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3609], Train Loss: 0.0615, Val Loss: 0.0402, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3610], Train Loss: 0.0498, Val Loss: 0.0464, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3611], Train Loss: 0.0545, Val Loss: 0.0313, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3612], Train Loss: 0.0665, Val Loss: 0.0458, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3613], Train Loss: 0.0578, Val Loss: 0.0394, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3614], Train Loss: 0.0651, Val Loss: 0.0447, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3615], Train Loss: 0.0607, Val Loss: 0.0360, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3616], Train Loss: 0.0565, Val Loss: 0.0474, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3617], Train Loss: 0.0589, Val Loss: 0.0413, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3618], Train Loss: 0.0638, Val Loss: 0.0432, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3619], Train Loss: 0.0559, Val Loss: 0.0354, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3620], Train Loss: 0.0527, Val Loss: 0.0473, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3621], Train Loss: 0.0541, Val Loss: 0.0408, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3622], Train Loss: 0.0534, Val Loss: 0.0441, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3623], Train Loss: 0.0582, Val Loss: 0.0491, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3624], Train Loss: 0.0528, Val Loss: 0.0420, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3625], Train Loss: 0.0563, Val Loss: 0.0421, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3626], Train Loss: 0.0536, Val Loss: 0.0331, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3627], Train Loss: 0.0576, Val Loss: 0.0420, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3628], Train Loss: 0.0576, Val Loss: 0.0433, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3629], Train Loss: 0.0620, Val Loss: 0.0292, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3630], Train Loss: 0.0572, Val Loss: 0.0467, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3631], Train Loss: 0.0581, Val Loss: 0.0311, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3632], Train Loss: 0.0538, Val Loss: 0.0450, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3633], Train Loss: 0.0593, Val Loss: 0.0409, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3634], Train Loss: 0.0582, Val Loss: 0.0398, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3635], Train Loss: 0.0568, Val Loss: 0.0566, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3636], Train Loss: 0.0567, Val Loss: 0.0390, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3637], Train Loss: 0.0601, Val Loss: 0.0531, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3638], Train Loss: 0.0507, Val Loss: 0.0391, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3639], Train Loss: 0.0563, Val Loss: 0.0486, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3640], Train Loss: 0.0607, Val Loss: 0.0334, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3641], Train Loss: 0.0570, Val Loss: 0.0421, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3642], Train Loss: 0.0608, Val Loss: 0.0381, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3643], Train Loss: 0.0577, Val Loss: 0.0313, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3644], Train Loss: 0.0597, Val Loss: 0.0556, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3645], Train Loss: 0.0566, Val Loss: 0.0406, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3646], Train Loss: 0.0618, Val Loss: 0.0459, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3647], Train Loss: 0.0606, Val Loss: 0.0489, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3648], Train Loss: 0.0562, Val Loss: 0.0299, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3649], Train Loss: 0.0580, Val Loss: 0.0490, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3650], Train Loss: 0.0535, Val Loss: 0.0345, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3651], Train Loss: 0.0543, Val Loss: 0.0426, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3652], Train Loss: 0.0647, Val Loss: 0.0333, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3653], Train Loss: 0.0547, Val Loss: 0.0380, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3654], Train Loss: 0.0553, Val Loss: 0.0502, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3655], Train Loss: 0.0608, Val Loss: 0.0281, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3656], Train Loss: 0.0634, Val Loss: 0.0509, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3657], Train Loss: 0.0593, Val Loss: 0.0336, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3658], Train Loss: 0.0589, Val Loss: 0.0474, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3659], Train Loss: 0.0564, Val Loss: 0.0439, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3660], Train Loss: 0.0683, Val Loss: 0.0336, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3661], Train Loss: 0.0526, Val Loss: 0.0646, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3662], Train Loss: 0.0526, Val Loss: 0.0291, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3663], Train Loss: 0.0627, Val Loss: 0.0558, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3664], Train Loss: 0.0595, Val Loss: 0.0371, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3665], Train Loss: 0.0603, Val Loss: 0.0433, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3666], Train Loss: 0.0602, Val Loss: 0.0346, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3667], Train Loss: 0.0586, Val Loss: 0.0512, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3668], Train Loss: 0.0521, Val Loss: 0.0360, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3669], Train Loss: 0.0528, Val Loss: 0.0458, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3670], Train Loss: 0.0598, Val Loss: 0.0379, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3671], Train Loss: 0.0623, Val Loss: 0.0374, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3672], Train Loss: 0.0600, Val Loss: 0.0383, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3673], Train Loss: 0.0581, Val Loss: 0.0378, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3674], Train Loss: 0.0606, Val Loss: 0.0525, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3675], Train Loss: 0.0619, Val Loss: 0.0497, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3676], Train Loss: 0.0611, Val Loss: 0.0368, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3677], Train Loss: 0.0608, Val Loss: 0.0372, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3678], Train Loss: 0.0583, Val Loss: 0.0374, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3679], Train Loss: 0.0597, Val Loss: 0.0492, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3680], Train Loss: 0.0559, Val Loss: 0.0408, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3681], Train Loss: 0.0537, Val Loss: 0.0438, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3682], Train Loss: 0.0580, Val Loss: 0.0421, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3683], Train Loss: 0.0643, Val Loss: 0.0459, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3684], Train Loss: 0.0544, Val Loss: 0.0397, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3685], Train Loss: 0.0535, Val Loss: 0.0384, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3686], Train Loss: 0.0557, Val Loss: 0.0444, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3687], Train Loss: 0.0553, Val Loss: 0.0489, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3688], Train Loss: 0.0607, Val Loss: 0.0363, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3689], Train Loss: 0.0585, Val Loss: 0.0445, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3690], Train Loss: 0.0483, Val Loss: 0.0471, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3691], Train Loss: 0.0622, Val Loss: 0.0463, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3692], Train Loss: 0.0502, Val Loss: 0.0402, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3693], Train Loss: 0.0598, Val Loss: 0.0418, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3694], Train Loss: 0.0535, Val Loss: 0.0462, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3695], Train Loss: 0.0552, Val Loss: 0.0431, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3696], Train Loss: 0.0519, Val Loss: 0.0367, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3697], Train Loss: 0.0546, Val Loss: 0.0474, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3698], Train Loss: 0.0520, Val Loss: 0.0382, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3699], Train Loss: 0.0537, Val Loss: 0.0476, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3700], Train Loss: 0.0565, Val Loss: 0.0449, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3701], Train Loss: 0.0467, Val Loss: 0.0454, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3702], Train Loss: 0.0591, Val Loss: 0.0612, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3703], Train Loss: 0.0586, Val Loss: 0.0379, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3704], Train Loss: 0.0553, Val Loss: 0.0482, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3705], Train Loss: 0.0485, Val Loss: 0.0491, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3706], Train Loss: 0.0527, Val Loss: 0.0403, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3707], Train Loss: 0.0617, Val Loss: 0.0447, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3708], Train Loss: 0.0566, Val Loss: 0.0368, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3709], Train Loss: 0.0572, Val Loss: 0.0392, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3710], Train Loss: 0.0676, Val Loss: 0.0502, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3711], Train Loss: 0.0547, Val Loss: 0.0364, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3712], Train Loss: 0.0538, Val Loss: 0.0566, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3713], Train Loss: 0.0533, Val Loss: 0.0379, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3714], Train Loss: 0.0599, Val Loss: 0.0494, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3715], Train Loss: 0.0618, Val Loss: 0.0394, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3716], Train Loss: 0.0548, Val Loss: 0.0434, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3717], Train Loss: 0.0533, Val Loss: 0.0459, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3718], Train Loss: 0.0567, Val Loss: 0.0393, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3719], Train Loss: 0.0620, Val Loss: 0.0428, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3720], Train Loss: 0.0513, Val Loss: 0.0399, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3721], Train Loss: 0.0560, Val Loss: 0.0403, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3722], Train Loss: 0.0549, Val Loss: 0.0446, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3723], Train Loss: 0.0510, Val Loss: 0.0533, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3724], Train Loss: 0.0639, Val Loss: 0.0360, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3725], Train Loss: 0.0625, Val Loss: 0.0385, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3726], Train Loss: 0.0560, Val Loss: 0.0429, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3727], Train Loss: 0.0583, Val Loss: 0.0355, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3728], Train Loss: 0.0515, Val Loss: 0.0516, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3729], Train Loss: 0.0503, Val Loss: 0.0377, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3730], Train Loss: 0.0535, Val Loss: 0.0359, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3731], Train Loss: 0.0552, Val Loss: 0.0441, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3732], Train Loss: 0.0549, Val Loss: 0.0472, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3733], Train Loss: 0.0613, Val Loss: 0.0367, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3734], Train Loss: 0.0556, Val Loss: 0.0380, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3735], Train Loss: 0.0636, Val Loss: 0.0364, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3736], Train Loss: 0.0568, Val Loss: 0.0420, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3737], Train Loss: 0.0570, Val Loss: 0.0339, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3738], Train Loss: 0.0727, Val Loss: 0.0367, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3739], Train Loss: 0.0580, Val Loss: 0.0453, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3740], Train Loss: 0.0528, Val Loss: 0.0360, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3741], Train Loss: 0.0530, Val Loss: 0.0448, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3742], Train Loss: 0.0601, Val Loss: 0.0323, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3743], Train Loss: 0.0624, Val Loss: 0.0420, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3744], Train Loss: 0.0560, Val Loss: 0.0508, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3745], Train Loss: 0.0534, Val Loss: 0.0324, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3746], Train Loss: 0.0592, Val Loss: 0.0465, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3747], Train Loss: 0.0459, Val Loss: 0.0422, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3748], Train Loss: 0.0575, Val Loss: 0.0378, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3749], Train Loss: 0.0586, Val Loss: 0.0463, LR: 0.000007, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3750], Train Loss: 0.0551, Val Loss: 0.0365, LR: 0.000008, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3751], Train Loss: 0.0610, Val Loss: 0.0398, LR: 0.000008, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3752], Train Loss: 0.0582, Val Loss: 0.0362, LR: 0.000008, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3753], Train Loss: 0.0559, Val Loss: 0.0312, LR: 0.000008, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3754], Train Loss: 0.0606, Val Loss: 0.0355, LR: 0.000008, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3755], Train Loss: 0.0562, Val Loss: 0.0299, LR: 0.000008, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3756], Train Loss: 0.0555, Val Loss: 0.0351, LR: 0.000008, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3757], Train Loss: 0.0596, Val Loss: 0.0345, LR: 0.000008, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3758], Train Loss: 0.0499, Val Loss: 0.0380, LR: 0.000008, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3759], Train Loss: 0.0532, Val Loss: 0.0386, LR: 0.000008, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3760], Train Loss: 0.0651, Val Loss: 0.0314, LR: 0.000008, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3761], Train Loss: 0.0536, Val Loss: 0.0465, LR: 0.000008, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3762], Train Loss: 0.0629, Val Loss: 0.0360, LR: 0.000008, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3763], Train Loss: 0.0494, Val Loss: 0.0413, LR: 0.000008, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3764], Train Loss: 0.0611, Val Loss: 0.0308, LR: 0.000008, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3765], Train Loss: 0.0506, Val Loss: 0.0323, LR: 0.000008, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3766], Train Loss: 0.0562, Val Loss: 0.0361, LR: 0.000008, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3767], Train Loss: 0.0644, Val Loss: 0.0367, LR: 0.000008, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3768], Train Loss: 0.0599, Val Loss: 0.0329, LR: 0.000008, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3769], Train Loss: 0.0570, Val Loss: 0.0307, LR: 0.000008, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3770], Train Loss: 0.0551, Val Loss: 0.0293, LR: 0.000008, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3771], Train Loss: 0.0592, Val Loss: 0.0336, LR: 0.000008, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3772], Train Loss: 0.0642, Val Loss: 0.0321, LR: 0.000008, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3773], Train Loss: 0.0630, Val Loss: 0.0359, LR: 0.000008, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3774], Train Loss: 0.0603, Val Loss: 0.0330, LR: 0.000008, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3775], Train Loss: 0.0635, Val Loss: 0.0368, LR: 0.000008, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3776], Train Loss: 0.0592, Val Loss: 0.0374, LR: 0.000008, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3777], Train Loss: 0.0626, Val Loss: 0.0396, LR: 0.000008, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3778], Train Loss: 0.0573, Val Loss: 0.0321, LR: 0.000008, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3779], Train Loss: 0.0601, Val Loss: 0.0506, LR: 0.000008, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3780], Train Loss: 0.0645, Val Loss: 0.0381, LR: 0.000008, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3781], Train Loss: 0.0620, Val Loss: 0.0331, LR: 0.000008, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3782], Train Loss: 0.0590, Val Loss: 0.0338, LR: 0.000008, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3783], Train Loss: 0.0576, Val Loss: 0.0457, LR: 0.000008, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3784], Train Loss: 0.0565, Val Loss: 0.0354, LR: 0.000008, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3785], Train Loss: 0.0593, Val Loss: 0.0395, LR: 0.000008, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3786], Train Loss: 0.0566, Val Loss: 0.0426, LR: 0.000008, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3787], Train Loss: 0.0528, Val Loss: 0.0507, LR: 0.000008, best val loss was: 0.0274
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3788], Train Loss: 0.0522, Val Loss: 0.0263, LR: 0.000008, best val loss was: 0.0263
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3789], Train Loss: 0.0542, Val Loss: 0.0520, LR: 0.000008, best val loss was: 0.0263
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3790], Train Loss: 0.0571, Val Loss: 0.0280, LR: 0.000008, best val loss was: 0.0263
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3791], Train Loss: 0.0602, Val Loss: 0.0462, LR: 0.000008, best val loss was: 0.0263
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3792], Train Loss: 0.0616, Val Loss: 0.0355, LR: 0.000008, best val loss was: 0.0263
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3793], Train Loss: 0.0571, Val Loss: 0.0341, LR: 0.000008, best val loss was: 0.0263
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3794], Train Loss: 0.0567, Val Loss: 0.0423, LR: 0.000008, best val loss was: 0.0263
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3795], Train Loss: 0.0651, Val Loss: 0.0308, LR: 0.000008, best val loss was: 0.0263
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3796], Train Loss: 0.0542, Val Loss: 0.0401, LR: 0.000008, best val loss was: 0.0263
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3797], Train Loss: 0.0666, Val Loss: 0.0324, LR: 0.000008, best val loss was: 0.0263
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3798], Train Loss: 0.0636, Val Loss: 0.0301, LR: 0.000008, best val loss was: 0.0263
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3799], Train Loss: 0.0632, Val Loss: 0.0412, LR: 0.000008, best val loss was: 0.0263
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3800], Train Loss: 0.0640, Val Loss: 0.0243, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3801], Train Loss: 0.0583, Val Loss: 0.0330, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3802], Train Loss: 0.0573, Val Loss: 0.0343, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3803], Train Loss: 0.0583, Val Loss: 0.0375, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3804], Train Loss: 0.0561, Val Loss: 0.0411, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3805], Train Loss: 0.0556, Val Loss: 0.0379, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3806], Train Loss: 0.0569, Val Loss: 0.0357, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3807], Train Loss: 0.0654, Val Loss: 0.0274, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3808], Train Loss: 0.0599, Val Loss: 0.0525, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3809], Train Loss: 0.0630, Val Loss: 0.0317, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3810], Train Loss: 0.0598, Val Loss: 0.0402, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3811], Train Loss: 0.0522, Val Loss: 0.0444, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3812], Train Loss: 0.0648, Val Loss: 0.0418, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3813], Train Loss: 0.0627, Val Loss: 0.0468, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3814], Train Loss: 0.0564, Val Loss: 0.0399, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3815], Train Loss: 0.0585, Val Loss: 0.0307, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3816], Train Loss: 0.0520, Val Loss: 0.0405, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3817], Train Loss: 0.0491, Val Loss: 0.0345, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3818], Train Loss: 0.0556, Val Loss: 0.0365, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3819], Train Loss: 0.0594, Val Loss: 0.0532, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3820], Train Loss: 0.0629, Val Loss: 0.0284, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3821], Train Loss: 0.0565, Val Loss: 0.0468, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3822], Train Loss: 0.0563, Val Loss: 0.0360, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3823], Train Loss: 0.0509, Val Loss: 0.0387, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3824], Train Loss: 0.0582, Val Loss: 0.0438, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3825], Train Loss: 0.0677, Val Loss: 0.0302, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3826], Train Loss: 0.0568, Val Loss: 0.0447, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3827], Train Loss: 0.0642, Val Loss: 0.0393, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3828], Train Loss: 0.0583, Val Loss: 0.0381, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3829], Train Loss: 0.0532, Val Loss: 0.0359, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3830], Train Loss: 0.0593, Val Loss: 0.0368, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3831], Train Loss: 0.0547, Val Loss: 0.0400, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3832], Train Loss: 0.0568, Val Loss: 0.0360, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3833], Train Loss: 0.0548, Val Loss: 0.0403, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3834], Train Loss: 0.0560, Val Loss: 0.0426, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3835], Train Loss: 0.0578, Val Loss: 0.0337, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3836], Train Loss: 0.0592, Val Loss: 0.0349, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3837], Train Loss: 0.0570, Val Loss: 0.0432, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3838], Train Loss: 0.0527, Val Loss: 0.0357, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3839], Train Loss: 0.0510, Val Loss: 0.0368, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3840], Train Loss: 0.0517, Val Loss: 0.0379, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3841], Train Loss: 0.0585, Val Loss: 0.0320, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3842], Train Loss: 0.0603, Val Loss: 0.0325, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3843], Train Loss: 0.0623, Val Loss: 0.0374, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3844], Train Loss: 0.0614, Val Loss: 0.0339, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3845], Train Loss: 0.0590, Val Loss: 0.0324, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3846], Train Loss: 0.0558, Val Loss: 0.0401, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3847], Train Loss: 0.0604, Val Loss: 0.0279, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3848], Train Loss: 0.0616, Val Loss: 0.0279, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3849], Train Loss: 0.0673, Val Loss: 0.0369, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3850], Train Loss: 0.0614, Val Loss: 0.0317, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3851], Train Loss: 0.0545, Val Loss: 0.0357, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3852], Train Loss: 0.0551, Val Loss: 0.0437, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3853], Train Loss: 0.0543, Val Loss: 0.0335, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3854], Train Loss: 0.0638, Val Loss: 0.0345, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3855], Train Loss: 0.0493, Val Loss: 0.0451, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3856], Train Loss: 0.0474, Val Loss: 0.0397, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3857], Train Loss: 0.0541, Val Loss: 0.0341, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3858], Train Loss: 0.0621, Val Loss: 0.0378, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3859], Train Loss: 0.0575, Val Loss: 0.0350, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3860], Train Loss: 0.0518, Val Loss: 0.0403, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3861], Train Loss: 0.0536, Val Loss: 0.0335, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3862], Train Loss: 0.0518, Val Loss: 0.0367, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3863], Train Loss: 0.0520, Val Loss: 0.0312, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3864], Train Loss: 0.0577, Val Loss: 0.0367, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3865], Train Loss: 0.0643, Val Loss: 0.0428, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3866], Train Loss: 0.0573, Val Loss: 0.0398, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3867], Train Loss: 0.0524, Val Loss: 0.0387, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3868], Train Loss: 0.0531, Val Loss: 0.0479, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3869], Train Loss: 0.0584, Val Loss: 0.0410, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3870], Train Loss: 0.0531, Val Loss: 0.0386, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3871], Train Loss: 0.0615, Val Loss: 0.0519, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3872], Train Loss: 0.0556, Val Loss: 0.0391, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3873], Train Loss: 0.0549, Val Loss: 0.0366, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3874], Train Loss: 0.0536, Val Loss: 0.0505, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3875], Train Loss: 0.0622, Val Loss: 0.0271, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3876], Train Loss: 0.0565, Val Loss: 0.0465, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3877], Train Loss: 0.0491, Val Loss: 0.0380, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3878], Train Loss: 0.0557, Val Loss: 0.0375, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3879], Train Loss: 0.0559, Val Loss: 0.0451, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3880], Train Loss: 0.0562, Val Loss: 0.0291, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3881], Train Loss: 0.0575, Val Loss: 0.0503, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3882], Train Loss: 0.0577, Val Loss: 0.0361, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3883], Train Loss: 0.0553, Val Loss: 0.0343, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3884], Train Loss: 0.0603, Val Loss: 0.0437, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3885], Train Loss: 0.0544, Val Loss: 0.0323, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3886], Train Loss: 0.0570, Val Loss: 0.0446, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3887], Train Loss: 0.0568, Val Loss: 0.0273, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3888], Train Loss: 0.0599, Val Loss: 0.0414, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3889], Train Loss: 0.0562, Val Loss: 0.0386, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3890], Train Loss: 0.0583, Val Loss: 0.0298, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3891], Train Loss: 0.0601, Val Loss: 0.0339, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3892], Train Loss: 0.0522, Val Loss: 0.0400, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3893], Train Loss: 0.0629, Val Loss: 0.0408, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3894], Train Loss: 0.0526, Val Loss: 0.0371, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3895], Train Loss: 0.0534, Val Loss: 0.0374, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3896], Train Loss: 0.0601, Val Loss: 0.0365, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3897], Train Loss: 0.0542, Val Loss: 0.0579, LR: 0.000008, best val loss was: 0.0243
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3898], Train Loss: 0.0588, Val Loss: 0.0237, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3899], Train Loss: 0.0602, Val Loss: 0.0475, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3900], Train Loss: 0.0603, Val Loss: 0.0301, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3901], Train Loss: 0.0562, Val Loss: 0.0545, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3902], Train Loss: 0.0542, Val Loss: 0.0342, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3903], Train Loss: 0.0597, Val Loss: 0.0455, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3904], Train Loss: 0.0602, Val Loss: 0.0397, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3905], Train Loss: 0.0518, Val Loss: 0.0378, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3906], Train Loss: 0.0537, Val Loss: 0.0326, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3907], Train Loss: 0.0589, Val Loss: 0.0400, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3908], Train Loss: 0.0552, Val Loss: 0.0350, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3909], Train Loss: 0.0646, Val Loss: 0.0315, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3910], Train Loss: 0.0636, Val Loss: 0.0464, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3911], Train Loss: 0.0548, Val Loss: 0.0314, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3912], Train Loss: 0.0598, Val Loss: 0.0476, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3913], Train Loss: 0.0536, Val Loss: 0.0344, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3914], Train Loss: 0.0520, Val Loss: 0.0359, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3915], Train Loss: 0.0603, Val Loss: 0.0410, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3916], Train Loss: 0.0533, Val Loss: 0.0313, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3917], Train Loss: 0.0556, Val Loss: 0.0418, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3918], Train Loss: 0.0587, Val Loss: 0.0393, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3919], Train Loss: 0.0548, Val Loss: 0.0331, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3920], Train Loss: 0.0556, Val Loss: 0.0421, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3921], Train Loss: 0.0535, Val Loss: 0.0400, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3922], Train Loss: 0.0528, Val Loss: 0.0379, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3923], Train Loss: 0.0627, Val Loss: 0.0398, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3924], Train Loss: 0.0580, Val Loss: 0.0432, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3925], Train Loss: 0.0598, Val Loss: 0.0402, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3926], Train Loss: 0.0558, Val Loss: 0.0368, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3927], Train Loss: 0.0592, Val Loss: 0.0382, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3928], Train Loss: 0.0545, Val Loss: 0.0505, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3929], Train Loss: 0.0554, Val Loss: 0.0340, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3930], Train Loss: 0.0593, Val Loss: 0.0383, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3931], Train Loss: 0.0601, Val Loss: 0.0504, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3932], Train Loss: 0.0594, Val Loss: 0.0383, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3933], Train Loss: 0.0557, Val Loss: 0.0409, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3934], Train Loss: 0.0498, Val Loss: 0.0382, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3935], Train Loss: 0.0573, Val Loss: 0.0349, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3936], Train Loss: 0.0681, Val Loss: 0.0364, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3937], Train Loss: 0.0539, Val Loss: 0.0338, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3938], Train Loss: 0.0588, Val Loss: 0.0324, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3939], Train Loss: 0.0639, Val Loss: 0.0354, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3940], Train Loss: 0.0573, Val Loss: 0.0478, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3941], Train Loss: 0.0579, Val Loss: 0.0281, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3942], Train Loss: 0.0524, Val Loss: 0.0481, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3943], Train Loss: 0.0580, Val Loss: 0.0309, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3944], Train Loss: 0.0583, Val Loss: 0.0421, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3945], Train Loss: 0.0569, Val Loss: 0.0312, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3946], Train Loss: 0.0487, Val Loss: 0.0370, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3947], Train Loss: 0.0565, Val Loss: 0.0481, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3948], Train Loss: 0.0574, Val Loss: 0.0348, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3949], Train Loss: 0.0544, Val Loss: 0.0336, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3950], Train Loss: 0.0523, Val Loss: 0.0448, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3951], Train Loss: 0.0565, Val Loss: 0.0335, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3952], Train Loss: 0.0517, Val Loss: 0.0402, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3953], Train Loss: 0.0565, Val Loss: 0.0421, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3954], Train Loss: 0.0548, Val Loss: 0.0402, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3955], Train Loss: 0.0537, Val Loss: 0.0327, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3956], Train Loss: 0.0561, Val Loss: 0.0372, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3957], Train Loss: 0.0584, Val Loss: 0.0424, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3958], Train Loss: 0.0530, Val Loss: 0.0354, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3959], Train Loss: 0.0631, Val Loss: 0.0351, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3960], Train Loss: 0.0574, Val Loss: 0.0504, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3961], Train Loss: 0.0528, Val Loss: 0.0433, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3962], Train Loss: 0.0529, Val Loss: 0.0374, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3963], Train Loss: 0.0555, Val Loss: 0.0366, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3964], Train Loss: 0.0563, Val Loss: 0.0357, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3965], Train Loss: 0.0530, Val Loss: 0.0484, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3966], Train Loss: 0.0650, Val Loss: 0.0395, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3967], Train Loss: 0.0590, Val Loss: 0.0375, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3968], Train Loss: 0.0545, Val Loss: 0.0343, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3969], Train Loss: 0.0522, Val Loss: 0.0389, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3970], Train Loss: 0.0540, Val Loss: 0.0388, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3971], Train Loss: 0.0526, Val Loss: 0.0392, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3972], Train Loss: 0.0563, Val Loss: 0.0402, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3973], Train Loss: 0.0543, Val Loss: 0.0263, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3974], Train Loss: 0.0580, Val Loss: 0.0510, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3975], Train Loss: 0.0578, Val Loss: 0.0299, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3976], Train Loss: 0.0613, Val Loss: 0.0406, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3977], Train Loss: 0.0610, Val Loss: 0.0354, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3978], Train Loss: 0.0573, Val Loss: 0.0381, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3979], Train Loss: 0.0546, Val Loss: 0.0379, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3980], Train Loss: 0.0571, Val Loss: 0.0316, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3981], Train Loss: 0.0504, Val Loss: 0.0349, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3982], Train Loss: 0.0589, Val Loss: 0.0388, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3983], Train Loss: 0.0588, Val Loss: 0.0414, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3984], Train Loss: 0.0556, Val Loss: 0.0411, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3985], Train Loss: 0.0537, Val Loss: 0.0477, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3986], Train Loss: 0.0535, Val Loss: 0.0344, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3987], Train Loss: 0.0539, Val Loss: 0.0348, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3988], Train Loss: 0.0614, Val Loss: 0.0400, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3989], Train Loss: 0.0519, Val Loss: 0.0324, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3990], Train Loss: 0.0605, Val Loss: 0.0343, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3991], Train Loss: 0.0491, Val Loss: 0.0434, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3992], Train Loss: 0.0556, Val Loss: 0.0334, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3993], Train Loss: 0.0601, Val Loss: 0.0284, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3994], Train Loss: 0.0562, Val Loss: 0.0429, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3995], Train Loss: 0.0564, Val Loss: 0.0293, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3996], Train Loss: 0.0533, Val Loss: 0.0365, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3997], Train Loss: 0.0605, Val Loss: 0.0428, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3998], Train Loss: 0.0547, Val Loss: 0.0422, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [3999], Train Loss: 0.0551, Val Loss: 0.0372, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4000], Train Loss: 0.0546, Val Loss: 0.0363, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4001], Train Loss: 0.0526, Val Loss: 0.0333, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4002], Train Loss: 0.0495, Val Loss: 0.0421, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4003], Train Loss: 0.0592, Val Loss: 0.0411, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4004], Train Loss: 0.0574, Val Loss: 0.0383, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4005], Train Loss: 0.0594, Val Loss: 0.0395, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4006], Train Loss: 0.0533, Val Loss: 0.0326, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4007], Train Loss: 0.0582, Val Loss: 0.0468, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4008], Train Loss: 0.0636, Val Loss: 0.0422, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4009], Train Loss: 0.0618, Val Loss: 0.0259, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4010], Train Loss: 0.0549, Val Loss: 0.0403, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4011], Train Loss: 0.0600, Val Loss: 0.0304, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4012], Train Loss: 0.0551, Val Loss: 0.0343, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4013], Train Loss: 0.0533, Val Loss: 0.0333, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4014], Train Loss: 0.0549, Val Loss: 0.0367, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4015], Train Loss: 0.0575, Val Loss: 0.0309, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4016], Train Loss: 0.0601, Val Loss: 0.0344, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4017], Train Loss: 0.0541, Val Loss: 0.0346, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4018], Train Loss: 0.0598, Val Loss: 0.0509, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4019], Train Loss: 0.0609, Val Loss: 0.0313, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4020], Train Loss: 0.0559, Val Loss: 0.0320, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4021], Train Loss: 0.0528, Val Loss: 0.0421, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4022], Train Loss: 0.0587, Val Loss: 0.0330, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4023], Train Loss: 0.0530, Val Loss: 0.0346, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4024], Train Loss: 0.0578, Val Loss: 0.0522, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4025], Train Loss: 0.0565, Val Loss: 0.0337, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4026], Train Loss: 0.0635, Val Loss: 0.0335, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4027], Train Loss: 0.0539, Val Loss: 0.0363, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4028], Train Loss: 0.0633, Val Loss: 0.0371, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4029], Train Loss: 0.0526, Val Loss: 0.0345, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4030], Train Loss: 0.0558, Val Loss: 0.0279, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4031], Train Loss: 0.0587, Val Loss: 0.0373, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4032], Train Loss: 0.0606, Val Loss: 0.0392, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4033], Train Loss: 0.0534, Val Loss: 0.0342, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4034], Train Loss: 0.0560, Val Loss: 0.0372, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4035], Train Loss: 0.0575, Val Loss: 0.0479, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4036], Train Loss: 0.0553, Val Loss: 0.0311, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4037], Train Loss: 0.0573, Val Loss: 0.0426, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4038], Train Loss: 0.0621, Val Loss: 0.0338, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4039], Train Loss: 0.0546, Val Loss: 0.0285, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4040], Train Loss: 0.0580, Val Loss: 0.0408, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4041], Train Loss: 0.0533, Val Loss: 0.0286, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4042], Train Loss: 0.0576, Val Loss: 0.0289, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4043], Train Loss: 0.0579, Val Loss: 0.0530, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4044], Train Loss: 0.0526, Val Loss: 0.0319, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4045], Train Loss: 0.0601, Val Loss: 0.0432, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4046], Train Loss: 0.0608, Val Loss: 0.0371, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4047], Train Loss: 0.0528, Val Loss: 0.0427, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4048], Train Loss: 0.0552, Val Loss: 0.0301, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4049], Train Loss: 0.0525, Val Loss: 0.0436, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4050], Train Loss: 0.0532, Val Loss: 0.0387, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4051], Train Loss: 0.0618, Val Loss: 0.0363, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4052], Train Loss: 0.0598, Val Loss: 0.0324, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4053], Train Loss: 0.0547, Val Loss: 0.0371, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4054], Train Loss: 0.0512, Val Loss: 0.0328, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4055], Train Loss: 0.0612, Val Loss: 0.0341, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4056], Train Loss: 0.0508, Val Loss: 0.0468, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4057], Train Loss: 0.0571, Val Loss: 0.0385, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4058], Train Loss: 0.0592, Val Loss: 0.0269, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4059], Train Loss: 0.0491, Val Loss: 0.0369, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4060], Train Loss: 0.0626, Val Loss: 0.0425, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4061], Train Loss: 0.0536, Val Loss: 0.0305, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4062], Train Loss: 0.0516, Val Loss: 0.0379, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4063], Train Loss: 0.0583, Val Loss: 0.0412, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4064], Train Loss: 0.0542, Val Loss: 0.0353, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4065], Train Loss: 0.0577, Val Loss: 0.0295, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4066], Train Loss: 0.0556, Val Loss: 0.0327, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4067], Train Loss: 0.0534, Val Loss: 0.0403, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4068], Train Loss: 0.0540, Val Loss: 0.0345, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4069], Train Loss: 0.0645, Val Loss: 0.0253, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4070], Train Loss: 0.0509, Val Loss: 0.0311, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4071], Train Loss: 0.0550, Val Loss: 0.0315, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4072], Train Loss: 0.0613, Val Loss: 0.0277, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4073], Train Loss: 0.0502, Val Loss: 0.0356, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4074], Train Loss: 0.0540, Val Loss: 0.0288, LR: 0.000008, best val loss was: 0.0237
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4075], Train Loss: 0.0514, Val Loss: 0.0234, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4076], Train Loss: 0.0564, Val Loss: 0.0245, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4077], Train Loss: 0.0589, Val Loss: 0.0339, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4078], Train Loss: 0.0545, Val Loss: 0.0302, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4079], Train Loss: 0.0566, Val Loss: 0.0242, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4080], Train Loss: 0.0518, Val Loss: 0.0283, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4081], Train Loss: 0.0584, Val Loss: 0.0335, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4082], Train Loss: 0.0534, Val Loss: 0.0311, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4083], Train Loss: 0.0512, Val Loss: 0.0340, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4084], Train Loss: 0.0660, Val Loss: 0.0331, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4085], Train Loss: 0.0542, Val Loss: 0.0394, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4086], Train Loss: 0.0493, Val Loss: 0.0365, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4087], Train Loss: 0.0556, Val Loss: 0.0355, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4088], Train Loss: 0.0527, Val Loss: 0.0352, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4089], Train Loss: 0.0562, Val Loss: 0.0328, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4090], Train Loss: 0.0559, Val Loss: 0.0296, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4091], Train Loss: 0.0462, Val Loss: 0.0373, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4092], Train Loss: 0.0456, Val Loss: 0.0424, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4093], Train Loss: 0.0590, Val Loss: 0.0351, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4094], Train Loss: 0.0573, Val Loss: 0.0247, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4095], Train Loss: 0.0560, Val Loss: 0.0373, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4096], Train Loss: 0.0539, Val Loss: 0.0359, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4097], Train Loss: 0.0612, Val Loss: 0.0259, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4098], Train Loss: 0.0602, Val Loss: 0.0314, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4099], Train Loss: 0.0560, Val Loss: 0.0365, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4100], Train Loss: 0.0615, Val Loss: 0.0373, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4101], Train Loss: 0.0538, Val Loss: 0.0348, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4102], Train Loss: 0.0583, Val Loss: 0.0444, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4103], Train Loss: 0.0528, Val Loss: 0.0320, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4104], Train Loss: 0.0533, Val Loss: 0.0330, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4105], Train Loss: 0.0442, Val Loss: 0.0402, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4106], Train Loss: 0.0632, Val Loss: 0.0354, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4107], Train Loss: 0.0541, Val Loss: 0.0413, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4108], Train Loss: 0.0611, Val Loss: 0.0282, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4109], Train Loss: 0.0510, Val Loss: 0.0370, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4110], Train Loss: 0.0587, Val Loss: 0.0387, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4111], Train Loss: 0.0563, Val Loss: 0.0261, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4112], Train Loss: 0.0489, Val Loss: 0.0324, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4113], Train Loss: 0.0514, Val Loss: 0.0346, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4114], Train Loss: 0.0619, Val Loss: 0.0317, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4115], Train Loss: 0.0547, Val Loss: 0.0388, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4116], Train Loss: 0.0539, Val Loss: 0.0320, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4117], Train Loss: 0.0579, Val Loss: 0.0365, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4118], Train Loss: 0.0558, Val Loss: 0.0317, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4119], Train Loss: 0.0625, Val Loss: 0.0275, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4120], Train Loss: 0.0531, Val Loss: 0.0286, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4121], Train Loss: 0.0564, Val Loss: 0.0370, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4122], Train Loss: 0.0610, Val Loss: 0.0310, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4123], Train Loss: 0.0632, Val Loss: 0.0339, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4124], Train Loss: 0.0560, Val Loss: 0.0305, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4125], Train Loss: 0.0668, Val Loss: 0.0347, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4126], Train Loss: 0.0491, Val Loss: 0.0347, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4127], Train Loss: 0.0481, Val Loss: 0.0295, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4128], Train Loss: 0.0527, Val Loss: 0.0364, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4129], Train Loss: 0.0556, Val Loss: 0.0365, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4130], Train Loss: 0.0491, Val Loss: 0.0370, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4131], Train Loss: 0.0573, Val Loss: 0.0312, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4132], Train Loss: 0.0522, Val Loss: 0.0370, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4133], Train Loss: 0.0594, Val Loss: 0.0312, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4134], Train Loss: 0.0582, Val Loss: 0.0331, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4135], Train Loss: 0.0580, Val Loss: 0.0340, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4136], Train Loss: 0.0570, Val Loss: 0.0276, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4137], Train Loss: 0.0565, Val Loss: 0.0363, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4138], Train Loss: 0.0586, Val Loss: 0.0318, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4139], Train Loss: 0.0578, Val Loss: 0.0312, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4140], Train Loss: 0.0553, Val Loss: 0.0454, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4141], Train Loss: 0.0524, Val Loss: 0.0320, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4142], Train Loss: 0.0594, Val Loss: 0.0269, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4143], Train Loss: 0.0572, Val Loss: 0.0425, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4144], Train Loss: 0.0464, Val Loss: 0.0348, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4145], Train Loss: 0.0621, Val Loss: 0.0339, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4146], Train Loss: 0.0551, Val Loss: 0.0463, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4147], Train Loss: 0.0577, Val Loss: 0.0333, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4148], Train Loss: 0.0550, Val Loss: 0.0293, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4149], Train Loss: 0.0549, Val Loss: 0.0370, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4150], Train Loss: 0.0499, Val Loss: 0.0416, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4151], Train Loss: 0.0524, Val Loss: 0.0355, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4152], Train Loss: 0.0555, Val Loss: 0.0292, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4153], Train Loss: 0.0493, Val Loss: 0.0470, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4154], Train Loss: 0.0593, Val Loss: 0.0325, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4155], Train Loss: 0.0567, Val Loss: 0.0337, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4156], Train Loss: 0.0548, Val Loss: 0.0393, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4157], Train Loss: 0.0529, Val Loss: 0.0278, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4158], Train Loss: 0.0504, Val Loss: 0.0363, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4159], Train Loss: 0.0588, Val Loss: 0.0397, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4160], Train Loss: 0.0515, Val Loss: 0.0340, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4161], Train Loss: 0.0553, Val Loss: 0.0438, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4162], Train Loss: 0.0510, Val Loss: 0.0351, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4163], Train Loss: 0.0544, Val Loss: 0.0350, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4164], Train Loss: 0.0597, Val Loss: 0.0344, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4165], Train Loss: 0.0561, Val Loss: 0.0380, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4166], Train Loss: 0.0591, Val Loss: 0.0371, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4167], Train Loss: 0.0536, Val Loss: 0.0272, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4168], Train Loss: 0.0566, Val Loss: 0.0360, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4169], Train Loss: 0.0507, Val Loss: 0.0373, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4170], Train Loss: 0.0558, Val Loss: 0.0363, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4171], Train Loss: 0.0584, Val Loss: 0.0307, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4172], Train Loss: 0.0563, Val Loss: 0.0247, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4173], Train Loss: 0.0567, Val Loss: 0.0436, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4174], Train Loss: 0.0557, Val Loss: 0.0328, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4175], Train Loss: 0.0545, Val Loss: 0.0310, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4176], Train Loss: 0.0543, Val Loss: 0.0329, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4177], Train Loss: 0.0562, Val Loss: 0.0440, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4178], Train Loss: 0.0544, Val Loss: 0.0325, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4179], Train Loss: 0.0542, Val Loss: 0.0343, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4180], Train Loss: 0.0565, Val Loss: 0.0385, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4181], Train Loss: 0.0604, Val Loss: 0.0493, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4182], Train Loss: 0.0566, Val Loss: 0.0312, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4183], Train Loss: 0.0596, Val Loss: 0.0466, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4184], Train Loss: 0.0559, Val Loss: 0.0392, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4185], Train Loss: 0.0527, Val Loss: 0.0361, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4186], Train Loss: 0.0527, Val Loss: 0.0353, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4187], Train Loss: 0.0543, Val Loss: 0.0336, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4188], Train Loss: 0.0569, Val Loss: 0.0415, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4189], Train Loss: 0.0496, Val Loss: 0.0392, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4190], Train Loss: 0.0592, Val Loss: 0.0364, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4191], Train Loss: 0.0589, Val Loss: 0.0415, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4192], Train Loss: 0.0655, Val Loss: 0.0348, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4193], Train Loss: 0.0508, Val Loss: 0.0308, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4194], Train Loss: 0.0582, Val Loss: 0.0372, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4195], Train Loss: 0.0529, Val Loss: 0.0311, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4196], Train Loss: 0.0533, Val Loss: 0.0472, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4197], Train Loss: 0.0553, Val Loss: 0.0383, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4198], Train Loss: 0.0510, Val Loss: 0.0329, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4199], Train Loss: 0.0602, Val Loss: 0.0394, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4200], Train Loss: 0.0521, Val Loss: 0.0382, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4201], Train Loss: 0.0520, Val Loss: 0.0354, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4202], Train Loss: 0.0542, Val Loss: 0.0322, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4203], Train Loss: 0.0565, Val Loss: 0.0515, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4204], Train Loss: 0.0524, Val Loss: 0.0324, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4205], Train Loss: 0.0510, Val Loss: 0.0394, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4206], Train Loss: 0.0596, Val Loss: 0.0451, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4207], Train Loss: 0.0555, Val Loss: 0.0389, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4208], Train Loss: 0.0571, Val Loss: 0.0334, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4209], Train Loss: 0.0572, Val Loss: 0.0358, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4210], Train Loss: 0.0540, Val Loss: 0.0467, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4211], Train Loss: 0.0571, Val Loss: 0.0320, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4212], Train Loss: 0.0636, Val Loss: 0.0341, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4213], Train Loss: 0.0506, Val Loss: 0.0404, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4214], Train Loss: 0.0584, Val Loss: 0.0360, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4215], Train Loss: 0.0626, Val Loss: 0.0274, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4216], Train Loss: 0.0534, Val Loss: 0.0321, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4217], Train Loss: 0.0569, Val Loss: 0.0337, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4218], Train Loss: 0.0582, Val Loss: 0.0316, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4219], Train Loss: 0.0582, Val Loss: 0.0315, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4220], Train Loss: 0.0598, Val Loss: 0.0254, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4221], Train Loss: 0.0610, Val Loss: 0.0373, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4222], Train Loss: 0.0530, Val Loss: 0.0369, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4223], Train Loss: 0.0483, Val Loss: 0.0316, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4224], Train Loss: 0.0501, Val Loss: 0.0324, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4225], Train Loss: 0.0535, Val Loss: 0.0406, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4226], Train Loss: 0.0515, Val Loss: 0.0295, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4227], Train Loss: 0.0582, Val Loss: 0.0256, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4228], Train Loss: 0.0578, Val Loss: 0.0396, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4229], Train Loss: 0.0576, Val Loss: 0.0330, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4230], Train Loss: 0.0543, Val Loss: 0.0262, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4231], Train Loss: 0.0472, Val Loss: 0.0316, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4232], Train Loss: 0.0560, Val Loss: 0.0383, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4233], Train Loss: 0.0588, Val Loss: 0.0276, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4234], Train Loss: 0.0555, Val Loss: 0.0340, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4235], Train Loss: 0.0560, Val Loss: 0.0296, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4236], Train Loss: 0.0524, Val Loss: 0.0373, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4237], Train Loss: 0.0542, Val Loss: 0.0314, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4238], Train Loss: 0.0522, Val Loss: 0.0260, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4239], Train Loss: 0.0471, Val Loss: 0.0374, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4240], Train Loss: 0.0513, Val Loss: 0.0361, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4241], Train Loss: 0.0518, Val Loss: 0.0367, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4242], Train Loss: 0.0563, Val Loss: 0.0275, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4243], Train Loss: 0.0488, Val Loss: 0.0365, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4244], Train Loss: 0.0548, Val Loss: 0.0329, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4245], Train Loss: 0.0535, Val Loss: 0.0410, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4246], Train Loss: 0.0603, Val Loss: 0.0358, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4247], Train Loss: 0.0584, Val Loss: 0.0317, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4248], Train Loss: 0.0564, Val Loss: 0.0343, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4249], Train Loss: 0.0611, Val Loss: 0.0384, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4250], Train Loss: 0.0536, Val Loss: 0.0365, LR: 0.000008, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4251], Train Loss: 0.0554, Val Loss: 0.0394, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4252], Train Loss: 0.0588, Val Loss: 0.0332, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4253], Train Loss: 0.0636, Val Loss: 0.0288, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4254], Train Loss: 0.0499, Val Loss: 0.0365, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4255], Train Loss: 0.0536, Val Loss: 0.0351, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4256], Train Loss: 0.0560, Val Loss: 0.0356, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4257], Train Loss: 0.0565, Val Loss: 0.0405, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4258], Train Loss: 0.0576, Val Loss: 0.0302, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4259], Train Loss: 0.0525, Val Loss: 0.0298, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4260], Train Loss: 0.0599, Val Loss: 0.0293, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4261], Train Loss: 0.0561, Val Loss: 0.0315, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4262], Train Loss: 0.0531, Val Loss: 0.0361, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4263], Train Loss: 0.0535, Val Loss: 0.0420, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4264], Train Loss: 0.0518, Val Loss: 0.0339, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4265], Train Loss: 0.0574, Val Loss: 0.0260, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4266], Train Loss: 0.0644, Val Loss: 0.0374, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4267], Train Loss: 0.0547, Val Loss: 0.0320, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4268], Train Loss: 0.0510, Val Loss: 0.0270, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4269], Train Loss: 0.0515, Val Loss: 0.0380, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4270], Train Loss: 0.0516, Val Loss: 0.0350, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4271], Train Loss: 0.0517, Val Loss: 0.0274, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4272], Train Loss: 0.0512, Val Loss: 0.0339, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4273], Train Loss: 0.0546, Val Loss: 0.0364, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4274], Train Loss: 0.0552, Val Loss: 0.0348, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4275], Train Loss: 0.0511, Val Loss: 0.0317, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4276], Train Loss: 0.0555, Val Loss: 0.0294, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4277], Train Loss: 0.0593, Val Loss: 0.0379, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4278], Train Loss: 0.0501, Val Loss: 0.0387, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4279], Train Loss: 0.0590, Val Loss: 0.0350, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4280], Train Loss: 0.0567, Val Loss: 0.0399, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4281], Train Loss: 0.0548, Val Loss: 0.0412, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4282], Train Loss: 0.0575, Val Loss: 0.0324, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4283], Train Loss: 0.0511, Val Loss: 0.0402, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4284], Train Loss: 0.0561, Val Loss: 0.0427, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4285], Train Loss: 0.0576, Val Loss: 0.0424, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4286], Train Loss: 0.0548, Val Loss: 0.0296, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4287], Train Loss: 0.0512, Val Loss: 0.0309, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4288], Train Loss: 0.0500, Val Loss: 0.0302, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4289], Train Loss: 0.0458, Val Loss: 0.0423, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4290], Train Loss: 0.0523, Val Loss: 0.0349, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4291], Train Loss: 0.0605, Val Loss: 0.0337, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4292], Train Loss: 0.0589, Val Loss: 0.0428, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4293], Train Loss: 0.0546, Val Loss: 0.0373, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4294], Train Loss: 0.0535, Val Loss: 0.0291, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4295], Train Loss: 0.0543, Val Loss: 0.0397, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4296], Train Loss: 0.0512, Val Loss: 0.0347, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4297], Train Loss: 0.0536, Val Loss: 0.0322, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4298], Train Loss: 0.0459, Val Loss: 0.0462, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4299], Train Loss: 0.0596, Val Loss: 0.0340, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4300], Train Loss: 0.0571, Val Loss: 0.0321, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4301], Train Loss: 0.0585, Val Loss: 0.0418, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4302], Train Loss: 0.0648, Val Loss: 0.0322, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4303], Train Loss: 0.0524, Val Loss: 0.0302, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4304], Train Loss: 0.0540, Val Loss: 0.0447, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4305], Train Loss: 0.0584, Val Loss: 0.0361, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4306], Train Loss: 0.0555, Val Loss: 0.0336, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4307], Train Loss: 0.0504, Val Loss: 0.0364, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4308], Train Loss: 0.0532, Val Loss: 0.0428, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4309], Train Loss: 0.0529, Val Loss: 0.0366, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4310], Train Loss: 0.0568, Val Loss: 0.0445, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4311], Train Loss: 0.0547, Val Loss: 0.0320, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4312], Train Loss: 0.0528, Val Loss: 0.0331, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4313], Train Loss: 0.0528, Val Loss: 0.0491, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4314], Train Loss: 0.0497, Val Loss: 0.0366, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4315], Train Loss: 0.0602, Val Loss: 0.0375, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4316], Train Loss: 0.0613, Val Loss: 0.0396, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4317], Train Loss: 0.0576, Val Loss: 0.0470, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4318], Train Loss: 0.0527, Val Loss: 0.0306, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4319], Train Loss: 0.0567, Val Loss: 0.0372, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4320], Train Loss: 0.0476, Val Loss: 0.0393, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4321], Train Loss: 0.0557, Val Loss: 0.0481, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4322], Train Loss: 0.0574, Val Loss: 0.0330, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4323], Train Loss: 0.0543, Val Loss: 0.0321, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4324], Train Loss: 0.0565, Val Loss: 0.0386, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4325], Train Loss: 0.0519, Val Loss: 0.0445, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4326], Train Loss: 0.0599, Val Loss: 0.0265, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4327], Train Loss: 0.0550, Val Loss: 0.0447, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4328], Train Loss: 0.0536, Val Loss: 0.0355, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4329], Train Loss: 0.0568, Val Loss: 0.0323, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4330], Train Loss: 0.0552, Val Loss: 0.0393, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4331], Train Loss: 0.0569, Val Loss: 0.0329, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4332], Train Loss: 0.0532, Val Loss: 0.0346, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4333], Train Loss: 0.0536, Val Loss: 0.0389, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4334], Train Loss: 0.0600, Val Loss: 0.0395, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4335], Train Loss: 0.0571, Val Loss: 0.0305, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4336], Train Loss: 0.0485, Val Loss: 0.0303, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4337], Train Loss: 0.0573, Val Loss: 0.0295, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4338], Train Loss: 0.0586, Val Loss: 0.0308, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4339], Train Loss: 0.0588, Val Loss: 0.0285, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4340], Train Loss: 0.0536, Val Loss: 0.0306, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4341], Train Loss: 0.0566, Val Loss: 0.0353, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4342], Train Loss: 0.0523, Val Loss: 0.0367, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4343], Train Loss: 0.0511, Val Loss: 0.0290, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4344], Train Loss: 0.0527, Val Loss: 0.0377, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4345], Train Loss: 0.0629, Val Loss: 0.0332, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4346], Train Loss: 0.0528, Val Loss: 0.0346, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4347], Train Loss: 0.0478, Val Loss: 0.0366, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4348], Train Loss: 0.0537, Val Loss: 0.0396, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4349], Train Loss: 0.0551, Val Loss: 0.0332, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4350], Train Loss: 0.0503, Val Loss: 0.0289, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4351], Train Loss: 0.0500, Val Loss: 0.0282, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4352], Train Loss: 0.0535, Val Loss: 0.0325, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4353], Train Loss: 0.0556, Val Loss: 0.0288, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4354], Train Loss: 0.0581, Val Loss: 0.0307, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4355], Train Loss: 0.0608, Val Loss: 0.0283, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4356], Train Loss: 0.0571, Val Loss: 0.0383, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4357], Train Loss: 0.0564, Val Loss: 0.0374, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4358], Train Loss: 0.0583, Val Loss: 0.0423, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4359], Train Loss: 0.0572, Val Loss: 0.0331, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4360], Train Loss: 0.0489, Val Loss: 0.0312, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4361], Train Loss: 0.0562, Val Loss: 0.0275, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4362], Train Loss: 0.0488, Val Loss: 0.0343, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4363], Train Loss: 0.0535, Val Loss: 0.0299, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4364], Train Loss: 0.0560, Val Loss: 0.0297, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4365], Train Loss: 0.0560, Val Loss: 0.0331, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4366], Train Loss: 0.0514, Val Loss: 0.0345, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4367], Train Loss: 0.0488, Val Loss: 0.0384, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4368], Train Loss: 0.0606, Val Loss: 0.0286, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4369], Train Loss: 0.0538, Val Loss: 0.0280, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4370], Train Loss: 0.0590, Val Loss: 0.0327, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4371], Train Loss: 0.0590, Val Loss: 0.0313, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4372], Train Loss: 0.0458, Val Loss: 0.0288, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4373], Train Loss: 0.0540, Val Loss: 0.0275, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4374], Train Loss: 0.0513, Val Loss: 0.0294, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4375], Train Loss: 0.0538, Val Loss: 0.0400, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4376], Train Loss: 0.0545, Val Loss: 0.0311, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4377], Train Loss: 0.0612, Val Loss: 0.0333, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4378], Train Loss: 0.0569, Val Loss: 0.0327, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4379], Train Loss: 0.0571, Val Loss: 0.0348, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4380], Train Loss: 0.0527, Val Loss: 0.0369, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4381], Train Loss: 0.0593, Val Loss: 0.0265, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4382], Train Loss: 0.0553, Val Loss: 0.0282, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4383], Train Loss: 0.0555, Val Loss: 0.0379, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4384], Train Loss: 0.0509, Val Loss: 0.0370, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4385], Train Loss: 0.0583, Val Loss: 0.0293, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4386], Train Loss: 0.0591, Val Loss: 0.0312, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4387], Train Loss: 0.0543, Val Loss: 0.0413, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4388], Train Loss: 0.0509, Val Loss: 0.0338, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4389], Train Loss: 0.0521, Val Loss: 0.0354, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4390], Train Loss: 0.0549, Val Loss: 0.0331, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4391], Train Loss: 0.0600, Val Loss: 0.0257, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4392], Train Loss: 0.0545, Val Loss: 0.0304, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4393], Train Loss: 0.0520, Val Loss: 0.0410, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4394], Train Loss: 0.0530, Val Loss: 0.0295, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4395], Train Loss: 0.0543, Val Loss: 0.0278, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4396], Train Loss: 0.0582, Val Loss: 0.0332, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4397], Train Loss: 0.0583, Val Loss: 0.0350, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4398], Train Loss: 0.0570, Val Loss: 0.0289, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4399], Train Loss: 0.0522, Val Loss: 0.0301, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4400], Train Loss: 0.0502, Val Loss: 0.0373, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4401], Train Loss: 0.0682, Val Loss: 0.0327, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4402], Train Loss: 0.0506, Val Loss: 0.0414, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4403], Train Loss: 0.0524, Val Loss: 0.0278, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4404], Train Loss: 0.0502, Val Loss: 0.0335, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4405], Train Loss: 0.0552, Val Loss: 0.0299, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4406], Train Loss: 0.0535, Val Loss: 0.0243, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4407], Train Loss: 0.0580, Val Loss: 0.0252, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4408], Train Loss: 0.0581, Val Loss: 0.0390, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4409], Train Loss: 0.0518, Val Loss: 0.0353, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4410], Train Loss: 0.0525, Val Loss: 0.0323, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4411], Train Loss: 0.0593, Val Loss: 0.0367, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4412], Train Loss: 0.0601, Val Loss: 0.0287, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4413], Train Loss: 0.0511, Val Loss: 0.0343, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4414], Train Loss: 0.0483, Val Loss: 0.0360, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4415], Train Loss: 0.0560, Val Loss: 0.0441, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4416], Train Loss: 0.0591, Val Loss: 0.0343, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4417], Train Loss: 0.0492, Val Loss: 0.0247, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4418], Train Loss: 0.0601, Val Loss: 0.0327, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4419], Train Loss: 0.0482, Val Loss: 0.0443, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4420], Train Loss: 0.0520, Val Loss: 0.0245, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4421], Train Loss: 0.0607, Val Loss: 0.0367, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4422], Train Loss: 0.0505, Val Loss: 0.0310, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4423], Train Loss: 0.0626, Val Loss: 0.0350, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4424], Train Loss: 0.0517, Val Loss: 0.0380, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4425], Train Loss: 0.0511, Val Loss: 0.0360, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4426], Train Loss: 0.0521, Val Loss: 0.0350, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4427], Train Loss: 0.0583, Val Loss: 0.0364, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4428], Train Loss: 0.0576, Val Loss: 0.0285, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4429], Train Loss: 0.0610, Val Loss: 0.0313, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4430], Train Loss: 0.0501, Val Loss: 0.0317, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4431], Train Loss: 0.0481, Val Loss: 0.0277, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4432], Train Loss: 0.0523, Val Loss: 0.0340, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4433], Train Loss: 0.0520, Val Loss: 0.0273, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4434], Train Loss: 0.0525, Val Loss: 0.0270, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4435], Train Loss: 0.0521, Val Loss: 0.0333, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4436], Train Loss: 0.0572, Val Loss: 0.0330, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4437], Train Loss: 0.0568, Val Loss: 0.0451, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4438], Train Loss: 0.0567, Val Loss: 0.0338, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4439], Train Loss: 0.0524, Val Loss: 0.0310, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4440], Train Loss: 0.0558, Val Loss: 0.0360, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4441], Train Loss: 0.0540, Val Loss: 0.0341, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4442], Train Loss: 0.0542, Val Loss: 0.0347, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4443], Train Loss: 0.0524, Val Loss: 0.0364, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4444], Train Loss: 0.0553, Val Loss: 0.0381, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4445], Train Loss: 0.0550, Val Loss: 0.0367, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4446], Train Loss: 0.0493, Val Loss: 0.0344, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4447], Train Loss: 0.0533, Val Loss: 0.0334, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4448], Train Loss: 0.0588, Val Loss: 0.0317, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4449], Train Loss: 0.0488, Val Loss: 0.0271, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4450], Train Loss: 0.0601, Val Loss: 0.0291, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4451], Train Loss: 0.0539, Val Loss: 0.0344, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4452], Train Loss: 0.0499, Val Loss: 0.0286, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4453], Train Loss: 0.0582, Val Loss: 0.0291, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4454], Train Loss: 0.0558, Val Loss: 0.0456, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4455], Train Loss: 0.0547, Val Loss: 0.0360, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4456], Train Loss: 0.0515, Val Loss: 0.0298, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4457], Train Loss: 0.0577, Val Loss: 0.0472, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4458], Train Loss: 0.0540, Val Loss: 0.0360, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4459], Train Loss: 0.0504, Val Loss: 0.0332, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4460], Train Loss: 0.0554, Val Loss: 0.0437, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4461], Train Loss: 0.0509, Val Loss: 0.0457, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4462], Train Loss: 0.0544, Val Loss: 0.0301, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4463], Train Loss: 0.0572, Val Loss: 0.0451, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4464], Train Loss: 0.0592, Val Loss: 0.0355, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4465], Train Loss: 0.0608, Val Loss: 0.0373, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4466], Train Loss: 0.0562, Val Loss: 0.0349, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4467], Train Loss: 0.0558, Val Loss: 0.0432, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4468], Train Loss: 0.0567, Val Loss: 0.0342, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4469], Train Loss: 0.0498, Val Loss: 0.0380, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4470], Train Loss: 0.0502, Val Loss: 0.0364, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4471], Train Loss: 0.0506, Val Loss: 0.0333, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4472], Train Loss: 0.0530, Val Loss: 0.0440, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4473], Train Loss: 0.0578, Val Loss: 0.0371, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4474], Train Loss: 0.0599, Val Loss: 0.0313, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4475], Train Loss: 0.0526, Val Loss: 0.0327, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4476], Train Loss: 0.0544, Val Loss: 0.0329, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4477], Train Loss: 0.0533, Val Loss: 0.0416, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4478], Train Loss: 0.0528, Val Loss: 0.0360, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4479], Train Loss: 0.0570, Val Loss: 0.0276, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4480], Train Loss: 0.0559, Val Loss: 0.0286, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4481], Train Loss: 0.0487, Val Loss: 0.0339, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4482], Train Loss: 0.0523, Val Loss: 0.0260, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4483], Train Loss: 0.0507, Val Loss: 0.0271, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4484], Train Loss: 0.0508, Val Loss: 0.0358, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4485], Train Loss: 0.0558, Val Loss: 0.0393, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4486], Train Loss: 0.0540, Val Loss: 0.0415, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4487], Train Loss: 0.0555, Val Loss: 0.0340, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4488], Train Loss: 0.0526, Val Loss: 0.0273, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4489], Train Loss: 0.0506, Val Loss: 0.0310, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4490], Train Loss: 0.0529, Val Loss: 0.0325, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4491], Train Loss: 0.0586, Val Loss: 0.0342, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4492], Train Loss: 0.0509, Val Loss: 0.0311, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4493], Train Loss: 0.0555, Val Loss: 0.0363, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4494], Train Loss: 0.0558, Val Loss: 0.0291, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4495], Train Loss: 0.0635, Val Loss: 0.0239, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4496], Train Loss: 0.0517, Val Loss: 0.0291, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4497], Train Loss: 0.0526, Val Loss: 0.0347, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4498], Train Loss: 0.0566, Val Loss: 0.0342, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4499], Train Loss: 0.0556, Val Loss: 0.0264, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4500], Train Loss: 0.0518, Val Loss: 0.0318, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4501], Train Loss: 0.0593, Val Loss: 0.0315, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4502], Train Loss: 0.0549, Val Loss: 0.0312, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4503], Train Loss: 0.0543, Val Loss: 0.0385, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4504], Train Loss: 0.0565, Val Loss: 0.0322, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4505], Train Loss: 0.0550, Val Loss: 0.0252, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4506], Train Loss: 0.0582, Val Loss: 0.0265, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4507], Train Loss: 0.0544, Val Loss: 0.0322, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4508], Train Loss: 0.0569, Val Loss: 0.0352, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4509], Train Loss: 0.0532, Val Loss: 0.0268, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4510], Train Loss: 0.0513, Val Loss: 0.0311, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4511], Train Loss: 0.0511, Val Loss: 0.0310, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4512], Train Loss: 0.0580, Val Loss: 0.0330, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4513], Train Loss: 0.0568, Val Loss: 0.0372, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4514], Train Loss: 0.0546, Val Loss: 0.0379, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4515], Train Loss: 0.0553, Val Loss: 0.0355, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4516], Train Loss: 0.0588, Val Loss: 0.0234, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4517], Train Loss: 0.0539, Val Loss: 0.0261, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4518], Train Loss: 0.0528, Val Loss: 0.0399, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4519], Train Loss: 0.0490, Val Loss: 0.0336, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4520], Train Loss: 0.0618, Val Loss: 0.0288, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4521], Train Loss: 0.0594, Val Loss: 0.0303, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4522], Train Loss: 0.0557, Val Loss: 0.0314, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4523], Train Loss: 0.0538, Val Loss: 0.0377, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4524], Train Loss: 0.0554, Val Loss: 0.0356, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4525], Train Loss: 0.0528, Val Loss: 0.0294, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4526], Train Loss: 0.0598, Val Loss: 0.0275, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4527], Train Loss: 0.0532, Val Loss: 0.0268, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4528], Train Loss: 0.0602, Val Loss: 0.0346, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4529], Train Loss: 0.0523, Val Loss: 0.0344, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4530], Train Loss: 0.0524, Val Loss: 0.0303, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4531], Train Loss: 0.0538, Val Loss: 0.0267, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4532], Train Loss: 0.0525, Val Loss: 0.0271, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4533], Train Loss: 0.0517, Val Loss: 0.0265, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4534], Train Loss: 0.0463, Val Loss: 0.0241, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4535], Train Loss: 0.0535, Val Loss: 0.0321, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4536], Train Loss: 0.0548, Val Loss: 0.0456, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4537], Train Loss: 0.0598, Val Loss: 0.0304, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4538], Train Loss: 0.0540, Val Loss: 0.0370, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4539], Train Loss: 0.0561, Val Loss: 0.0360, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4540], Train Loss: 0.0468, Val Loss: 0.0369, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4541], Train Loss: 0.0514, Val Loss: 0.0279, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4542], Train Loss: 0.0505, Val Loss: 0.0269, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4543], Train Loss: 0.0552, Val Loss: 0.0339, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4544], Train Loss: 0.0490, Val Loss: 0.0345, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4545], Train Loss: 0.0546, Val Loss: 0.0313, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4546], Train Loss: 0.0558, Val Loss: 0.0374, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4547], Train Loss: 0.0559, Val Loss: 0.0351, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4548], Train Loss: 0.0573, Val Loss: 0.0261, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4549], Train Loss: 0.0497, Val Loss: 0.0260, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4550], Train Loss: 0.0512, Val Loss: 0.0286, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4551], Train Loss: 0.0538, Val Loss: 0.0297, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4552], Train Loss: 0.0566, Val Loss: 0.0252, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4553], Train Loss: 0.0513, Val Loss: 0.0329, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4554], Train Loss: 0.0483, Val Loss: 0.0388, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4555], Train Loss: 0.0510, Val Loss: 0.0329, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4556], Train Loss: 0.0587, Val Loss: 0.0265, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4557], Train Loss: 0.0539, Val Loss: 0.0263, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4558], Train Loss: 0.0566, Val Loss: 0.0344, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4559], Train Loss: 0.0583, Val Loss: 0.0347, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4560], Train Loss: 0.0565, Val Loss: 0.0313, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4561], Train Loss: 0.0509, Val Loss: 0.0433, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4562], Train Loss: 0.0591, Val Loss: 0.0322, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4563], Train Loss: 0.0508, Val Loss: 0.0284, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4564], Train Loss: 0.0517, Val Loss: 0.0378, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4565], Train Loss: 0.0523, Val Loss: 0.0327, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4566], Train Loss: 0.0529, Val Loss: 0.0350, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4567], Train Loss: 0.0578, Val Loss: 0.0381, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4568], Train Loss: 0.0514, Val Loss: 0.0312, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4569], Train Loss: 0.0538, Val Loss: 0.0290, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4570], Train Loss: 0.0599, Val Loss: 0.0303, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4571], Train Loss: 0.0538, Val Loss: 0.0302, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4572], Train Loss: 0.0600, Val Loss: 0.0293, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4573], Train Loss: 0.0563, Val Loss: 0.0295, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4574], Train Loss: 0.0455, Val Loss: 0.0316, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4575], Train Loss: 0.0618, Val Loss: 0.0362, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4576], Train Loss: 0.0561, Val Loss: 0.0354, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4577], Train Loss: 0.0590, Val Loss: 0.0284, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4578], Train Loss: 0.0577, Val Loss: 0.0266, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4579], Train Loss: 0.0548, Val Loss: 0.0256, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4580], Train Loss: 0.0508, Val Loss: 0.0349, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4581], Train Loss: 0.0555, Val Loss: 0.0372, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4582], Train Loss: 0.0537, Val Loss: 0.0323, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4583], Train Loss: 0.0641, Val Loss: 0.0273, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4584], Train Loss: 0.0569, Val Loss: 0.0281, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4585], Train Loss: 0.0481, Val Loss: 0.0289, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4586], Train Loss: 0.0591, Val Loss: 0.0318, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4587], Train Loss: 0.0506, Val Loss: 0.0315, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4588], Train Loss: 0.0554, Val Loss: 0.0340, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4589], Train Loss: 0.0527, Val Loss: 0.0294, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4590], Train Loss: 0.0472, Val Loss: 0.0293, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4591], Train Loss: 0.0497, Val Loss: 0.0265, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4592], Train Loss: 0.0585, Val Loss: 0.0347, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4593], Train Loss: 0.0573, Val Loss: 0.0346, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4594], Train Loss: 0.0582, Val Loss: 0.0345, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4595], Train Loss: 0.0549, Val Loss: 0.0390, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4596], Train Loss: 0.0552, Val Loss: 0.0426, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4597], Train Loss: 0.0607, Val Loss: 0.0274, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4598], Train Loss: 0.0573, Val Loss: 0.0266, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4599], Train Loss: 0.0571, Val Loss: 0.0354, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4600], Train Loss: 0.0594, Val Loss: 0.0396, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4601], Train Loss: 0.0496, Val Loss: 0.0363, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4602], Train Loss: 0.0565, Val Loss: 0.0311, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4603], Train Loss: 0.0532, Val Loss: 0.0372, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4604], Train Loss: 0.0484, Val Loss: 0.0443, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4605], Train Loss: 0.0532, Val Loss: 0.0271, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4606], Train Loss: 0.0585, Val Loss: 0.0291, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4607], Train Loss: 0.0551, Val Loss: 0.0298, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4608], Train Loss: 0.0577, Val Loss: 0.0303, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4609], Train Loss: 0.0596, Val Loss: 0.0305, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4610], Train Loss: 0.0530, Val Loss: 0.0301, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4611], Train Loss: 0.0516, Val Loss: 0.0309, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4612], Train Loss: 0.0511, Val Loss: 0.0285, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4613], Train Loss: 0.0597, Val Loss: 0.0307, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4614], Train Loss: 0.0516, Val Loss: 0.0367, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4615], Train Loss: 0.0570, Val Loss: 0.0288, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4616], Train Loss: 0.0464, Val Loss: 0.0267, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4617], Train Loss: 0.0517, Val Loss: 0.0356, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4618], Train Loss: 0.0546, Val Loss: 0.0383, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4619], Train Loss: 0.0546, Val Loss: 0.0314, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4620], Train Loss: 0.0538, Val Loss: 0.0298, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4621], Train Loss: 0.0532, Val Loss: 0.0283, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4622], Train Loss: 0.0510, Val Loss: 0.0287, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4623], Train Loss: 0.0551, Val Loss: 0.0271, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4624], Train Loss: 0.0533, Val Loss: 0.0253, LR: 0.000009, best val loss was: 0.0234
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4625], Train Loss: 0.0518, Val Loss: 0.0231, LR: 0.000009, best val loss was: 0.0231
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4626], Train Loss: 0.0565, Val Loss: 0.0225, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4627], Train Loss: 0.0568, Val Loss: 0.0361, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4628], Train Loss: 0.0541, Val Loss: 0.0258, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4629], Train Loss: 0.0528, Val Loss: 0.0233, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4630], Train Loss: 0.0488, Val Loss: 0.0262, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4631], Train Loss: 0.0508, Val Loss: 0.0308, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4632], Train Loss: 0.0544, Val Loss: 0.0319, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4633], Train Loss: 0.0544, Val Loss: 0.0276, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4634], Train Loss: 0.0590, Val Loss: 0.0313, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4635], Train Loss: 0.0525, Val Loss: 0.0350, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4636], Train Loss: 0.0531, Val Loss: 0.0373, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4637], Train Loss: 0.0543, Val Loss: 0.0298, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4638], Train Loss: 0.0553, Val Loss: 0.0293, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4639], Train Loss: 0.0573, Val Loss: 0.0258, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4640], Train Loss: 0.0537, Val Loss: 0.0308, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4641], Train Loss: 0.0535, Val Loss: 0.0286, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4642], Train Loss: 0.0533, Val Loss: 0.0324, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4643], Train Loss: 0.0523, Val Loss: 0.0355, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4644], Train Loss: 0.0591, Val Loss: 0.0302, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4645], Train Loss: 0.0535, Val Loss: 0.0300, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4646], Train Loss: 0.0537, Val Loss: 0.0299, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4647], Train Loss: 0.0562, Val Loss: 0.0287, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4648], Train Loss: 0.0513, Val Loss: 0.0256, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4649], Train Loss: 0.0539, Val Loss: 0.0322, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4650], Train Loss: 0.0530, Val Loss: 0.0423, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4651], Train Loss: 0.0531, Val Loss: 0.0312, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4652], Train Loss: 0.0587, Val Loss: 0.0297, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4653], Train Loss: 0.0502, Val Loss: 0.0290, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4654], Train Loss: 0.0578, Val Loss: 0.0284, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4655], Train Loss: 0.0597, Val Loss: 0.0267, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4656], Train Loss: 0.0515, Val Loss: 0.0235, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4657], Train Loss: 0.0515, Val Loss: 0.0273, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4658], Train Loss: 0.0469, Val Loss: 0.0310, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4659], Train Loss: 0.0492, Val Loss: 0.0304, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4660], Train Loss: 0.0636, Val Loss: 0.0331, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4661], Train Loss: 0.0532, Val Loss: 0.0479, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4662], Train Loss: 0.0595, Val Loss: 0.0301, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4663], Train Loss: 0.0575, Val Loss: 0.0312, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4664], Train Loss: 0.0453, Val Loss: 0.0343, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4665], Train Loss: 0.0548, Val Loss: 0.0331, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4666], Train Loss: 0.0518, Val Loss: 0.0336, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4667], Train Loss: 0.0450, Val Loss: 0.0407, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4668], Train Loss: 0.0532, Val Loss: 0.0365, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4669], Train Loss: 0.0502, Val Loss: 0.0273, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4670], Train Loss: 0.0558, Val Loss: 0.0277, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4671], Train Loss: 0.0559, Val Loss: 0.0293, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4672], Train Loss: 0.0579, Val Loss: 0.0329, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4673], Train Loss: 0.0551, Val Loss: 0.0329, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4674], Train Loss: 0.0525, Val Loss: 0.0374, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4675], Train Loss: 0.0467, Val Loss: 0.0353, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4676], Train Loss: 0.0507, Val Loss: 0.0363, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4677], Train Loss: 0.0522, Val Loss: 0.0353, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4678], Train Loss: 0.0501, Val Loss: 0.0334, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4679], Train Loss: 0.0530, Val Loss: 0.0291, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4680], Train Loss: 0.0537, Val Loss: 0.0307, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4681], Train Loss: 0.0504, Val Loss: 0.0361, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4682], Train Loss: 0.0508, Val Loss: 0.0381, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4683], Train Loss: 0.0633, Val Loss: 0.0276, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4684], Train Loss: 0.0566, Val Loss: 0.0282, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4685], Train Loss: 0.0553, Val Loss: 0.0286, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4686], Train Loss: 0.0553, Val Loss: 0.0266, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4687], Train Loss: 0.0520, Val Loss: 0.0240, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4688], Train Loss: 0.0603, Val Loss: 0.0250, LR: 0.000009, best val loss was: 0.0225
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4689], Train Loss: 0.0570, Val Loss: 0.0223, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4690], Train Loss: 0.0534, Val Loss: 0.0310, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4691], Train Loss: 0.0537, Val Loss: 0.0390, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4692], Train Loss: 0.0528, Val Loss: 0.0309, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4693], Train Loss: 0.0586, Val Loss: 0.0257, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4694], Train Loss: 0.0580, Val Loss: 0.0362, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4695], Train Loss: 0.0546, Val Loss: 0.0308, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4696], Train Loss: 0.0539, Val Loss: 0.0277, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4697], Train Loss: 0.0568, Val Loss: 0.0327, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4698], Train Loss: 0.0534, Val Loss: 0.0364, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4699], Train Loss: 0.0550, Val Loss: 0.0285, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4700], Train Loss: 0.0567, Val Loss: 0.0282, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4701], Train Loss: 0.0556, Val Loss: 0.0301, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4702], Train Loss: 0.0532, Val Loss: 0.0392, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4703], Train Loss: 0.0525, Val Loss: 0.0416, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4704], Train Loss: 0.0517, Val Loss: 0.0337, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4705], Train Loss: 0.0515, Val Loss: 0.0301, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4706], Train Loss: 0.0545, Val Loss: 0.0343, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4707], Train Loss: 0.0512, Val Loss: 0.0323, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4708], Train Loss: 0.0648, Val Loss: 0.0343, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4709], Train Loss: 0.0519, Val Loss: 0.0250, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4710], Train Loss: 0.0538, Val Loss: 0.0249, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4711], Train Loss: 0.0495, Val Loss: 0.0259, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4712], Train Loss: 0.0518, Val Loss: 0.0325, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4713], Train Loss: 0.0495, Val Loss: 0.0374, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4714], Train Loss: 0.0523, Val Loss: 0.0307, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4715], Train Loss: 0.0513, Val Loss: 0.0347, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4716], Train Loss: 0.0560, Val Loss: 0.0296, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4717], Train Loss: 0.0486, Val Loss: 0.0262, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4718], Train Loss: 0.0486, Val Loss: 0.0287, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4719], Train Loss: 0.0531, Val Loss: 0.0313, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4720], Train Loss: 0.0558, Val Loss: 0.0327, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4721], Train Loss: 0.0476, Val Loss: 0.0336, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4722], Train Loss: 0.0527, Val Loss: 0.0343, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4723], Train Loss: 0.0550, Val Loss: 0.0377, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4724], Train Loss: 0.0625, Val Loss: 0.0266, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4725], Train Loss: 0.0490, Val Loss: 0.0272, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4726], Train Loss: 0.0545, Val Loss: 0.0281, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4727], Train Loss: 0.0500, Val Loss: 0.0275, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4728], Train Loss: 0.0572, Val Loss: 0.0236, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4729], Train Loss: 0.0546, Val Loss: 0.0343, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4730], Train Loss: 0.0543, Val Loss: 0.0429, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4731], Train Loss: 0.0576, Val Loss: 0.0256, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4732], Train Loss: 0.0578, Val Loss: 0.0284, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4733], Train Loss: 0.0524, Val Loss: 0.0325, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4734], Train Loss: 0.0544, Val Loss: 0.0258, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4735], Train Loss: 0.0572, Val Loss: 0.0302, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4736], Train Loss: 0.0518, Val Loss: 0.0330, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4737], Train Loss: 0.0503, Val Loss: 0.0363, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4738], Train Loss: 0.0546, Val Loss: 0.0370, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4739], Train Loss: 0.0550, Val Loss: 0.0283, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4740], Train Loss: 0.0572, Val Loss: 0.0291, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4741], Train Loss: 0.0561, Val Loss: 0.0297, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4742], Train Loss: 0.0561, Val Loss: 0.0296, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4743], Train Loss: 0.0435, Val Loss: 0.0336, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4744], Train Loss: 0.0533, Val Loss: 0.0332, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4745], Train Loss: 0.0525, Val Loss: 0.0308, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4746], Train Loss: 0.0507, Val Loss: 0.0344, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4747], Train Loss: 0.0488, Val Loss: 0.0380, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4748], Train Loss: 0.0463, Val Loss: 0.0312, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4749], Train Loss: 0.0543, Val Loss: 0.0283, LR: 0.000009, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4750], Train Loss: 0.0491, Val Loss: 0.0290, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4751], Train Loss: 0.0562, Val Loss: 0.0263, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4752], Train Loss: 0.0628, Val Loss: 0.0333, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4753], Train Loss: 0.0518, Val Loss: 0.0260, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4754], Train Loss: 0.0544, Val Loss: 0.0265, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4755], Train Loss: 0.0566, Val Loss: 0.0279, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4756], Train Loss: 0.0501, Val Loss: 0.0247, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4757], Train Loss: 0.0574, Val Loss: 0.0227, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4758], Train Loss: 0.0524, Val Loss: 0.0259, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4759], Train Loss: 0.0640, Val Loss: 0.0230, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4760], Train Loss: 0.0512, Val Loss: 0.0235, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4761], Train Loss: 0.0584, Val Loss: 0.0282, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4762], Train Loss: 0.0562, Val Loss: 0.0335, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4763], Train Loss: 0.0503, Val Loss: 0.0341, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4764], Train Loss: 0.0614, Val Loss: 0.0266, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4765], Train Loss: 0.0504, Val Loss: 0.0357, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4766], Train Loss: 0.0502, Val Loss: 0.0365, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4767], Train Loss: 0.0601, Val Loss: 0.0334, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4768], Train Loss: 0.0500, Val Loss: 0.0266, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4769], Train Loss: 0.0472, Val Loss: 0.0263, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4770], Train Loss: 0.0511, Val Loss: 0.0356, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4771], Train Loss: 0.0552, Val Loss: 0.0387, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4772], Train Loss: 0.0532, Val Loss: 0.0301, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4773], Train Loss: 0.0498, Val Loss: 0.0308, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4774], Train Loss: 0.0481, Val Loss: 0.0319, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4775], Train Loss: 0.0491, Val Loss: 0.0324, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4776], Train Loss: 0.0605, Val Loss: 0.0299, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4777], Train Loss: 0.0578, Val Loss: 0.0314, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4778], Train Loss: 0.0482, Val Loss: 0.0332, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4779], Train Loss: 0.0565, Val Loss: 0.0337, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4780], Train Loss: 0.0564, Val Loss: 0.0311, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4781], Train Loss: 0.0544, Val Loss: 0.0327, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4782], Train Loss: 0.0527, Val Loss: 0.0340, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4783], Train Loss: 0.0616, Val Loss: 0.0368, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4784], Train Loss: 0.0552, Val Loss: 0.0309, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4785], Train Loss: 0.0592, Val Loss: 0.0242, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4786], Train Loss: 0.0569, Val Loss: 0.0229, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4787], Train Loss: 0.0550, Val Loss: 0.0289, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4788], Train Loss: 0.0532, Val Loss: 0.0316, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4789], Train Loss: 0.0538, Val Loss: 0.0349, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4790], Train Loss: 0.0545, Val Loss: 0.0345, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4791], Train Loss: 0.0550, Val Loss: 0.0304, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4792], Train Loss: 0.0446, Val Loss: 0.0268, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4793], Train Loss: 0.0517, Val Loss: 0.0299, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4794], Train Loss: 0.0605, Val Loss: 0.0309, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4795], Train Loss: 0.0555, Val Loss: 0.0250, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4796], Train Loss: 0.0530, Val Loss: 0.0269, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4797], Train Loss: 0.0473, Val Loss: 0.0245, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4798], Train Loss: 0.0572, Val Loss: 0.0228, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4799], Train Loss: 0.0579, Val Loss: 0.0310, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4800], Train Loss: 0.0565, Val Loss: 0.0334, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4801], Train Loss: 0.0517, Val Loss: 0.0287, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4802], Train Loss: 0.0512, Val Loss: 0.0301, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4803], Train Loss: 0.0532, Val Loss: 0.0265, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4804], Train Loss: 0.0550, Val Loss: 0.0283, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4805], Train Loss: 0.0531, Val Loss: 0.0283, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4806], Train Loss: 0.0532, Val Loss: 0.0247, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4807], Train Loss: 0.0528, Val Loss: 0.0232, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4808], Train Loss: 0.0508, Val Loss: 0.0285, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4809], Train Loss: 0.0495, Val Loss: 0.0282, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4810], Train Loss: 0.0593, Val Loss: 0.0343, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4811], Train Loss: 0.0504, Val Loss: 0.0303, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4812], Train Loss: 0.0553, Val Loss: 0.0309, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4813], Train Loss: 0.0508, Val Loss: 0.0285, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4814], Train Loss: 0.0601, Val Loss: 0.0340, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4815], Train Loss: 0.0605, Val Loss: 0.0421, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4816], Train Loss: 0.0499, Val Loss: 0.0334, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4817], Train Loss: 0.0500, Val Loss: 0.0297, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4818], Train Loss: 0.0578, Val Loss: 0.0326, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4819], Train Loss: 0.0512, Val Loss: 0.0312, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4820], Train Loss: 0.0497, Val Loss: 0.0310, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4821], Train Loss: 0.0472, Val Loss: 0.0331, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4822], Train Loss: 0.0537, Val Loss: 0.0363, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4823], Train Loss: 0.0534, Val Loss: 0.0343, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4824], Train Loss: 0.0508, Val Loss: 0.0327, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4825], Train Loss: 0.0558, Val Loss: 0.0247, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4826], Train Loss: 0.0574, Val Loss: 0.0278, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4827], Train Loss: 0.0598, Val Loss: 0.0315, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4828], Train Loss: 0.0505, Val Loss: 0.0328, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4829], Train Loss: 0.0499, Val Loss: 0.0351, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4830], Train Loss: 0.0536, Val Loss: 0.0358, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4831], Train Loss: 0.0506, Val Loss: 0.0323, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4832], Train Loss: 0.0495, Val Loss: 0.0349, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4833], Train Loss: 0.0603, Val Loss: 0.0307, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4834], Train Loss: 0.0605, Val Loss: 0.0263, LR: 0.000010, best val loss was: 0.0223
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4835], Train Loss: 0.0525, Val Loss: 0.0216, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4836], Train Loss: 0.0562, Val Loss: 0.0241, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4837], Train Loss: 0.0604, Val Loss: 0.0315, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4838], Train Loss: 0.0580, Val Loss: 0.0350, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4839], Train Loss: 0.0569, Val Loss: 0.0332, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4840], Train Loss: 0.0623, Val Loss: 0.0311, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4841], Train Loss: 0.0523, Val Loss: 0.0281, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4842], Train Loss: 0.0531, Val Loss: 0.0273, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4843], Train Loss: 0.0541, Val Loss: 0.0269, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4844], Train Loss: 0.0527, Val Loss: 0.0294, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4845], Train Loss: 0.0487, Val Loss: 0.0319, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4846], Train Loss: 0.0505, Val Loss: 0.0298, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4847], Train Loss: 0.0598, Val Loss: 0.0259, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4848], Train Loss: 0.0491, Val Loss: 0.0299, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4849], Train Loss: 0.0525, Val Loss: 0.0274, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4850], Train Loss: 0.0575, Val Loss: 0.0276, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4851], Train Loss: 0.0474, Val Loss: 0.0272, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4852], Train Loss: 0.0587, Val Loss: 0.0295, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4853], Train Loss: 0.0503, Val Loss: 0.0312, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4854], Train Loss: 0.0509, Val Loss: 0.0293, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4855], Train Loss: 0.0513, Val Loss: 0.0359, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4856], Train Loss: 0.0581, Val Loss: 0.0311, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4857], Train Loss: 0.0554, Val Loss: 0.0277, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4858], Train Loss: 0.0609, Val Loss: 0.0249, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4859], Train Loss: 0.0502, Val Loss: 0.0267, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4860], Train Loss: 0.0500, Val Loss: 0.0289, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4861], Train Loss: 0.0558, Val Loss: 0.0315, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4862], Train Loss: 0.0532, Val Loss: 0.0336, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4863], Train Loss: 0.0555, Val Loss: 0.0334, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4864], Train Loss: 0.0550, Val Loss: 0.0302, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4865], Train Loss: 0.0598, Val Loss: 0.0258, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4866], Train Loss: 0.0510, Val Loss: 0.0253, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4867], Train Loss: 0.0481, Val Loss: 0.0267, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4868], Train Loss: 0.0489, Val Loss: 0.0355, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4869], Train Loss: 0.0519, Val Loss: 0.0362, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4870], Train Loss: 0.0449, Val Loss: 0.0310, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4871], Train Loss: 0.0541, Val Loss: 0.0307, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4872], Train Loss: 0.0531, Val Loss: 0.0263, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4873], Train Loss: 0.0552, Val Loss: 0.0262, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4874], Train Loss: 0.0529, Val Loss: 0.0303, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4875], Train Loss: 0.0556, Val Loss: 0.0347, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4876], Train Loss: 0.0569, Val Loss: 0.0347, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4877], Train Loss: 0.0603, Val Loss: 0.0298, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4878], Train Loss: 0.0581, Val Loss: 0.0300, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4879], Train Loss: 0.0471, Val Loss: 0.0370, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4880], Train Loss: 0.0552, Val Loss: 0.0334, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4881], Train Loss: 0.0527, Val Loss: 0.0441, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4882], Train Loss: 0.0565, Val Loss: 0.0254, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4883], Train Loss: 0.0561, Val Loss: 0.0297, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4884], Train Loss: 0.0568, Val Loss: 0.0319, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4885], Train Loss: 0.0575, Val Loss: 0.0288, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4886], Train Loss: 0.0490, Val Loss: 0.0259, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4887], Train Loss: 0.0581, Val Loss: 0.0276, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4888], Train Loss: 0.0554, Val Loss: 0.0349, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4889], Train Loss: 0.0497, Val Loss: 0.0345, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4890], Train Loss: 0.0607, Val Loss: 0.0332, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4891], Train Loss: 0.0533, Val Loss: 0.0341, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4892], Train Loss: 0.0549, Val Loss: 0.0281, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4893], Train Loss: 0.0561, Val Loss: 0.0273, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4894], Train Loss: 0.0550, Val Loss: 0.0281, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4895], Train Loss: 0.0535, Val Loss: 0.0310, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4896], Train Loss: 0.0545, Val Loss: 0.0351, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4897], Train Loss: 0.0569, Val Loss: 0.0336, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4898], Train Loss: 0.0562, Val Loss: 0.0310, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4899], Train Loss: 0.0518, Val Loss: 0.0324, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4900], Train Loss: 0.0561, Val Loss: 0.0265, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4901], Train Loss: 0.0546, Val Loss: 0.0281, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4902], Train Loss: 0.0549, Val Loss: 0.0309, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4903], Train Loss: 0.0507, Val Loss: 0.0336, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4904], Train Loss: 0.0567, Val Loss: 0.0337, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4905], Train Loss: 0.0482, Val Loss: 0.0355, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4906], Train Loss: 0.0490, Val Loss: 0.0327, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4907], Train Loss: 0.0554, Val Loss: 0.0351, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4908], Train Loss: 0.0545, Val Loss: 0.0314, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4909], Train Loss: 0.0574, Val Loss: 0.0260, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4910], Train Loss: 0.0501, Val Loss: 0.0304, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4911], Train Loss: 0.0552, Val Loss: 0.0301, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4912], Train Loss: 0.0531, Val Loss: 0.0270, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4913], Train Loss: 0.0559, Val Loss: 0.0286, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4914], Train Loss: 0.0507, Val Loss: 0.0307, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4915], Train Loss: 0.0559, Val Loss: 0.0288, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4916], Train Loss: 0.0558, Val Loss: 0.0341, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4917], Train Loss: 0.0566, Val Loss: 0.0389, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4918], Train Loss: 0.0521, Val Loss: 0.0388, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4919], Train Loss: 0.0548, Val Loss: 0.0391, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4920], Train Loss: 0.0469, Val Loss: 0.0342, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4921], Train Loss: 0.0489, Val Loss: 0.0316, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4922], Train Loss: 0.0547, Val Loss: 0.0349, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4923], Train Loss: 0.0536, Val Loss: 0.0343, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4924], Train Loss: 0.0542, Val Loss: 0.0359, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4925], Train Loss: 0.0539, Val Loss: 0.0340, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4926], Train Loss: 0.0514, Val Loss: 0.0315, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4927], Train Loss: 0.0507, Val Loss: 0.0331, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4928], Train Loss: 0.0543, Val Loss: 0.0301, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4929], Train Loss: 0.0464, Val Loss: 0.0241, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4930], Train Loss: 0.0561, Val Loss: 0.0280, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4931], Train Loss: 0.0537, Val Loss: 0.0277, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4932], Train Loss: 0.0479, Val Loss: 0.0262, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4933], Train Loss: 0.0545, Val Loss: 0.0261, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4934], Train Loss: 0.0560, Val Loss: 0.0270, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4935], Train Loss: 0.0600, Val Loss: 0.0333, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4936], Train Loss: 0.0514, Val Loss: 0.0423, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4937], Train Loss: 0.0522, Val Loss: 0.0357, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4938], Train Loss: 0.0555, Val Loss: 0.0322, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4939], Train Loss: 0.0556, Val Loss: 0.0329, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4940], Train Loss: 0.0606, Val Loss: 0.0285, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4941], Train Loss: 0.0486, Val Loss: 0.0285, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4942], Train Loss: 0.0542, Val Loss: 0.0278, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4943], Train Loss: 0.0554, Val Loss: 0.0284, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4944], Train Loss: 0.0512, Val Loss: 0.0340, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4945], Train Loss: 0.0537, Val Loss: 0.0324, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4946], Train Loss: 0.0503, Val Loss: 0.0312, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4947], Train Loss: 0.0524, Val Loss: 0.0271, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4948], Train Loss: 0.0510, Val Loss: 0.0276, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4949], Train Loss: 0.0599, Val Loss: 0.0295, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4950], Train Loss: 0.0505, Val Loss: 0.0316, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4951], Train Loss: 0.0581, Val Loss: 0.0382, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4952], Train Loss: 0.0548, Val Loss: 0.0339, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4953], Train Loss: 0.0640, Val Loss: 0.0305, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4954], Train Loss: 0.0535, Val Loss: 0.0278, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4955], Train Loss: 0.0490, Val Loss: 0.0274, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4956], Train Loss: 0.0548, Val Loss: 0.0271, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4957], Train Loss: 0.0499, Val Loss: 0.0265, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4958], Train Loss: 0.0536, Val Loss: 0.0256, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4959], Train Loss: 0.0510, Val Loss: 0.0304, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4960], Train Loss: 0.0493, Val Loss: 0.0317, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4961], Train Loss: 0.0563, Val Loss: 0.0392, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4962], Train Loss: 0.0539, Val Loss: 0.0279, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4963], Train Loss: 0.0543, Val Loss: 0.0275, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4964], Train Loss: 0.0579, Val Loss: 0.0306, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4965], Train Loss: 0.0486, Val Loss: 0.0260, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4966], Train Loss: 0.0528, Val Loss: 0.0336, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4967], Train Loss: 0.0541, Val Loss: 0.0293, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4968], Train Loss: 0.0593, Val Loss: 0.0273, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4969], Train Loss: 0.0606, Val Loss: 0.0299, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4970], Train Loss: 0.0495, Val Loss: 0.0226, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4971], Train Loss: 0.0590, Val Loss: 0.0315, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4972], Train Loss: 0.0469, Val Loss: 0.0349, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4973], Train Loss: 0.0529, Val Loss: 0.0292, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4974], Train Loss: 0.0479, Val Loss: 0.0241, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4975], Train Loss: 0.0632, Val Loss: 0.0258, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4976], Train Loss: 0.0521, Val Loss: 0.0268, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4977], Train Loss: 0.0510, Val Loss: 0.0324, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4978], Train Loss: 0.0498, Val Loss: 0.0313, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4979], Train Loss: 0.0545, Val Loss: 0.0302, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4980], Train Loss: 0.0597, Val Loss: 0.0308, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4981], Train Loss: 0.0540, Val Loss: 0.0292, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4982], Train Loss: 0.0529, Val Loss: 0.0274, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4983], Train Loss: 0.0556, Val Loss: 0.0316, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4984], Train Loss: 0.0503, Val Loss: 0.0244, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4985], Train Loss: 0.0564, Val Loss: 0.0241, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4986], Train Loss: 0.0586, Val Loss: 0.0323, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4987], Train Loss: 0.0531, Val Loss: 0.0329, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4988], Train Loss: 0.0538, Val Loss: 0.0301, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4989], Train Loss: 0.0492, Val Loss: 0.0296, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4990], Train Loss: 0.0606, Val Loss: 0.0302, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4991], Train Loss: 0.0493, Val Loss: 0.0275, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4992], Train Loss: 0.0512, Val Loss: 0.0259, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4993], Train Loss: 0.0490, Val Loss: 0.0250, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4994], Train Loss: 0.0576, Val Loss: 0.0249, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4995], Train Loss: 0.0571, Val Loss: 0.0268, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4996], Train Loss: 0.0516, Val Loss: 0.0255, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4997], Train Loss: 0.0524, Val Loss: 0.0256, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4998], Train Loss: 0.0504, Val Loss: 0.0279, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [4999], Train Loss: 0.0562, Val Loss: 0.0321, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5000], Train Loss: 0.0500, Val Loss: 0.0388, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5001], Train Loss: 0.0585, Val Loss: 0.0340, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5002], Train Loss: 0.0617, Val Loss: 0.0279, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5003], Train Loss: 0.0541, Val Loss: 0.0247, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5004], Train Loss: 0.0524, Val Loss: 0.0302, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5005], Train Loss: 0.0523, Val Loss: 0.0362, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5006], Train Loss: 0.0497, Val Loss: 0.0343, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5007], Train Loss: 0.0475, Val Loss: 0.0293, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5008], Train Loss: 0.0556, Val Loss: 0.0282, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5009], Train Loss: 0.0586, Val Loss: 0.0321, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5010], Train Loss: 0.0514, Val Loss: 0.0297, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5011], Train Loss: 0.0502, Val Loss: 0.0351, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5012], Train Loss: 0.0516, Val Loss: 0.0394, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5013], Train Loss: 0.0545, Val Loss: 0.0357, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5014], Train Loss: 0.0523, Val Loss: 0.0402, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5015], Train Loss: 0.0493, Val Loss: 0.0387, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5016], Train Loss: 0.0499, Val Loss: 0.0348, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5017], Train Loss: 0.0556, Val Loss: 0.0296, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5018], Train Loss: 0.0551, Val Loss: 0.0278, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5019], Train Loss: 0.0522, Val Loss: 0.0318, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5020], Train Loss: 0.0583, Val Loss: 0.0287, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5021], Train Loss: 0.0526, Val Loss: 0.0322, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5022], Train Loss: 0.0523, Val Loss: 0.0295, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5023], Train Loss: 0.0609, Val Loss: 0.0302, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5024], Train Loss: 0.0541, Val Loss: 0.0358, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5025], Train Loss: 0.0519, Val Loss: 0.0316, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5026], Train Loss: 0.0526, Val Loss: 0.0299, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5027], Train Loss: 0.0584, Val Loss: 0.0308, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5028], Train Loss: 0.0605, Val Loss: 0.0283, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5029], Train Loss: 0.0512, Val Loss: 0.0316, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5030], Train Loss: 0.0553, Val Loss: 0.0253, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5031], Train Loss: 0.0519, Val Loss: 0.0289, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5032], Train Loss: 0.0532, Val Loss: 0.0318, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5033], Train Loss: 0.0544, Val Loss: 0.0337, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5034], Train Loss: 0.0468, Val Loss: 0.0281, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5035], Train Loss: 0.0525, Val Loss: 0.0321, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5036], Train Loss: 0.0553, Val Loss: 0.0364, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5037], Train Loss: 0.0533, Val Loss: 0.0367, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5038], Train Loss: 0.0548, Val Loss: 0.0361, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5039], Train Loss: 0.0547, Val Loss: 0.0305, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5040], Train Loss: 0.0550, Val Loss: 0.0277, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5041], Train Loss: 0.0510, Val Loss: 0.0264, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5042], Train Loss: 0.0521, Val Loss: 0.0295, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5043], Train Loss: 0.0497, Val Loss: 0.0270, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5044], Train Loss: 0.0537, Val Loss: 0.0245, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5045], Train Loss: 0.0538, Val Loss: 0.0275, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5046], Train Loss: 0.0484, Val Loss: 0.0306, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5047], Train Loss: 0.0527, Val Loss: 0.0347, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5048], Train Loss: 0.0572, Val Loss: 0.0304, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5049], Train Loss: 0.0532, Val Loss: 0.0362, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5050], Train Loss: 0.0517, Val Loss: 0.0333, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5051], Train Loss: 0.0480, Val Loss: 0.0325, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5052], Train Loss: 0.0535, Val Loss: 0.0292, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5053], Train Loss: 0.0547, Val Loss: 0.0333, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5054], Train Loss: 0.0607, Val Loss: 0.0274, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5055], Train Loss: 0.0554, Val Loss: 0.0247, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5056], Train Loss: 0.0494, Val Loss: 0.0270, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5057], Train Loss: 0.0476, Val Loss: 0.0262, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5058], Train Loss: 0.0461, Val Loss: 0.0267, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5059], Train Loss: 0.0574, Val Loss: 0.0285, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5060], Train Loss: 0.0530, Val Loss: 0.0254, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5061], Train Loss: 0.0505, Val Loss: 0.0232, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5062], Train Loss: 0.0471, Val Loss: 0.0227, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5063], Train Loss: 0.0528, Val Loss: 0.0267, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5064], Train Loss: 0.0484, Val Loss: 0.0359, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5065], Train Loss: 0.0573, Val Loss: 0.0260, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5066], Train Loss: 0.0493, Val Loss: 0.0281, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5067], Train Loss: 0.0553, Val Loss: 0.0330, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5068], Train Loss: 0.0591, Val Loss: 0.0306, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5069], Train Loss: 0.0534, Val Loss: 0.0269, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5070], Train Loss: 0.0473, Val Loss: 0.0265, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5071], Train Loss: 0.0593, Val Loss: 0.0295, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5072], Train Loss: 0.0480, Val Loss: 0.0304, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5073], Train Loss: 0.0590, Val Loss: 0.0306, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5074], Train Loss: 0.0626, Val Loss: 0.0330, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5075], Train Loss: 0.0540, Val Loss: 0.0326, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5076], Train Loss: 0.0514, Val Loss: 0.0322, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5077], Train Loss: 0.0514, Val Loss: 0.0362, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5078], Train Loss: 0.0514, Val Loss: 0.0326, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5079], Train Loss: 0.0474, Val Loss: 0.0286, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5080], Train Loss: 0.0542, Val Loss: 0.0270, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5081], Train Loss: 0.0585, Val Loss: 0.0273, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5082], Train Loss: 0.0529, Val Loss: 0.0288, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5083], Train Loss: 0.0568, Val Loss: 0.0247, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5084], Train Loss: 0.0495, Val Loss: 0.0315, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5085], Train Loss: 0.0498, Val Loss: 0.0323, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5086], Train Loss: 0.0646, Val Loss: 0.0332, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5087], Train Loss: 0.0523, Val Loss: 0.0312, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5088], Train Loss: 0.0530, Val Loss: 0.0286, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5089], Train Loss: 0.0574, Val Loss: 0.0297, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5090], Train Loss: 0.0492, Val Loss: 0.0296, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5091], Train Loss: 0.0507, Val Loss: 0.0282, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5092], Train Loss: 0.0552, Val Loss: 0.0261, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5093], Train Loss: 0.0525, Val Loss: 0.0259, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5094], Train Loss: 0.0516, Val Loss: 0.0306, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5095], Train Loss: 0.0523, Val Loss: 0.0274, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5096], Train Loss: 0.0476, Val Loss: 0.0257, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5097], Train Loss: 0.0480, Val Loss: 0.0258, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5098], Train Loss: 0.0526, Val Loss: 0.0232, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5099], Train Loss: 0.0525, Val Loss: 0.0235, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5100], Train Loss: 0.0533, Val Loss: 0.0251, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5101], Train Loss: 0.0499, Val Loss: 0.0253, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5102], Train Loss: 0.0550, Val Loss: 0.0240, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5103], Train Loss: 0.0492, Val Loss: 0.0253, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5104], Train Loss: 0.0569, Val Loss: 0.0301, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5105], Train Loss: 0.0482, Val Loss: 0.0321, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5106], Train Loss: 0.0459, Val Loss: 0.0311, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5107], Train Loss: 0.0541, Val Loss: 0.0339, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5108], Train Loss: 0.0542, Val Loss: 0.0371, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5109], Train Loss: 0.0466, Val Loss: 0.0337, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5110], Train Loss: 0.0564, Val Loss: 0.0254, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5111], Train Loss: 0.0549, Val Loss: 0.0279, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5112], Train Loss: 0.0564, Val Loss: 0.0271, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5113], Train Loss: 0.0557, Val Loss: 0.0237, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5114], Train Loss: 0.0542, Val Loss: 0.0264, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5115], Train Loss: 0.0505, Val Loss: 0.0302, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5116], Train Loss: 0.0545, Val Loss: 0.0301, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5117], Train Loss: 0.0512, Val Loss: 0.0264, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5118], Train Loss: 0.0529, Val Loss: 0.0239, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5119], Train Loss: 0.0551, Val Loss: 0.0242, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5120], Train Loss: 0.0529, Val Loss: 0.0255, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5121], Train Loss: 0.0531, Val Loss: 0.0267, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5122], Train Loss: 0.0540, Val Loss: 0.0321, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5123], Train Loss: 0.0610, Val Loss: 0.0329, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5124], Train Loss: 0.0498, Val Loss: 0.0259, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5125], Train Loss: 0.0578, Val Loss: 0.0225, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5126], Train Loss: 0.0503, Val Loss: 0.0259, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5127], Train Loss: 0.0567, Val Loss: 0.0305, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5128], Train Loss: 0.0562, Val Loss: 0.0327, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5129], Train Loss: 0.0555, Val Loss: 0.0325, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5130], Train Loss: 0.0458, Val Loss: 0.0281, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5131], Train Loss: 0.0481, Val Loss: 0.0343, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5132], Train Loss: 0.0552, Val Loss: 0.0395, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5133], Train Loss: 0.0602, Val Loss: 0.0278, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5134], Train Loss: 0.0582, Val Loss: 0.0291, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5135], Train Loss: 0.0472, Val Loss: 0.0291, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5136], Train Loss: 0.0519, Val Loss: 0.0294, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5137], Train Loss: 0.0548, Val Loss: 0.0324, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5138], Train Loss: 0.0563, Val Loss: 0.0315, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5139], Train Loss: 0.0551, Val Loss: 0.0334, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5140], Train Loss: 0.0552, Val Loss: 0.0342, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5141], Train Loss: 0.0602, Val Loss: 0.0340, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5142], Train Loss: 0.0534, Val Loss: 0.0320, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5143], Train Loss: 0.0575, Val Loss: 0.0316, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5144], Train Loss: 0.0574, Val Loss: 0.0314, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5145], Train Loss: 0.0557, Val Loss: 0.0299, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5146], Train Loss: 0.0586, Val Loss: 0.0287, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5147], Train Loss: 0.0638, Val Loss: 0.0317, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5148], Train Loss: 0.0533, Val Loss: 0.0310, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5149], Train Loss: 0.0533, Val Loss: 0.0326, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5150], Train Loss: 0.0536, Val Loss: 0.0360, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5151], Train Loss: 0.0541, Val Loss: 0.0314, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5152], Train Loss: 0.0490, Val Loss: 0.0278, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5153], Train Loss: 0.0553, Val Loss: 0.0255, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5154], Train Loss: 0.0486, Val Loss: 0.0256, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5155], Train Loss: 0.0669, Val Loss: 0.0251, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5156], Train Loss: 0.0595, Val Loss: 0.0296, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5157], Train Loss: 0.0569, Val Loss: 0.0321, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5158], Train Loss: 0.0544, Val Loss: 0.0253, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5159], Train Loss: 0.0569, Val Loss: 0.0280, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5160], Train Loss: 0.0563, Val Loss: 0.0225, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5161], Train Loss: 0.0553, Val Loss: 0.0231, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5162], Train Loss: 0.0500, Val Loss: 0.0222, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5163], Train Loss: 0.0541, Val Loss: 0.0309, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5164], Train Loss: 0.0505, Val Loss: 0.0324, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5165], Train Loss: 0.0553, Val Loss: 0.0260, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5166], Train Loss: 0.0598, Val Loss: 0.0234, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5167], Train Loss: 0.0519, Val Loss: 0.0231, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5168], Train Loss: 0.0518, Val Loss: 0.0327, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5169], Train Loss: 0.0518, Val Loss: 0.0298, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5170], Train Loss: 0.0540, Val Loss: 0.0284, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5171], Train Loss: 0.0539, Val Loss: 0.0263, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5172], Train Loss: 0.0544, Val Loss: 0.0295, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5173], Train Loss: 0.0553, Val Loss: 0.0250, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5174], Train Loss: 0.0576, Val Loss: 0.0231, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5175], Train Loss: 0.0502, Val Loss: 0.0247, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5176], Train Loss: 0.0568, Val Loss: 0.0310, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5177], Train Loss: 0.0533, Val Loss: 0.0267, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5178], Train Loss: 0.0550, Val Loss: 0.0274, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5179], Train Loss: 0.0570, Val Loss: 0.0326, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5180], Train Loss: 0.0511, Val Loss: 0.0266, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5181], Train Loss: 0.0565, Val Loss: 0.0260, LR: 0.000010, best val loss was: 0.0216
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5182], Train Loss: 0.0589, Val Loss: 0.0196, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5183], Train Loss: 0.0527, Val Loss: 0.0225, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5184], Train Loss: 0.0554, Val Loss: 0.0238, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5185], Train Loss: 0.0524, Val Loss: 0.0259, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5186], Train Loss: 0.0567, Val Loss: 0.0267, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5187], Train Loss: 0.0528, Val Loss: 0.0261, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5188], Train Loss: 0.0510, Val Loss: 0.0277, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5189], Train Loss: 0.0587, Val Loss: 0.0269, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5190], Train Loss: 0.0556, Val Loss: 0.0268, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5191], Train Loss: 0.0561, Val Loss: 0.0278, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5192], Train Loss: 0.0566, Val Loss: 0.0341, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5193], Train Loss: 0.0506, Val Loss: 0.0302, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5194], Train Loss: 0.0544, Val Loss: 0.0302, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5195], Train Loss: 0.0526, Val Loss: 0.0268, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5196], Train Loss: 0.0586, Val Loss: 0.0248, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5197], Train Loss: 0.0557, Val Loss: 0.0257, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5198], Train Loss: 0.0504, Val Loss: 0.0236, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5199], Train Loss: 0.0604, Val Loss: 0.0276, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5200], Train Loss: 0.0547, Val Loss: 0.0270, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5201], Train Loss: 0.0613, Val Loss: 0.0253, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5202], Train Loss: 0.0567, Val Loss: 0.0240, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5203], Train Loss: 0.0510, Val Loss: 0.0276, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5204], Train Loss: 0.0557, Val Loss: 0.0302, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5205], Train Loss: 0.0579, Val Loss: 0.0276, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5206], Train Loss: 0.0483, Val Loss: 0.0294, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5207], Train Loss: 0.0495, Val Loss: 0.0310, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5208], Train Loss: 0.0544, Val Loss: 0.0316, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5209], Train Loss: 0.0594, Val Loss: 0.0303, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5210], Train Loss: 0.0575, Val Loss: 0.0309, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5211], Train Loss: 0.0462, Val Loss: 0.0269, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5212], Train Loss: 0.0562, Val Loss: 0.0262, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5213], Train Loss: 0.0532, Val Loss: 0.0350, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5214], Train Loss: 0.0545, Val Loss: 0.0342, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5215], Train Loss: 0.0556, Val Loss: 0.0365, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5216], Train Loss: 0.0589, Val Loss: 0.0318, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5217], Train Loss: 0.0484, Val Loss: 0.0285, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5218], Train Loss: 0.0500, Val Loss: 0.0295, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5219], Train Loss: 0.0569, Val Loss: 0.0307, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5220], Train Loss: 0.0519, Val Loss: 0.0263, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5221], Train Loss: 0.0518, Val Loss: 0.0255, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5222], Train Loss: 0.0525, Val Loss: 0.0239, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5223], Train Loss: 0.0554, Val Loss: 0.0294, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5224], Train Loss: 0.0571, Val Loss: 0.0257, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5225], Train Loss: 0.0575, Val Loss: 0.0257, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5226], Train Loss: 0.0557, Val Loss: 0.0309, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5227], Train Loss: 0.0507, Val Loss: 0.0251, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5228], Train Loss: 0.0573, Val Loss: 0.0228, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5229], Train Loss: 0.0498, Val Loss: 0.0228, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5230], Train Loss: 0.0520, Val Loss: 0.0248, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5231], Train Loss: 0.0584, Val Loss: 0.0270, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5232], Train Loss: 0.0591, Val Loss: 0.0242, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5233], Train Loss: 0.0586, Val Loss: 0.0269, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5234], Train Loss: 0.0497, Val Loss: 0.0260, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5235], Train Loss: 0.0553, Val Loss: 0.0231, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5236], Train Loss: 0.0476, Val Loss: 0.0254, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5237], Train Loss: 0.0510, Val Loss: 0.0280, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5238], Train Loss: 0.0516, Val Loss: 0.0305, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5239], Train Loss: 0.0621, Val Loss: 0.0268, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5240], Train Loss: 0.0513, Val Loss: 0.0265, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5241], Train Loss: 0.0544, Val Loss: 0.0248, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5242], Train Loss: 0.0602, Val Loss: 0.0255, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5243], Train Loss: 0.0531, Val Loss: 0.0258, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5244], Train Loss: 0.0535, Val Loss: 0.0220, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5245], Train Loss: 0.0482, Val Loss: 0.0216, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5246], Train Loss: 0.0532, Val Loss: 0.0258, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5247], Train Loss: 0.0572, Val Loss: 0.0233, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5248], Train Loss: 0.0527, Val Loss: 0.0252, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5249], Train Loss: 0.0544, Val Loss: 0.0289, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5250], Train Loss: 0.0569, Val Loss: 0.0254, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5251], Train Loss: 0.0483, Val Loss: 0.0249, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5252], Train Loss: 0.0543, Val Loss: 0.0253, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5253], Train Loss: 0.0556, Val Loss: 0.0271, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5254], Train Loss: 0.0529, Val Loss: 0.0226, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5255], Train Loss: 0.0567, Val Loss: 0.0244, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5256], Train Loss: 0.0538, Val Loss: 0.0241, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5257], Train Loss: 0.0550, Val Loss: 0.0245, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5258], Train Loss: 0.0520, Val Loss: 0.0221, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5259], Train Loss: 0.0506, Val Loss: 0.0279, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5260], Train Loss: 0.0567, Val Loss: 0.0278, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5261], Train Loss: 0.0569, Val Loss: 0.0263, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5262], Train Loss: 0.0568, Val Loss: 0.0265, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5263], Train Loss: 0.0522, Val Loss: 0.0266, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5264], Train Loss: 0.0541, Val Loss: 0.0291, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5265], Train Loss: 0.0473, Val Loss: 0.0315, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5266], Train Loss: 0.0503, Val Loss: 0.0298, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5267], Train Loss: 0.0505, Val Loss: 0.0340, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5268], Train Loss: 0.0482, Val Loss: 0.0271, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5269], Train Loss: 0.0529, Val Loss: 0.0281, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5270], Train Loss: 0.0501, Val Loss: 0.0301, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5271], Train Loss: 0.0561, Val Loss: 0.0251, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5272], Train Loss: 0.0503, Val Loss: 0.0287, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5273], Train Loss: 0.0598, Val Loss: 0.0264, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5274], Train Loss: 0.0555, Val Loss: 0.0277, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5275], Train Loss: 0.0510, Val Loss: 0.0315, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5276], Train Loss: 0.0457, Val Loss: 0.0370, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5277], Train Loss: 0.0476, Val Loss: 0.0399, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5278], Train Loss: 0.0535, Val Loss: 0.0331, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5279], Train Loss: 0.0522, Val Loss: 0.0289, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5280], Train Loss: 0.0536, Val Loss: 0.0274, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5281], Train Loss: 0.0547, Val Loss: 0.0290, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5282], Train Loss: 0.0557, Val Loss: 0.0289, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5283], Train Loss: 0.0574, Val Loss: 0.0285, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5284], Train Loss: 0.0519, Val Loss: 0.0255, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5285], Train Loss: 0.0483, Val Loss: 0.0283, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5286], Train Loss: 0.0548, Val Loss: 0.0263, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5287], Train Loss: 0.0560, Val Loss: 0.0327, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5288], Train Loss: 0.0491, Val Loss: 0.0290, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5289], Train Loss: 0.0565, Val Loss: 0.0318, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5290], Train Loss: 0.0590, Val Loss: 0.0297, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5291], Train Loss: 0.0506, Val Loss: 0.0335, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5292], Train Loss: 0.0517, Val Loss: 0.0344, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5293], Train Loss: 0.0607, Val Loss: 0.0334, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5294], Train Loss: 0.0536, Val Loss: 0.0318, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5295], Train Loss: 0.0623, Val Loss: 0.0253, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5296], Train Loss: 0.0520, Val Loss: 0.0254, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5297], Train Loss: 0.0524, Val Loss: 0.0253, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5298], Train Loss: 0.0521, Val Loss: 0.0272, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5299], Train Loss: 0.0565, Val Loss: 0.0245, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5300], Train Loss: 0.0533, Val Loss: 0.0262, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5301], Train Loss: 0.0581, Val Loss: 0.0238, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5302], Train Loss: 0.0577, Val Loss: 0.0250, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5303], Train Loss: 0.0577, Val Loss: 0.0292, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5304], Train Loss: 0.0568, Val Loss: 0.0220, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5305], Train Loss: 0.0542, Val Loss: 0.0213, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5306], Train Loss: 0.0482, Val Loss: 0.0226, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5307], Train Loss: 0.0487, Val Loss: 0.0291, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5308], Train Loss: 0.0520, Val Loss: 0.0272, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5309], Train Loss: 0.0552, Val Loss: 0.0256, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5310], Train Loss: 0.0557, Val Loss: 0.0272, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5311], Train Loss: 0.0516, Val Loss: 0.0291, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5312], Train Loss: 0.0522, Val Loss: 0.0277, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5313], Train Loss: 0.0571, Val Loss: 0.0254, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5314], Train Loss: 0.0518, Val Loss: 0.0239, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5315], Train Loss: 0.0524, Val Loss: 0.0261, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5316], Train Loss: 0.0458, Val Loss: 0.0274, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5317], Train Loss: 0.0527, Val Loss: 0.0301, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5318], Train Loss: 0.0544, Val Loss: 0.0273, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5319], Train Loss: 0.0549, Val Loss: 0.0323, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5320], Train Loss: 0.0487, Val Loss: 0.0311, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5321], Train Loss: 0.0555, Val Loss: 0.0313, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5322], Train Loss: 0.0527, Val Loss: 0.0282, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5323], Train Loss: 0.0550, Val Loss: 0.0277, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5324], Train Loss: 0.0499, Val Loss: 0.0289, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5325], Train Loss: 0.0515, Val Loss: 0.0255, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5326], Train Loss: 0.0544, Val Loss: 0.0260, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5327], Train Loss: 0.0523, Val Loss: 0.0267, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5328], Train Loss: 0.0553, Val Loss: 0.0294, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5329], Train Loss: 0.0514, Val Loss: 0.0307, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5330], Train Loss: 0.0563, Val Loss: 0.0255, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5331], Train Loss: 0.0511, Val Loss: 0.0265, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5332], Train Loss: 0.0602, Val Loss: 0.0241, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5333], Train Loss: 0.0572, Val Loss: 0.0241, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5334], Train Loss: 0.0572, Val Loss: 0.0232, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5335], Train Loss: 0.0494, Val Loss: 0.0234, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5336], Train Loss: 0.0593, Val Loss: 0.0239, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5337], Train Loss: 0.0543, Val Loss: 0.0239, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5338], Train Loss: 0.0500, Val Loss: 0.0263, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5339], Train Loss: 0.0579, Val Loss: 0.0272, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5340], Train Loss: 0.0571, Val Loss: 0.0230, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5341], Train Loss: 0.0586, Val Loss: 0.0284, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5342], Train Loss: 0.0481, Val Loss: 0.0255, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5343], Train Loss: 0.0516, Val Loss: 0.0249, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5344], Train Loss: 0.0523, Val Loss: 0.0242, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5345], Train Loss: 0.0524, Val Loss: 0.0224, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5346], Train Loss: 0.0524, Val Loss: 0.0260, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5347], Train Loss: 0.0560, Val Loss: 0.0277, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5348], Train Loss: 0.0510, Val Loss: 0.0296, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5349], Train Loss: 0.0520, Val Loss: 0.0300, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5350], Train Loss: 0.0506, Val Loss: 0.0283, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5351], Train Loss: 0.0481, Val Loss: 0.0327, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5352], Train Loss: 0.0573, Val Loss: 0.0271, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5353], Train Loss: 0.0535, Val Loss: 0.0306, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5354], Train Loss: 0.0524, Val Loss: 0.0298, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5355], Train Loss: 0.0523, Val Loss: 0.0250, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5356], Train Loss: 0.0564, Val Loss: 0.0269, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5357], Train Loss: 0.0558, Val Loss: 0.0247, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5358], Train Loss: 0.0489, Val Loss: 0.0227, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5359], Train Loss: 0.0564, Val Loss: 0.0224, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5360], Train Loss: 0.0549, Val Loss: 0.0266, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5361], Train Loss: 0.0567, Val Loss: 0.0312, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5362], Train Loss: 0.0512, Val Loss: 0.0264, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5363], Train Loss: 0.0542, Val Loss: 0.0240, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5364], Train Loss: 0.0558, Val Loss: 0.0259, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5365], Train Loss: 0.0509, Val Loss: 0.0317, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5366], Train Loss: 0.0550, Val Loss: 0.0347, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5367], Train Loss: 0.0494, Val Loss: 0.0288, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5368], Train Loss: 0.0528, Val Loss: 0.0262, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5369], Train Loss: 0.0480, Val Loss: 0.0260, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5370], Train Loss: 0.0534, Val Loss: 0.0260, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5371], Train Loss: 0.0550, Val Loss: 0.0298, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5372], Train Loss: 0.0604, Val Loss: 0.0284, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5373], Train Loss: 0.0512, Val Loss: 0.0228, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5374], Train Loss: 0.0536, Val Loss: 0.0243, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5375], Train Loss: 0.0618, Val Loss: 0.0225, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5376], Train Loss: 0.0507, Val Loss: 0.0242, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5377], Train Loss: 0.0525, Val Loss: 0.0241, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5378], Train Loss: 0.0511, Val Loss: 0.0266, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5379], Train Loss: 0.0540, Val Loss: 0.0285, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5380], Train Loss: 0.0510, Val Loss: 0.0260, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5381], Train Loss: 0.0496, Val Loss: 0.0281, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5382], Train Loss: 0.0514, Val Loss: 0.0266, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5383], Train Loss: 0.0595, Val Loss: 0.0222, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5384], Train Loss: 0.0520, Val Loss: 0.0243, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5385], Train Loss: 0.0553, Val Loss: 0.0263, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5386], Train Loss: 0.0554, Val Loss: 0.0280, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5387], Train Loss: 0.0467, Val Loss: 0.0255, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5388], Train Loss: 0.0538, Val Loss: 0.0278, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5389], Train Loss: 0.0555, Val Loss: 0.0313, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5390], Train Loss: 0.0566, Val Loss: 0.0344, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5391], Train Loss: 0.0475, Val Loss: 0.0298, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5392], Train Loss: 0.0594, Val Loss: 0.0298, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5393], Train Loss: 0.0498, Val Loss: 0.0261, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5394], Train Loss: 0.0520, Val Loss: 0.0256, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5395], Train Loss: 0.0526, Val Loss: 0.0273, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5396], Train Loss: 0.0541, Val Loss: 0.0266, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5397], Train Loss: 0.0536, Val Loss: 0.0256, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5398], Train Loss: 0.0573, Val Loss: 0.0231, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5399], Train Loss: 0.0557, Val Loss: 0.0261, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5400], Train Loss: 0.0585, Val Loss: 0.0281, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5401], Train Loss: 0.0488, Val Loss: 0.0284, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5402], Train Loss: 0.0461, Val Loss: 0.0241, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5403], Train Loss: 0.0555, Val Loss: 0.0252, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5404], Train Loss: 0.0420, Val Loss: 0.0255, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5405], Train Loss: 0.0603, Val Loss: 0.0199, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5406], Train Loss: 0.0545, Val Loss: 0.0208, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5407], Train Loss: 0.0495, Val Loss: 0.0209, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5408], Train Loss: 0.0557, Val Loss: 0.0224, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5409], Train Loss: 0.0507, Val Loss: 0.0227, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5410], Train Loss: 0.0496, Val Loss: 0.0255, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5411], Train Loss: 0.0500, Val Loss: 0.0263, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5412], Train Loss: 0.0530, Val Loss: 0.0233, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5413], Train Loss: 0.0548, Val Loss: 0.0242, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5414], Train Loss: 0.0484, Val Loss: 0.0258, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5415], Train Loss: 0.0579, Val Loss: 0.0273, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5416], Train Loss: 0.0492, Val Loss: 0.0270, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5417], Train Loss: 0.0554, Val Loss: 0.0302, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5418], Train Loss: 0.0480, Val Loss: 0.0289, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5419], Train Loss: 0.0461, Val Loss: 0.0303, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5420], Train Loss: 0.0470, Val Loss: 0.0283, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5421], Train Loss: 0.0571, Val Loss: 0.0261, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5422], Train Loss: 0.0519, Val Loss: 0.0241, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5423], Train Loss: 0.0499, Val Loss: 0.0224, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5424], Train Loss: 0.0484, Val Loss: 0.0236, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5425], Train Loss: 0.0485, Val Loss: 0.0264, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5426], Train Loss: 0.0525, Val Loss: 0.0269, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5427], Train Loss: 0.0599, Val Loss: 0.0278, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5428], Train Loss: 0.0502, Val Loss: 0.0255, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5429], Train Loss: 0.0477, Val Loss: 0.0251, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5430], Train Loss: 0.0513, Val Loss: 0.0264, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5431], Train Loss: 0.0522, Val Loss: 0.0224, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5432], Train Loss: 0.0531, Val Loss: 0.0260, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5433], Train Loss: 0.0568, Val Loss: 0.0246, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5434], Train Loss: 0.0488, Val Loss: 0.0284, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5435], Train Loss: 0.0475, Val Loss: 0.0263, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5436], Train Loss: 0.0457, Val Loss: 0.0234, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5437], Train Loss: 0.0542, Val Loss: 0.0240, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5438], Train Loss: 0.0565, Val Loss: 0.0238, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5439], Train Loss: 0.0584, Val Loss: 0.0311, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5440], Train Loss: 0.0519, Val Loss: 0.0281, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5441], Train Loss: 0.0516, Val Loss: 0.0264, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5442], Train Loss: 0.0554, Val Loss: 0.0254, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5443], Train Loss: 0.0493, Val Loss: 0.0275, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5444], Train Loss: 0.0595, Val Loss: 0.0275, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5445], Train Loss: 0.0562, Val Loss: 0.0278, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5446], Train Loss: 0.0622, Val Loss: 0.0296, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5447], Train Loss: 0.0496, Val Loss: 0.0287, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5448], Train Loss: 0.0476, Val Loss: 0.0277, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5449], Train Loss: 0.0525, Val Loss: 0.0273, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5450], Train Loss: 0.0487, Val Loss: 0.0289, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5451], Train Loss: 0.0487, Val Loss: 0.0258, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5452], Train Loss: 0.0503, Val Loss: 0.0271, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5453], Train Loss: 0.0525, Val Loss: 0.0297, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5454], Train Loss: 0.0458, Val Loss: 0.0266, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5455], Train Loss: 0.0457, Val Loss: 0.0289, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5456], Train Loss: 0.0494, Val Loss: 0.0253, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5457], Train Loss: 0.0528, Val Loss: 0.0270, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5458], Train Loss: 0.0516, Val Loss: 0.0299, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5459], Train Loss: 0.0505, Val Loss: 0.0279, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5460], Train Loss: 0.0589, Val Loss: 0.0259, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5461], Train Loss: 0.0559, Val Loss: 0.0245, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5462], Train Loss: 0.0496, Val Loss: 0.0266, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5463], Train Loss: 0.0503, Val Loss: 0.0300, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5464], Train Loss: 0.0582, Val Loss: 0.0299, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5465], Train Loss: 0.0556, Val Loss: 0.0263, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5466], Train Loss: 0.0541, Val Loss: 0.0270, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5467], Train Loss: 0.0445, Val Loss: 0.0323, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5468], Train Loss: 0.0570, Val Loss: 0.0328, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5469], Train Loss: 0.0614, Val Loss: 0.0264, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5470], Train Loss: 0.0584, Val Loss: 0.0237, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5471], Train Loss: 0.0562, Val Loss: 0.0223, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5472], Train Loss: 0.0494, Val Loss: 0.0235, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5473], Train Loss: 0.0467, Val Loss: 0.0242, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5474], Train Loss: 0.0552, Val Loss: 0.0223, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5475], Train Loss: 0.0509, Val Loss: 0.0248, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5476], Train Loss: 0.0576, Val Loss: 0.0266, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5477], Train Loss: 0.0489, Val Loss: 0.0266, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5478], Train Loss: 0.0554, Val Loss: 0.0264, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5479], Train Loss: 0.0512, Val Loss: 0.0270, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5480], Train Loss: 0.0472, Val Loss: 0.0244, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5481], Train Loss: 0.0521, Val Loss: 0.0276, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5482], Train Loss: 0.0575, Val Loss: 0.0262, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5483], Train Loss: 0.0512, Val Loss: 0.0264, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5484], Train Loss: 0.0547, Val Loss: 0.0293, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5485], Train Loss: 0.0511, Val Loss: 0.0301, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5486], Train Loss: 0.0526, Val Loss: 0.0302, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5487], Train Loss: 0.0482, Val Loss: 0.0253, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5488], Train Loss: 0.0523, Val Loss: 0.0248, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5489], Train Loss: 0.0556, Val Loss: 0.0245, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5490], Train Loss: 0.0490, Val Loss: 0.0237, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5491], Train Loss: 0.0557, Val Loss: 0.0303, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5492], Train Loss: 0.0502, Val Loss: 0.0254, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5493], Train Loss: 0.0512, Val Loss: 0.0260, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5494], Train Loss: 0.0616, Val Loss: 0.0290, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5495], Train Loss: 0.0491, Val Loss: 0.0309, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5496], Train Loss: 0.0510, Val Loss: 0.0293, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5497], Train Loss: 0.0490, Val Loss: 0.0265, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5498], Train Loss: 0.0539, Val Loss: 0.0271, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5499], Train Loss: 0.0556, Val Loss: 0.0267, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5500], Train Loss: 0.0527, Val Loss: 0.0232, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5501], Train Loss: 0.0520, Val Loss: 0.0256, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5502], Train Loss: 0.0576, Val Loss: 0.0276, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5503], Train Loss: 0.0496, Val Loss: 0.0286, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5504], Train Loss: 0.0523, Val Loss: 0.0279, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5505], Train Loss: 0.0528, Val Loss: 0.0253, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5506], Train Loss: 0.0500, Val Loss: 0.0254, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5507], Train Loss: 0.0513, Val Loss: 0.0216, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5508], Train Loss: 0.0489, Val Loss: 0.0202, LR: 0.000010, best val loss was: 0.0196
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5509], Train Loss: 0.0542, Val Loss: 0.0195, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5510], Train Loss: 0.0524, Val Loss: 0.0235, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5511], Train Loss: 0.0455, Val Loss: 0.0217, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5512], Train Loss: 0.0558, Val Loss: 0.0195, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5513], Train Loss: 0.0498, Val Loss: 0.0209, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5514], Train Loss: 0.0594, Val Loss: 0.0246, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5515], Train Loss: 0.0474, Val Loss: 0.0286, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5516], Train Loss: 0.0631, Val Loss: 0.0261, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5517], Train Loss: 0.0519, Val Loss: 0.0221, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5518], Train Loss: 0.0568, Val Loss: 0.0220, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5519], Train Loss: 0.0558, Val Loss: 0.0215, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5520], Train Loss: 0.0511, Val Loss: 0.0227, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5521], Train Loss: 0.0518, Val Loss: 0.0224, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5522], Train Loss: 0.0572, Val Loss: 0.0233, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5523], Train Loss: 0.0533, Val Loss: 0.0253, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5524], Train Loss: 0.0487, Val Loss: 0.0310, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5525], Train Loss: 0.0441, Val Loss: 0.0299, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5526], Train Loss: 0.0540, Val Loss: 0.0279, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5527], Train Loss: 0.0531, Val Loss: 0.0303, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5528], Train Loss: 0.0505, Val Loss: 0.0313, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5529], Train Loss: 0.0556, Val Loss: 0.0287, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5530], Train Loss: 0.0498, Val Loss: 0.0326, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5531], Train Loss: 0.0558, Val Loss: 0.0313, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5532], Train Loss: 0.0551, Val Loss: 0.0277, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5533], Train Loss: 0.0567, Val Loss: 0.0268, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5534], Train Loss: 0.0478, Val Loss: 0.0268, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5535], Train Loss: 0.0545, Val Loss: 0.0258, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5536], Train Loss: 0.0474, Val Loss: 0.0223, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5537], Train Loss: 0.0544, Val Loss: 0.0222, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5538], Train Loss: 0.0548, Val Loss: 0.0241, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5539], Train Loss: 0.0538, Val Loss: 0.0284, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5540], Train Loss: 0.0461, Val Loss: 0.0288, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5541], Train Loss: 0.0588, Val Loss: 0.0306, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5542], Train Loss: 0.0456, Val Loss: 0.0325, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5543], Train Loss: 0.0493, Val Loss: 0.0303, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5544], Train Loss: 0.0542, Val Loss: 0.0305, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5545], Train Loss: 0.0590, Val Loss: 0.0287, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5546], Train Loss: 0.0642, Val Loss: 0.0281, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5547], Train Loss: 0.0540, Val Loss: 0.0257, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5548], Train Loss: 0.0511, Val Loss: 0.0257, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5549], Train Loss: 0.0460, Val Loss: 0.0226, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5550], Train Loss: 0.0536, Val Loss: 0.0211, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5551], Train Loss: 0.0488, Val Loss: 0.0210, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5552], Train Loss: 0.0509, Val Loss: 0.0235, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5553], Train Loss: 0.0510, Val Loss: 0.0230, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5554], Train Loss: 0.0585, Val Loss: 0.0260, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5555], Train Loss: 0.0538, Val Loss: 0.0285, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5556], Train Loss: 0.0531, Val Loss: 0.0370, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5557], Train Loss: 0.0505, Val Loss: 0.0379, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5558], Train Loss: 0.0499, Val Loss: 0.0365, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5559], Train Loss: 0.0526, Val Loss: 0.0294, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5560], Train Loss: 0.0514, Val Loss: 0.0280, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5561], Train Loss: 0.0472, Val Loss: 0.0301, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5562], Train Loss: 0.0488, Val Loss: 0.0285, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5563], Train Loss: 0.0551, Val Loss: 0.0266, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5564], Train Loss: 0.0542, Val Loss: 0.0272, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5565], Train Loss: 0.0534, Val Loss: 0.0245, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5566], Train Loss: 0.0526, Val Loss: 0.0240, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5567], Train Loss: 0.0557, Val Loss: 0.0232, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5568], Train Loss: 0.0570, Val Loss: 0.0284, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5569], Train Loss: 0.0499, Val Loss: 0.0290, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5570], Train Loss: 0.0512, Val Loss: 0.0293, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5571], Train Loss: 0.0500, Val Loss: 0.0270, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5572], Train Loss: 0.0486, Val Loss: 0.0253, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5573], Train Loss: 0.0544, Val Loss: 0.0298, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5574], Train Loss: 0.0513, Val Loss: 0.0255, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5575], Train Loss: 0.0537, Val Loss: 0.0262, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5576], Train Loss: 0.0544, Val Loss: 0.0208, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5577], Train Loss: 0.0535, Val Loss: 0.0206, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5578], Train Loss: 0.0590, Val Loss: 0.0209, LR: 0.000010, best val loss was: 0.0195
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5579], Train Loss: 0.0508, Val Loss: 0.0188, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5580], Train Loss: 0.0532, Val Loss: 0.0218, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5581], Train Loss: 0.0549, Val Loss: 0.0232, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5582], Train Loss: 0.0510, Val Loss: 0.0225, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5583], Train Loss: 0.0512, Val Loss: 0.0236, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5584], Train Loss: 0.0484, Val Loss: 0.0244, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5585], Train Loss: 0.0532, Val Loss: 0.0255, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5586], Train Loss: 0.0520, Val Loss: 0.0233, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5587], Train Loss: 0.0499, Val Loss: 0.0245, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5588], Train Loss: 0.0550, Val Loss: 0.0241, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5589], Train Loss: 0.0560, Val Loss: 0.0274, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5590], Train Loss: 0.0505, Val Loss: 0.0242, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5591], Train Loss: 0.0503, Val Loss: 0.0251, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5592], Train Loss: 0.0573, Val Loss: 0.0227, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5593], Train Loss: 0.0536, Val Loss: 0.0224, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5594], Train Loss: 0.0568, Val Loss: 0.0245, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5595], Train Loss: 0.0524, Val Loss: 0.0252, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5596], Train Loss: 0.0459, Val Loss: 0.0272, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5597], Train Loss: 0.0519, Val Loss: 0.0267, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5598], Train Loss: 0.0462, Val Loss: 0.0296, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5599], Train Loss: 0.0568, Val Loss: 0.0335, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5600], Train Loss: 0.0503, Val Loss: 0.0294, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5601], Train Loss: 0.0451, Val Loss: 0.0249, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5602], Train Loss: 0.0477, Val Loss: 0.0244, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5603], Train Loss: 0.0550, Val Loss: 0.0267, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5604], Train Loss: 0.0478, Val Loss: 0.0257, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5605], Train Loss: 0.0486, Val Loss: 0.0320, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5606], Train Loss: 0.0522, Val Loss: 0.0335, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5607], Train Loss: 0.0540, Val Loss: 0.0294, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5608], Train Loss: 0.0566, Val Loss: 0.0241, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5609], Train Loss: 0.0504, Val Loss: 0.0255, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5610], Train Loss: 0.0505, Val Loss: 0.0209, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5611], Train Loss: 0.0529, Val Loss: 0.0262, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5612], Train Loss: 0.0570, Val Loss: 0.0306, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5613], Train Loss: 0.0545, Val Loss: 0.0408, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5614], Train Loss: 0.0499, Val Loss: 0.0311, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5615], Train Loss: 0.0562, Val Loss: 0.0278, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5616], Train Loss: 0.0508, Val Loss: 0.0268, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5617], Train Loss: 0.0578, Val Loss: 0.0276, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5618], Train Loss: 0.0480, Val Loss: 0.0269, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5619], Train Loss: 0.0493, Val Loss: 0.0266, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5620], Train Loss: 0.0542, Val Loss: 0.0246, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5621], Train Loss: 0.0578, Val Loss: 0.0280, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5622], Train Loss: 0.0585, Val Loss: 0.0297, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5623], Train Loss: 0.0577, Val Loss: 0.0251, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5624], Train Loss: 0.0511, Val Loss: 0.0270, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5625], Train Loss: 0.0445, Val Loss: 0.0277, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5626], Train Loss: 0.0524, Val Loss: 0.0274, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5627], Train Loss: 0.0558, Val Loss: 0.0270, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5628], Train Loss: 0.0548, Val Loss: 0.0218, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5629], Train Loss: 0.0565, Val Loss: 0.0244, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5630], Train Loss: 0.0561, Val Loss: 0.0206, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5631], Train Loss: 0.0557, Val Loss: 0.0241, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5632], Train Loss: 0.0499, Val Loss: 0.0228, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5633], Train Loss: 0.0544, Val Loss: 0.0249, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5634], Train Loss: 0.0544, Val Loss: 0.0258, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5635], Train Loss: 0.0522, Val Loss: 0.0230, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5636], Train Loss: 0.0541, Val Loss: 0.0209, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5637], Train Loss: 0.0496, Val Loss: 0.0207, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5638], Train Loss: 0.0481, Val Loss: 0.0248, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5639], Train Loss: 0.0571, Val Loss: 0.0265, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5640], Train Loss: 0.0585, Val Loss: 0.0256, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5641], Train Loss: 0.0565, Val Loss: 0.0236, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5642], Train Loss: 0.0514, Val Loss: 0.0230, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5643], Train Loss: 0.0539, Val Loss: 0.0245, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5644], Train Loss: 0.0561, Val Loss: 0.0245, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5645], Train Loss: 0.0533, Val Loss: 0.0258, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5646], Train Loss: 0.0571, Val Loss: 0.0263, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5647], Train Loss: 0.0484, Val Loss: 0.0250, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5648], Train Loss: 0.0488, Val Loss: 0.0223, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5649], Train Loss: 0.0470, Val Loss: 0.0243, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5650], Train Loss: 0.0483, Val Loss: 0.0274, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5651], Train Loss: 0.0497, Val Loss: 0.0272, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5652], Train Loss: 0.0565, Val Loss: 0.0265, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5653], Train Loss: 0.0472, Val Loss: 0.0278, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5654], Train Loss: 0.0588, Val Loss: 0.0249, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5655], Train Loss: 0.0526, Val Loss: 0.0237, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5656], Train Loss: 0.0487, Val Loss: 0.0265, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5657], Train Loss: 0.0506, Val Loss: 0.0246, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5658], Train Loss: 0.0498, Val Loss: 0.0248, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5659], Train Loss: 0.0527, Val Loss: 0.0278, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5660], Train Loss: 0.0540, Val Loss: 0.0288, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5661], Train Loss: 0.0548, Val Loss: 0.0298, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5662], Train Loss: 0.0465, Val Loss: 0.0316, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5663], Train Loss: 0.0527, Val Loss: 0.0242, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5664], Train Loss: 0.0582, Val Loss: 0.0231, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5665], Train Loss: 0.0539, Val Loss: 0.0217, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5666], Train Loss: 0.0511, Val Loss: 0.0246, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5667], Train Loss: 0.0464, Val Loss: 0.0242, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5668], Train Loss: 0.0530, Val Loss: 0.0226, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5669], Train Loss: 0.0539, Val Loss: 0.0231, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5670], Train Loss: 0.0505, Val Loss: 0.0246, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5671], Train Loss: 0.0550, Val Loss: 0.0228, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5672], Train Loss: 0.0529, Val Loss: 0.0216, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5673], Train Loss: 0.0545, Val Loss: 0.0202, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5674], Train Loss: 0.0494, Val Loss: 0.0239, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5675], Train Loss: 0.0532, Val Loss: 0.0228, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5676], Train Loss: 0.0545, Val Loss: 0.0227, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5677], Train Loss: 0.0545, Val Loss: 0.0221, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5678], Train Loss: 0.0532, Val Loss: 0.0213, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5679], Train Loss: 0.0584, Val Loss: 0.0295, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5680], Train Loss: 0.0552, Val Loss: 0.0278, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5681], Train Loss: 0.0530, Val Loss: 0.0259, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5682], Train Loss: 0.0513, Val Loss: 0.0259, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5683], Train Loss: 0.0554, Val Loss: 0.0259, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5684], Train Loss: 0.0471, Val Loss: 0.0247, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5685], Train Loss: 0.0604, Val Loss: 0.0253, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5686], Train Loss: 0.0523, Val Loss: 0.0236, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5687], Train Loss: 0.0523, Val Loss: 0.0252, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5688], Train Loss: 0.0565, Val Loss: 0.0289, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5689], Train Loss: 0.0519, Val Loss: 0.0331, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5690], Train Loss: 0.0562, Val Loss: 0.0304, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5691], Train Loss: 0.0518, Val Loss: 0.0268, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5692], Train Loss: 0.0612, Val Loss: 0.0294, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5693], Train Loss: 0.0521, Val Loss: 0.0259, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5694], Train Loss: 0.0569, Val Loss: 0.0259, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5695], Train Loss: 0.0574, Val Loss: 0.0265, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5696], Train Loss: 0.0595, Val Loss: 0.0277, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5697], Train Loss: 0.0510, Val Loss: 0.0246, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5698], Train Loss: 0.0555, Val Loss: 0.0241, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5699], Train Loss: 0.0534, Val Loss: 0.0264, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5700], Train Loss: 0.0473, Val Loss: 0.0297, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5701], Train Loss: 0.0512, Val Loss: 0.0291, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5702], Train Loss: 0.0565, Val Loss: 0.0310, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5703], Train Loss: 0.0604, Val Loss: 0.0307, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5704], Train Loss: 0.0552, Val Loss: 0.0287, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5705], Train Loss: 0.0563, Val Loss: 0.0265, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5706], Train Loss: 0.0539, Val Loss: 0.0299, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5707], Train Loss: 0.0527, Val Loss: 0.0285, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5708], Train Loss: 0.0540, Val Loss: 0.0263, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5709], Train Loss: 0.0595, Val Loss: 0.0246, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5710], Train Loss: 0.0531, Val Loss: 0.0225, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5711], Train Loss: 0.0528, Val Loss: 0.0263, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5712], Train Loss: 0.0553, Val Loss: 0.0212, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5713], Train Loss: 0.0553, Val Loss: 0.0221, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5714], Train Loss: 0.0533, Val Loss: 0.0228, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5715], Train Loss: 0.0558, Val Loss: 0.0219, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5716], Train Loss: 0.0528, Val Loss: 0.0243, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5717], Train Loss: 0.0598, Val Loss: 0.0283, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5718], Train Loss: 0.0562, Val Loss: 0.0271, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5719], Train Loss: 0.0492, Val Loss: 0.0265, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5720], Train Loss: 0.0466, Val Loss: 0.0230, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5721], Train Loss: 0.0562, Val Loss: 0.0229, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5722], Train Loss: 0.0528, Val Loss: 0.0252, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5723], Train Loss: 0.0508, Val Loss: 0.0226, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5724], Train Loss: 0.0539, Val Loss: 0.0289, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5725], Train Loss: 0.0506, Val Loss: 0.0289, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5726], Train Loss: 0.0532, Val Loss: 0.0268, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5727], Train Loss: 0.0564, Val Loss: 0.0254, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5728], Train Loss: 0.0487, Val Loss: 0.0263, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5729], Train Loss: 0.0570, Val Loss: 0.0264, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5730], Train Loss: 0.0546, Val Loss: 0.0253, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5731], Train Loss: 0.0529, Val Loss: 0.0253, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5732], Train Loss: 0.0545, Val Loss: 0.0276, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5733], Train Loss: 0.0517, Val Loss: 0.0333, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5734], Train Loss: 0.0528, Val Loss: 0.0312, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5735], Train Loss: 0.0538, Val Loss: 0.0327, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5736], Train Loss: 0.0620, Val Loss: 0.0293, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5737], Train Loss: 0.0430, Val Loss: 0.0262, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5738], Train Loss: 0.0536, Val Loss: 0.0248, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5739], Train Loss: 0.0555, Val Loss: 0.0228, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5740], Train Loss: 0.0556, Val Loss: 0.0235, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5741], Train Loss: 0.0554, Val Loss: 0.0244, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5742], Train Loss: 0.0476, Val Loss: 0.0279, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5743], Train Loss: 0.0573, Val Loss: 0.0286, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5744], Train Loss: 0.0508, Val Loss: 0.0250, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5745], Train Loss: 0.0439, Val Loss: 0.0254, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5746], Train Loss: 0.0495, Val Loss: 0.0264, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5747], Train Loss: 0.0567, Val Loss: 0.0227, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5748], Train Loss: 0.0467, Val Loss: 0.0297, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5749], Train Loss: 0.0474, Val Loss: 0.0248, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5750], Train Loss: 0.0509, Val Loss: 0.0249, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5751], Train Loss: 0.0543, Val Loss: 0.0212, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5752], Train Loss: 0.0469, Val Loss: 0.0212, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5753], Train Loss: 0.0504, Val Loss: 0.0232, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5754], Train Loss: 0.0542, Val Loss: 0.0281, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5755], Train Loss: 0.0567, Val Loss: 0.0245, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5756], Train Loss: 0.0466, Val Loss: 0.0257, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5757], Train Loss: 0.0582, Val Loss: 0.0261, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5758], Train Loss: 0.0475, Val Loss: 0.0249, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5759], Train Loss: 0.0520, Val Loss: 0.0252, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5760], Train Loss: 0.0464, Val Loss: 0.0273, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5761], Train Loss: 0.0518, Val Loss: 0.0254, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5762], Train Loss: 0.0540, Val Loss: 0.0266, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5763], Train Loss: 0.0557, Val Loss: 0.0240, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5764], Train Loss: 0.0515, Val Loss: 0.0221, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5765], Train Loss: 0.0529, Val Loss: 0.0227, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5766], Train Loss: 0.0541, Val Loss: 0.0287, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5767], Train Loss: 0.0557, Val Loss: 0.0262, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5768], Train Loss: 0.0501, Val Loss: 0.0283, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5769], Train Loss: 0.0508, Val Loss: 0.0293, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5770], Train Loss: 0.0555, Val Loss: 0.0285, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5771], Train Loss: 0.0502, Val Loss: 0.0270, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5772], Train Loss: 0.0523, Val Loss: 0.0249, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5773], Train Loss: 0.0505, Val Loss: 0.0287, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5774], Train Loss: 0.0511, Val Loss: 0.0330, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5775], Train Loss: 0.0513, Val Loss: 0.0328, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5776], Train Loss: 0.0522, Val Loss: 0.0326, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5777], Train Loss: 0.0459, Val Loss: 0.0323, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5778], Train Loss: 0.0565, Val Loss: 0.0314, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5779], Train Loss: 0.0477, Val Loss: 0.0358, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5780], Train Loss: 0.0530, Val Loss: 0.0335, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5781], Train Loss: 0.0544, Val Loss: 0.0280, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5782], Train Loss: 0.0509, Val Loss: 0.0274, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5783], Train Loss: 0.0500, Val Loss: 0.0263, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5784], Train Loss: 0.0531, Val Loss: 0.0254, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5785], Train Loss: 0.0522, Val Loss: 0.0228, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5786], Train Loss: 0.0573, Val Loss: 0.0250, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5787], Train Loss: 0.0547, Val Loss: 0.0238, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5788], Train Loss: 0.0537, Val Loss: 0.0247, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5789], Train Loss: 0.0576, Val Loss: 0.0234, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5790], Train Loss: 0.0582, Val Loss: 0.0292, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5791], Train Loss: 0.0528, Val Loss: 0.0289, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5792], Train Loss: 0.0498, Val Loss: 0.0318, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5793], Train Loss: 0.0526, Val Loss: 0.0269, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5794], Train Loss: 0.0611, Val Loss: 0.0252, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5795], Train Loss: 0.0504, Val Loss: 0.0241, LR: 0.000010, best val loss was: 0.0188
model:  ckpt_50pct_recursive_h10_real_val_speed_correction_R1_v2
Epoch [5796], Train Loss: 0.0522, Val Loss: 0.0254, LR: 0.000010, best val loss was: 0.0188
Traceback (most recent call last):
  File "c:\Users\39340\Documents\GitHub\in-context-bldc\speed_estimator\train_zerostep_new_v3.py", line 440, in <module>
    train_loss = train(model, train_dl, criterion, optimizer, device, R_training)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\39340\Documents\GitHub\in-context-bldc\speed_estimator\train_zerostep_new_v3.py", line 158, in train
    loss.backward()
  File "C:\Users\39340\AppData\Roaming\Python\Python312\site-packages\torch\_tensor.py", line 648, in backward
    torch.autograd.backward(
  File "C:\Users\39340\AppData\Roaming\Python\Python312\site-packages\torch\autograd\__init__.py", line 353, in backward
    _engine_run_backward(
  File "C:\Users\39340\AppData\Roaming\Python\Python312\site-packages\torch\autograd\graph.py", line 824, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
